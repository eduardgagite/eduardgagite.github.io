{"content":"\nКогда данных становится много, важно понимать, сколько памяти реально занимает каждый ключ и какие структуры «съедают» больше всего. В **Redis** для этого есть отдельные инструменты: команды **MEMORY USAGE**, **MEMORY STATS** и **MEMORY DOCTOR**.\n\nС их помощью можно найти самые тяжёлые ключи, сравнить разные варианты хранения и принять осознанное решение по оптимизации.\n\n## MEMORY USAGE — размер одного ключа\n\nПроще всего начать с оценки конкретного ключа. Команда **MEMORY USAGE** показывает примерный объём памяти в байтах, который занимает значение.\n\nПример с простым кэшем статьи:\n\n```\nSET cache:article:42 \"{...json статьи...}\"\nMEMORY USAGE cache:article:42\n```\n\nВ ответ Redis вернёт число, например:\n\n```\n(integer) 2048\n```\n\nЭто не точный, но достаточно близкий к реальности размер. Полезно запускать **MEMORY USAGE** на разных типах ключей:\n\n- строки с JSON;\n- хеши с теми же данными;\n- списки, множества, упорядоченные множества.\n\nТак можно быстро увидеть, какой формат для вашей задачи дешевле по памяти.\n\n## Поиск «тяжёлых» ключей через SCAN\n\nЧтобы понять, какие ключи в инстансе самые крупные, можно пройтись по ним через **SCAN** и для каждого посмотреть **MEMORY USAGE**.\n\nНапример, ищем тяжёлые ключи кэша:\n\n```\nSCAN 0 MATCH cache:* COUNT 100\nMEMORY USAGE cache:article:1\nMEMORY USAGE cache:article:2\nMEMORY USAGE cache:profile:42\n```\n\nСкрипт на стороне приложения:\n\n- вызывает **SCAN** в цикле;\n- для каждого найденного ключа делает **MEMORY USAGE**;\n- сортирует по размеру и показывает топ-10–20 самых больших.\n\nТакой подход помогает быстро найти неожиданные «пожиратели» памяти: огромные списки логов, ключи без **TTL**, слишком крупные JSON-объекты.\n\n## MEMORY STATS и MEMORY DOCTOR\n\nДля общей картины по памяти можно использовать:\n\n```\nMEMORY STATS\n```\n\nКоманда возвращает большой набор метрик: общую использованную память, накладные расходы на структуры, настройки аллокатора, фрагментацию. Полезно сохранить этот вывод и сравнивать его до и после изменений в схеме хранения.\n\nЕсли хочется быстрой подсказки от самого Redis:\n\n```\nMEMORY DOCTOR\n```\n\nОтвет будет в текстовом виде и может содержать советы уровня:\n\n- уменьшить количество маленьких ключей;\n- обратить внимание на фрагментацию;\n- посмотреть на конфигурацию аллокатора.\n\nЭти рекомендации не всегда точечные, но часто помогают заметить общие проблемы.\n\n## Сравнение вариантов хранения на примере\n\nДопустим, у нас есть 1000 настроек пользователей. Можно хранить их как 1000 отдельных ключей:\n\n```\nSET user:1:settings \"{...}\"\nSET user:2:settings \"{...}\"\n...\nSET user:1000:settings \"{...}\"\n```\n\nА можно как один хеш:\n\n```\nHSET user:settings 1 \"{...}\"\nHSET user:settings 2 \"{...}\"\n...\nHSET user:settings 1000 \"{...}\"\n```\n\nЧтобы сравнить, достаточно измерить:\n\n```\nMEMORY USAGE user:1:settings\nMEMORY USAGE user:settings\n```\n\nВо многих случаях один хеш будет экономичнее, чем множество мелких ключей, за счёт меньших накладных расходов. Но лучше всегда проверять на своих данных.\n\n## Итог\n\nИнструменты **MEMORY USAGE**, **MEMORY STATS** и **MEMORY DOCTOR** помогают превратить оптимизацию памяти в измеряемый процесс, а не в угадывание.\n\nРегулярная оценка размеров ключей и поиск самых тяжёлых записей позволяет вовремя заметить неэффективные структуры и переработать схему хранения до того, как Redis начнёт упираться в лимит.\n\n\n"}