{"content":"\nВ предыдущих статьях мы разобрали горутины, каналы, select и sync-примитивы. Теперь соберём из этих кирпичиков готовые архитектурные решения, которые встречаются в реальных Go-проектах каждый день.\n\n## Worker Pool — пул воркеров\n\nЗадача: обработать 10 000 задач, но запускать не более 5 горутин одновременно (чтобы не перегрузить базу данных или внешний API).\n\n```\nfunc worker(id int, jobs <-chan int, results chan<- int) {\n    for job := range jobs {\n        fmt.Printf(\"Воркер %d обрабатывает задачу %d\\n\", id, job)\n        time.Sleep(time.Second)\n        results <- job * 2\n    }\n}\n\nfunc main() {\n    jobs := make(chan int, 100)\n    results := make(chan int, 100)\n\n    for w := 1; w <= 5; w++ {\n        go worker(w, jobs, results)\n    }\n\n    for j := 1; j <= 20; j++ {\n        jobs <- j\n    }\n    close(jobs)\n\n    for i := 1; i <= 20; i++ {\n        fmt.Println(<-results)\n    }\n}\n```\n\nКанал **jobs** с типом **<-chan int** (только чтение) и **results** с типом **chan<- int** (только запись) — это направленные каналы. Они не дают воркеру случайно отправить задачу вместо получения.\n\nПул воркеров решает две задачи: ограничивает нагрузку (не больше N одновременных операций) и эффективно распределяет работу между горутинами.\n\n## Fan-Out / Fan-In\n\n**Fan-Out** — одна горутина раздаёт задачи нескольким воркерам. **Fan-In** — результаты из нескольких каналов собираются в один.\n\n```\nfunc producer(count int) <-chan int {\n    out := make(chan int)\n    go func() {\n        for i := 0; i < count; i++ {\n            out <- i\n        }\n        close(out)\n    }()\n    return out\n}\n\nfunc square(in <-chan int) <-chan int {\n    out := make(chan int)\n    go func() {\n        for n := range in {\n            out <- n * n\n        }\n        close(out)\n    }()\n    return out\n}\n\nfunc merge(channels ...<-chan int) <-chan int {\n    out := make(chan int)\n    var wg sync.WaitGroup\n\n    for _, ch := range channels {\n        wg.Add(1)\n        go func(c <-chan int) {\n            defer wg.Done()\n            for v := range c {\n                out <- v\n            }\n        }(ch)\n    }\n\n    go func() {\n        wg.Wait()\n        close(out)\n    }()\n\n    return out\n}\n\nfunc main() {\n    source := producer(10)\n\n    ch1 := square(source)\n    ch2 := square(source)\n    ch3 := square(source)\n\n    for result := range merge(ch1, ch2, ch3) {\n        fmt.Println(result)\n    }\n}\n```\n\nЭтот паттерн подходит для конвейерной обработки данных: прочитали из файла → распарсили → обогатили → записали.\n\n## Pipeline — конвейер\n\nКонвейер — цепочка этапов, где выход одного этапа является входом следующего. Каждый этап — отдельная горутина.\n\n```\nfunc generate(nums ...int) <-chan int {\n    out := make(chan int)\n    go func() {\n        for _, n := range nums {\n            out <- n\n        }\n        close(out)\n    }()\n    return out\n}\n\nfunc double(in <-chan int) <-chan int {\n    out := make(chan int)\n    go func() {\n        for n := range in {\n            out <- n * 2\n        }\n        close(out)\n    }()\n    return out\n}\n\nfunc addTen(in <-chan int) <-chan int {\n    out := make(chan int)\n    go func() {\n        for n := range in {\n            out <- n + 10\n        }\n        close(out)\n    }()\n    return out\n}\n\nfunc main() {\n    for v := range addTen(double(generate(1, 2, 3, 4))) {\n        fmt.Println(v) // 12, 14, 16, 18\n    }\n}\n```\n\nКаждый этап работает в своей горутине. Данные текут по каналам без буферизации — следующий этап начинает работу, как только предыдущий выдаст значение.\n\n## errgroup — параллельные задачи с обработкой ошибок\n\nПакет **golang.org/x/sync/errgroup** решает частую задачу: запустить N горутин, дождаться всех и вернуть первую ошибку.\n\n```\nimport \"golang.org/x/sync/errgroup\"\n\nfunc fetchAll(urls []string) error {\n    g, ctx := errgroup.WithContext(context.Background())\n\n    for _, url := range urls {\n        url := url\n        g.Go(func() error {\n            req, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n            if err != nil {\n                return fmt.Errorf(\"создание запроса %s: %w\", url, err)\n            }\n\n            resp, err := http.DefaultClient.Do(req)\n            if err != nil {\n                return fmt.Errorf(\"запрос к %s: %w\", url, err)\n            }\n            defer resp.Body.Close()\n\n            fmt.Printf(\"%s: %d\\n\", url, resp.StatusCode)\n            return nil\n        })\n    }\n\n    return g.Wait()\n}\n```\n\nЕсли одна из горутин вернёт ошибку, **ctx** будет отменён, и остальные горутины (если они проверяют контекст) тоже остановятся.\n\n### errgroup с лимитом параллелизма\n\n```\ng, ctx := errgroup.WithContext(context.Background())\ng.SetLimit(5)\n\nfor _, task := range tasks {\n    task := task\n    g.Go(func() error {\n        return processTask(ctx, task)\n    })\n}\n\nerr := g.Wait()\n```\n\nМетод **SetLimit** превращает errgroup в пул воркеров с обработкой ошибок — часто это всё, что нужно.\n\n## Семафор через буферизированный канал\n\nЕсли нужен простой лимит параллелизма без errgroup, буферизированный канал работает как семафор.\n\n```\nfunc processWithLimit(items []string, limit int) {\n    sem := make(chan struct{}, limit)\n    var wg sync.WaitGroup\n\n    for _, item := range items {\n        wg.Add(1)\n        sem <- struct{}{}\n\n        go func(item string) {\n            defer wg.Done()\n            defer func() { <-sem }()\n\n            process(item)\n        }(item)\n    }\n\n    wg.Wait()\n}\n```\n\nКанал ёмкостью **limit** пропускает не больше **limit** горутин одновременно. Попытка записать в полный канал блокирует, пока кто-то не освободит место.\n\n## Итог\n\n**Worker Pool** — для контролируемой параллельной обработки задач. **Fan-Out/Fan-In** — для распараллеливания одного потока данных. **Pipeline** — для конвейерной обработки в несколько этапов. **errgroup** — для параллельных задач с обработкой ошибок и лимитом. На практике чаще всего хватает **errgroup с SetLimit** — он покрывает 80% случаев.\n"}