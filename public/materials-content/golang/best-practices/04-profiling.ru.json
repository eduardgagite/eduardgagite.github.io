{"content":"\nКод работает, тесты зелёные, но сервис тормозит или ест слишком много памяти. Угадывать, где проблема — плохая стратегия. Go предоставляет встроенный профайлер **pprof**, который точно показывает, на что тратится CPU и куда уходит память.\n\n## Подключение pprof к серверу\n\nСамый простой способ — импортировать пакет **net/http/pprof**. Он автоматически регистрирует HTTP-эндпоинты для профилирования.\n\n```\nimport (\n    \"net/http\"\n    _ \"net/http/pprof\"\n)\n\nfunc main() {\n    go func() {\n        http.ListenAndServe(\"localhost:6060\", nil)\n    }()\n\n    runApp()\n}\n```\n\nПодчёркивание перед импортом (**_ \"net/http/pprof\"**) означает: \"нам не нужны функции из этого пакета, но его init() должен выполниться\". Именно init() регистрирует обработчики.\n\nЭндпоинт слушает на **localhost:6060** — доступен только локально. Не выставляйте pprof наружу в продакшене без аутентификации.\n\n## CPU-профиль\n\nCPU-профиль показывает, какие функции потребляют больше всего процессорного времени.\n\n### Сбор профиля\n\n```\ngo tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n```\n\nВо время сбора отправляйте нагрузку на сервер (реальные запросы или через утилиту вроде **wrk** / **hey**), чтобы профиль отразил типичную работу.\n\n### Анализ в интерактивном режиме\n\nПосле сбора откроется интерактивная консоль.\n\n```\n(pprof) top 10\n```\n\nКоманда **top** показывает функции, которые потребляют больше всего CPU:\n\n```\nShowing top 10 nodes out of 85\n      flat  flat%   sum%        cum   cum%\n     2.10s 28.38% 28.38%      2.10s 28.38%  runtime.memmove\n     1.20s 16.22% 44.59%      1.20s 16.22%  encoding/json.(*decodeState).scanWhile\n     0.80s 10.81% 55.41%      3.40s 45.95%  myapp/handler.ProcessRequest\n```\n\n- **flat** — время, проведённое непосредственно в этой функции.\n- **cum** (cumulative) — время в этой функции плюс во всех функциях, которые она вызвала.\n\n```\n(pprof) list ProcessRequest\n```\n\nКоманда **list** показывает исходный код с аннотациями — сколько времени потратила каждая строка.\n\n### Визуализация\n\n```\ngo tool pprof -http=:8080 http://localhost:6060/debug/pprof/profile?seconds=30\n```\n\nФлаг **-http** запускает веб-интерфейс с интерактивным графом вызовов, flame graph и другими визуализациями. Это самый удобный способ анализа.\n\n## Профиль памяти (heap)\n\nПоказывает, какие функции выделяют больше всего памяти.\n\n```\ngo tool pprof http://localhost:6060/debug/pprof/heap\n```\n\n```\n(pprof) top\n      flat  flat%   sum%        cum   cum%\n    512MB 45.00% 45.00%    512MB 45.00%  myapp/cache.LoadAll\n    128MB 11.25% 56.25%    128MB 11.25%  encoding/json.(*Decoder).Decode\n```\n\nДва режима просмотра:\n\n- **inuse_space** (по умолчанию) — сколько памяти занято прямо сейчас.\n- **alloc_space** — сколько памяти было выделено за всё время (включая уже освобождённую).\n\n```\n(pprof) sample_index = alloc_space\n(pprof) top\n```\n\nРежим **alloc_space** полезен для поиска мест, где создаётся много короткоживущих объектов — это нагружает сборщик мусора.\n\n## Профилирование горутин\n\nЕсли сервис зависает или горутины утекают (goroutine leak), посмотрите профиль горутин.\n\n```\ngo tool pprof http://localhost:6060/debug/pprof/goroutine\n```\n\n```\n(pprof) top\n    5000  goroutines in total\n    4990  myapp/worker.processJob (blocked on channel receive)\n```\n\nЕсли видите тысячи горутин, застрявших в одном месте — это утечка. Горутина создаётся, но никогда не завершается (например, читает из канала, в который никто не пишет).\n\n## Профилирование в тестах\n\nДля профилирования без запуска сервера используйте флаги **go test**. Для CPU — **-cpuprofile**, для памяти — **-memprofile**:\n\n```\ngo test -cpuprofile=cpu.out -bench=. ./...\ngo tool pprof cpu.out\n\ngo test -memprofile=mem.out -bench=. ./...\ngo tool pprof mem.out\n```\n\nЭто удобно для оптимизации конкретных функций: написали бенчмарк, сняли профиль, нашли узкое место, оптимизировали, сняли профиль снова.\n\n## Профилирование в коде\n\nИногда нужно профилировать не сервер, а утилиту командной строки.\n\n```\nimport \"runtime/pprof\"\n\nfunc main() {\n    f, _ := os.Create(\"cpu.out\")\n    pprof.StartCPUProfile(f)\n    defer pprof.StopCPUProfile()\n\n    doHeavyWork()\n}\n```\n\n```\ngo tool pprof cpu.out\n```\n\n## Практический пример: поиск утечки памяти\n\nСервис постепенно ест всё больше памяти. Алгоритм поиска:\n\n1. Снимите heap-профиль: **go tool pprof -http=:8080 http://localhost:6060/debug/pprof/heap**.\n2. Откройте flame graph в веб-интерфейсе.\n3. Найдите самую широкую полоску — это функция, выделяющая больше всего памяти.\n4. Посмотрите исходный код через **list**.\n5. Типичные причины: растущий кэш без TTL, срезы, которые только растут, горутины, которые не завершаются.\n\n## Итог\n\n**pprof** — встроенный профайлер Go для CPU, памяти и горутин. Подключается одной строкой импорта. Используйте **go tool pprof -http** для визуального анализа. **Никогда не оптимизируйте по ощущениям — снимите профиль и оптимизируйте то, что действительно тормозит.**\n"}