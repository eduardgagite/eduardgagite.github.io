{
  "entries": [
    {
      "title": "Introduction to containerization",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Introduction to containerization",
      "sectionOrder": 1,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "01-introduction-to-containerization",
        "lang": "en"
      },
      "path": "/content/materials/docker/intro/01-introduction-to-containerization.en.md",
      "content": "\n"
    },
    {
      "title": "Введение в контейнеризацию",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Введение в контейнеризацию",
      "sectionOrder": 1,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "01-introduction-to-containerization",
        "lang": "ru"
      },
      "path": "/content/materials/docker/intro/01-introduction-to-containerization.ru.md",
      "content": "\nПредставьте ситуацию: разработчик написал приложение, у него оно работает идеально. Но когда другой член команды пытается запустить тот же проект, появляются ошибки: чего-то не хватает, версии библиотек разные, среда настроена иначе. В итоге много времени уходит не на разработку, а на попытки «заставить всё работать одинаково».\n\nКонтейнеры решают эту проблему.\n\n## Простой пример из реальной жизни\n\nДопустим, вы разработали веб-приложение на Python.  \n\nДля его работы нужны:\n\n- определённая версия Python,  \n\n- конкретная версия библиотеки Flask,  \n\n- нужные пакеты системы,  \n\n- свои конфигурационные файлы.\n\nУ каждого члена команды компьютер настроен по-разному, и каждый сервер тоже уникален. Без контейнеров приложение может вести себя по-разному в зависимости от окружения.\n\n**Контейнер решает это так:**\n\n1. Вы описываете в единообразном файле, что нужно вашему приложению.  \n\n2. Docker создаёт контейнер — маленькое изолированное «мини-окружение», где всё настроено правильно.  \n\n3. Этот контейнер можно запустить на любом компьютере или сервере — и приложение заработает одинаково.\n\nЭто похоже на то, как если бы вы упаковали приложение в коробку со всем, что ему нужно, и отправили кому угодно — коробку открывают, и всё работает без сюрпризов.\n\n## Что такое контейнер\n\nКонтейнер — это упакованная среда, в которой находится всё, что нужно приложению:\n\n- код программы,  \n\n- библиотеки и зависимости,  \n\n- необходимые системные утилиты,  \n\n- минимальные настройки окружения.\n\nКонтейнеры изолированы друг от друга, но используют общую операционную систему хоста. Поэтому они:\n\n- запускаются за секунды,\n\n- занимают мало места,\n\n- экономно используют ресурсы,\n\n- легко переносимы.\n\nИменно эта простота и предсказуемость сделали контейнеризацию стандартом de-facto в современной разработке.\n\n"
    },
    {
      "title": "Problems Docker solves",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Introduction to containerization",
      "sectionOrder": 1,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "02-docker-tasks",
        "lang": "en"
      },
      "path": "/content/materials/docker/intro/02-docker-tasks.en.md",
      "content": "\n\n"
    },
    {
      "title": "Задачи, которые решает Docker",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Введение в контейнеризацию",
      "sectionOrder": 1,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "02-docker-tasks",
        "lang": "ru"
      },
      "path": "/content/materials/docker/intro/02-docker-tasks.ru.md",
      "content": "\nВ разработке приложений часто возникает одна и та же проблема: код отлично работает на компьютере разработчика, но начинает «ломаться» на другом сервере или у другого члена команды. Причина — разные версии библиотек, несовпадающие настройки и отличающиеся системы. Из-за этого развёртывание становится долгим, сложным и непредсказуемым.\n\nЭта проблема получила понятное и эффективное решение в 2013 году, когда появилась платформа Docker.\n\nDocker — это инструмент, который помогает разработчикам проще и быстрее запускать приложения. Его основная идея — упаковать приложение вместе со всеми зависимостями в единый контейнер. Такой контейнер можно запускать на разных серверах без дополнительных настроек — приложение будет работать одинаково везде.\n\nКонтейнеры изолируют приложения друг от друга, поэтому на одном сервере можно безопасно запускать много разных сервисов. При этом они гораздо легче и быстрее виртуальных машин, так как не требуют отдельной операционной системы.\n\nDocker решает три ключевые задачи:\n\n1. **Упаковка приложения.** Код и все необходимые компоненты помещаются в контейнер, что гарантирует одинаковый запуск в любой среде.  \n2. **Передача контейнера.** Команда может легко делиться контейнерами между этапами разработки, тестирования и подготовки к релизу.  \n3. **Развёртывание.** Контейнеры можно запускать на рабочем сервере (в продакшене), в дата-центре или в облаке без изменения конфигурации.\n\nВ результате сокращается время между написанием кода и его запуском в реальной среде. Процессы разработки, тестирования и выката становятся быстрее, стабильнее и предсказуемее."
    },
    {
      "title": "Virtual machines vs containers",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Introduction to containerization",
      "sectionOrder": 1,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "03-vms-vs-containers",
        "lang": "en"
      },
      "path": "/content/materials/docker/intro/03-vms-vs-containers.en.md",
      "content": "\n\n"
    },
    {
      "title": "Сравнение виртуальных машин и контейнеров",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Введение в контейнеризацию",
      "sectionOrder": 1,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "03-vms-vs-containers",
        "lang": "ru"
      },
      "path": "/content/materials/docker/intro/03-vms-vs-containers.ru.md",
      "content": "\nПри разработке и запуске приложений долгое время использовали виртуальные машины. Они позволяли изолировать приложения друг от друга, но имели существенный минус — каждую такую машину приходилось запускать вместе с полноценной операционной системой. Это занимало много ресурсов и замедляло работу.\n\nКонтейнеры решили эту проблему. Они также изолируют приложения, но устраняют лишнюю «оболочку» в виде полной ОС.\n\nОсновные отличия можно описать так:\n\n## Виртуальные машины\n\nВиртуальная машина (VM) запускается через гипервизор и содержит:\n- собственную полноценную операционную систему,\n- системные службы,\n- приложения и их зависимости.\n\nЭто даёт хорошую изоляцию, но требует много памяти, процессорного времени и времени для загрузки. Запуск десятков виртуальных машин на одном сервере может быть дорогим и медленным.\n\n## Контейнеры\n\nКонтейнер использует общую операционную систему хоста, но отделяет приложения друг от друга с помощью изоляции на уровне процессов. Такой подход делает контейнеры:\n\n- легче — нет отдельной ОС внутри,\n- быстрее — запускаются за секунды,\n- экономичнее — можно разместить больше контейнеров на одном сервере.\n\nПри этом изоляция остаётся достаточно надёжной для большинства задач.\n\n## Что это даёт разработчикам\n\nКонтейнеры позволяют запускать приложения быстрее и эффективнее, чем виртуальные машины, и без лишних накладных расходов. Это стало одной из ключевых причин, почему Docker получил широкое распространение — от локальной разработки до крупных облачных систем."
    },
    {
      "title": "Docker architecture: Engine, CLI, Daemon",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Introduction to containerization",
      "sectionOrder": 1,
      "order": 4,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "04-docker-architecture",
        "lang": "en"
      },
      "path": "/content/materials/docker/intro/04-docker-architecture.en.md",
      "content": "\n\n"
    },
    {
      "title": "Архитектура Docker: Engine, CLI, Daemon",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Введение в контейнеризацию",
      "sectionOrder": 1,
      "order": 4,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "04-docker-architecture",
        "lang": "ru"
      },
      "path": "/content/materials/docker/intro/04-docker-architecture.ru.md",
      "content": "\n\n"
    },
    {
      "title": "Lua-скрипты",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "advanced",
      "sectionTitle": "Продвинутые темы",
      "sectionOrder": 12,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "advanced",
        "slug": "01-lua-scripts",
        "lang": "ru"
      },
      "path": "/content/materials/redis/advanced/01-lua-scripts.ru.md",
      "content": "\nИногда одной команды Redis недостаточно: нужно сделать несколько проверок, обновить пару ключей и при этом сохранить атомарность. В таких случаях выручает встроенная поддержка **Lua-скриптов**: небольшой скрипт выполняется целиком как одна команда, без гонок между конкурентными клиентами.\n\nГлавная идея: сложная логика с несколькими шагами переносится в Redis и выполняется там, где лежат данные.\n\n## Запуск простого Lua-скрипта\n\nБазовая команда — **EVAL**. Внутри скрипта доступны массивы **KEYS** и **ARGV**: первые используются для имён ключей, вторые — для произвольных аргументов.\n\nПример: атомарно увеличить счётчик только если он меньше порога.\n\n```\nEVAL \"\n  local current = tonumber(redis.call('GET', KEYS[1]) or '0')\n  if current >= tonumber(ARGV[1]) then\n    return current\n  end\n  current = current + 1\n  redis.call('SET', KEYS[1], current)\n  return current\n\" 1 metrics:actions 100\n```\n\nЧто происходит:\n\n- скрипт читает значение **metrics:actions**;\n- если значение достигло порога **100**, просто возвращает его;\n- иначе увеличивает и сохраняет обратно;\n- вся логика выполняется как одна атомарная операция.\n\n## Использование SHA и кэширование скриптов\n\nКаждый скрипт можно загрузить в Redis и вызывать по SHA‑хэшу. Это уменьшает накладные расходы при частом запуске.\n\nЗагрузка:\n\n```\nSCRIPT LOAD \"\n  return redis.call('INCRBY', KEYS[1], tonumber(ARGV[1]))\n\"\n```\n\nRedis вернёт SHA скрипта, например:\n\n```\n\"f2b3c0...\"\n```\n\nВызов по SHA:\n\n```\nEVALSHA f2b3c0... 1 metrics:views 10\n```\n\nЕсли скрипт уже загружен, Redis сразу выполнит его, минуя повторный разбор текста.\n\n## Ограничения и практические рекомендации\n\nВажно помнить:\n\n- скрипты выполняются в одном потоке и блокируют выполнение других команд до завершения;\n- нельзя вызывать команды, которые требуют пользовательского ввода или делают блокировки;\n- скрипты должны быть быстрыми и предусказуемыми по времени выполнения.\n\nПрактичные советы:\n\n- выносить в Lua только логику, где критична атомарность и несколько шагов;\n- не загонять в скрипт огромные циклы по тысячам ключей;\n- держать код скриптов в репозитории, а не писать случайный текст прямо в консоли.\n\n## Итог\n\n**Lua-скрипты** позволяют реализовывать сложные атомарные операции прямо в Redis, без гонок и дополнительных сетевых запросов.\n\nЕсли использовать их точечно — для проверки и обновления нескольких ключей за один шаг — можно заметно упростить код приложения и повысить надёжность критичных операций.\n\n\n"
    },
    {
      "title": "Транзакции и мультикоманды",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "advanced",
      "sectionTitle": "Продвинутые темы",
      "sectionOrder": 12,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "advanced",
        "slug": "02-transactions",
        "lang": "ru"
      },
      "path": "/content/materials/redis/advanced/02-transactions.ru.md",
      "content": "\nВ **Redis** нет привычных транзакций с изоляцией и откатом, как в классических СУБД, но есть механизм **MULTI/EXEC** и оптимистичные блокировки через **WATCH**. Вместе они позволяют группировать несколько команд в одну «мультикоманду» и атомарно применять изменения, если никто не успел вмешаться.\n\nВажно понимать, что транзакции в Redis — это скорее последовательное выполнение команд без прерывания, чем полноценная ACID‑модель.\n\n## MULTI/EXEC — группировка команд\n\nБазовый паттерн:\n\n1. Открываем транзакцию командой **MULTI**.\n2. Отправляем несколько команд — они не выполняются сразу, а попадают в очередь.\n3. Фиксируем изменения через **EXEC**.\n\nПример: инкремент двух счётчиков как одной операции.\n\n```\nMULTI\nINCR metrics:views\nINCR metrics:clicks\nEXEC\n```\n\nЗдесь:\n\n- обе команды попадут в очередь;\n- при EXEC Redis выполнит их последовательно, без вмешательства других клиентов между ними;\n- отката при ошибке одной команды нет — ответственность на приложении.\n\n## WATCH — оптимистичная блокировка\n\nЕсли важно убедиться, что данные не менялись между чтением и записью, используют **WATCH**. Он помечает один или несколько ключей как наблюдаемые; если какой‑то из них изменится до EXEC, транзакция не выполнится.\n\nПример: безопасное списание баланса.\n\n```\nWATCH user:42:balance\nGET user:42:balance\nMULTI\nDECRBY user:42:balance 100\nEXEC\n```\n\nСценарий:\n\n- после WATCH и GET приложение решает, достаточно ли средств;\n- если в это время другой клиент изменит **user:42:balance**, EXEC вернёт nil — транзакция не применится;\n- приложение может повторить попытку или сообщить об ошибке.\n\nТакой подход называют оптимистичной блокировкой: нет тяжёлых лочков, но есть проверка на конкурентные изменения.\n\n## Пайплайны против транзакций\n\nВажно не путать:\n\n- транзакции (**MULTI/EXEC**) — про атомарность группы команд;\n- пайплайны — про уменьшение сетевых задержек за счёт отправки нескольких команд одним пакетом.\n\nМногие клиентские библиотеки позволяют отправлять пачку команд без ожидания ответов по очереди. Это ускоряет работу, но не даёт никаких гарантий атомарности.\n\nКомбинировать подходы можно: внутри пайплайна использовать MULTI/EXEC, если нужна и скорость, и атомарность.\n\n## Итог\n\nТранзакции в **Redis** через **MULTI/EXEC** и **WATCH** помогают группировать команды и защищаться от гонок при конкурентных изменениях.\n\nЕсли правильно использовать оптимистичные блокировки и помнить об отсутствии автоматического отката, можно реализовать надёжные сценарии обновления нескольких ключей без излишнего усложнения архитектуры.\n\n\n"
    },
    {
      "title": "Модули Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "advanced",
      "sectionTitle": "Продвинутые темы",
      "sectionOrder": 12,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "advanced",
        "slug": "03-redis-modules",
        "lang": "ru"
      },
      "path": "/content/materials/redis/advanced/03-redis-modules.ru.md",
      "content": "\nБазовый **Redis** уже даёт много возможностей, но иногда хочется добавить свои типы данных, команды или встроить внешнюю логику ближе к памяти. Для этого существуют **модули Redis** — динамические расширения, которые сервер может загружать при старте или во время работы.\n\nМодули позволяют превратить Redis во что‑то большее, чем «ключ–значение»: поисковый движок, графовую базу, JSON‑хранилище и многое другое.\n\n## Как подключаются модули\n\nМодуль — это скомпилированная библиотека (обычно .so), которую Redis загружает командой **MODULE LOAD** или через конфиг.\n\nЧерез конфиг:\n\n```\nloadmodule /etc/redis/modules/my_module.so\n```\n\nЧерез команду:\n\n```\nMODULE LOAD /etc/redis/modules/my_module.so\n```\n\nПосмотреть загруженные модули:\n\n```\nMODULE LIST\n```\n\nРазгрузить модуль (если разрешено конфигурацией):\n\n```\nMODULE UNLOAD my_module\n```\n\nКак правило, в продакшене модули подключают через конфиг при старте, чтобы при перезапуске Redis всегда поднимался в одном и том же составе.\n\n## Что дают модули на практике\n\nПопулярные официальные и сторонние модули добавляют:\n\n- новые структуры данных (JSON‑объекты, графы, временные ряды);\n- продвинутый поиск и индексацию;\n- готовые высокоуровневые функции (например, для анализа данных).\n\nИдея в том, что тяжёлую по логике часть можно реализовать один раз как модуль, а приложение будет работать с ней через привычный протокол Redis.\n\n## Ограничения и осторожность\n\nВажно помнить:\n\n- модули работают внутри процесса Redis, любые ошибки или утечки в них могут уронить весь сервер;\n- обновление модулей требует аккуратного тестирования и контроля версии Redis;\n- не все хостинги и облачные сервисы позволяют загружать кастомные модули.\n\nПрактические рекомендации:\n\n- использовать только зрелые и поддерживаемые модули в продакшене;\n- проверять совместимость версии Redis и модуля;\n- отделять инстансы с модулями от тех, где нужен «чистый» Redis под кэш и быстрые ключи.\n\n## Итог\n\n**Модули Redis** позволяют расширять сервер новыми типами данных и командами, не меняя сам Redis и не переписывая приложение на низком уровне.\n\nЕсли аккуратно выбирать модули и отделять экспериментальные вещи от критичных инстансов, можно сильно обогатить возможности Redis, сохраняя при этом его скорость и простоту работы.\n\n\n"
    },
    {
      "title": "RedisJSON, RedisSearch, RedisGraph",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "advanced",
      "sectionTitle": "Продвинутые темы",
      "sectionOrder": 12,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "advanced",
        "slug": "04-redisjson-search-graph",
        "lang": "ru"
      },
      "path": "/content/materials/redis/advanced/04-redisjson-search-graph.ru.md",
      "content": "\nОтдельные модули **RedisJSON**, **RedisSearch** и **RedisGraph** превращают Redis в гораздо более универсальный инструмент: можно хранить и индексировать JSON‑документы, делать полнотекстовый поиск и строить графовые модели прямо поверх Redis.\n\nИх объединяет общий принцип: сложные структуры и запросы живут ближе к памяти, а приложение общается с ними через знакомый протокол Redis.\n\n## RedisJSON — работа с JSON-объектами\n\n**RedisJSON** добавляет полноценное хранение JSON‑документов с возможностью изменять отдельные поля без перезаписи всей строки.\n\nПример записи профиля пользователя:\n\n```\nJSON.SET user:42 $ '{\"name\":\"Alice\",\"age\":30,\"tags\":[\"dev\",\"redis\"]}'\n```\n\nЧтение всего объекта:\n\n```\nJSON.GET user:42\n```\n\nИзменение одного поля:\n\n```\nJSON.SET user:42 $.age 31\n```\n\nПолучение только нужного фрагмента:\n\n```\nJSON.GET user:42 $.tags\n```\n\nТакой подход удобен, когда:\n\n- данные естественно выглядят как JSON;\n- часто нужно менять отдельные поля;\n- важно не гонять лишние байты между приложением и Redis.\n\n## RedisSearch — индексы и поиск\n\n**RedisSearch** (часто под именем RediSearch) добавляет полнотекстовый поиск, индексы и сложные запросы по данным в Redis.\n\nПример создания индекса по JSON‑документам профилей:\n\n```\nFT.CREATE idx:users ON JSON PREFIX 1 user: SCHEMA $.name AS name TEXT $.age AS age NUMERIC\n```\n\nДобавление данных уже рассмотрено в RedisJSON. Теперь можно искать:\n\n```\nFT.SEARCH idx:users \"@name:Alice\"\nFT.SEARCH idx:users \"@age:[25 35]\"\n```\n\nRedisSearch сам ведёт индекс и позволяет:\n\n- делать фильтрацию по полям;\n- добавлять сортировку и пагинацию;\n- строить сложные запросы над данными, уже лежащими в Redis.\n\nЭто удобно, когда нужно быстрый поиск по профилям, товарам или логам без отдельной поисковой системы.\n\n## RedisGraph — графовые данные\n\n**RedisGraph** добавляет графовую модель: вершины, рёбра и запросы в стиле Cypher.\n\nПример создания простого графа:\n\n```\nGRAPH.QUERY social \"\n  CREATE (:User {id: 1, name: 'Alice'})-[:FOLLOWS]->(:User {id: 2, name: 'Bob'})\n\"\n```\n\nЗапрос друзей:\n\n```\nGRAPH.QUERY social \"\n  MATCH (u:User {id: 1})-[:FOLLOWS]->(f:User)\n  RETURN f.name\n\"\n```\n\nТакой подход подходит для:\n\n- социальных графов;\n- рекомендательных систем;\n- задач, где важны связи и пути между сущностями.\n\n## Итог\n\nМодули **RedisJSON**, **RedisSearch** и **RedisGraph** расширяют Redis за пределы классического «ключ–значение»: позволяют работать с JSON‑документами, делать быстрый поиск и строить графовые запросы прямо в памяти.\n\nЕсли проекту нужны такие возможности, а Redis уже используется как базовая инфраструктура, эти модули позволяют обойтись без отдельных специализированных систем, сохранив при этом высокую скорость.\n\n\n"
    },
    {
      "title": "Базовые паттерны работы клиента с Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "clients",
      "sectionTitle": "Клиенты и работа из приложений",
      "sectionOrder": 13,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "clients",
        "slug": "01-client-patterns",
        "lang": "ru"
      },
      "path": "/content/materials/redis/clients/01-client-patterns.ru.md",
      "content": "\nRedis сам по себе всего лишь сервер, который принимает команды. В реальных приложениях к нему всегда ходит клиентская библиотека: для Node.js, Python, Go, Java и так далее. От того, как выстроена эта обвязка, часто зависит не меньше, чем от конфигурации самого Redis.\n\nРазберём базовые паттерны, которые полезно закладывать в любой код, работающий с Redis.\n\n## Долгоживущие подключения вместо «подключиться–сделать–закрыть»\n\nRedis хорошо работает с постоянными TCP‑соединениями. Открывать и закрывать сокет на каждый запрос — лишняя нагрузка и лишние задержки.\n\nТипичная ошибка:\n\n1. Подключиться к Redis.\n2. Выполнить одну команду.\n3. Закрыть подключение.\n\nЛучше:\n\n- создать клиент один раз при старте приложения;\n- переиспользовать подключение для всех запросов;\n- закрывать соединение только при остановке сервиса.\n\nВ большинстве библиотек это выглядит как создание одного экземпляра клиента и его шаринг по всему приложению.\n\n## Локальный слой обёрток над Redis\n\nВместо того чтобы разбрасывать по коду сырые команды, полезно завести тонкий сервис, который:\n\n- знает схему ключей;\n- инкапсулирует логику кэша и TTL;\n- прячет детали клиента.\n\nПримеры логических методов:\n\n- сохранить сессию пользователя;\n- получить кэш страницы;\n- увеличить счётчик метрики.\n\nТакая обёртка помогает:\n\n- менять схему ключей без переписывания всего приложения;\n- централизованно настраивать время жизни, сериализацию и обработку ошибок;\n- упростить тестирование, подменяя реализацию на фейковую.\n\n## Явная схема ключей в одном месте\n\nСхема ключей Redis часто растёт стихийно. Лучше сразу описать её явно в одном модуле.\n\nПримеры шаблонов:\n\n- **user:ID** для данных пользователя;\n- **session:token:...** для сессий;\n- **cache:...** для кэша;\n- **metrics:...** для метрик.\n\nВ коде приложения удобно иметь функции‑генераторы:\n\n```\nuserKey(42)          -> \"user:42\"\nsessionTokenKey(t)   -> \"session:token:abcd\"\ncacheArticleKey(10)  -> \"cache:article:10\"\n```\n\nТак меньше риск опечаток, а миграция схемы ключей сводится к изменению этих функций.\n\n## Баланс ответственности между Redis и БД\n\nRedis часто используется вместе с основной базой данных. Важно чётко понимать, за что отвечает каждый слой.\n\nТипичный паттерн:\n\n- основная БД — источник правды (постоянные данные, транзакции, сложные запросы);\n- Redis — быстрый кэш, счётчики, очереди, временные структуры.\n\nПоследствия:\n\n- при ошибке Redis приложение по возможности должно уметь обратиться к БД напрямую;\n- логика согласованности данных должна быть в приложении, а не в надежде «Redis сам разберётся».\n\n## Итог\n\nБазовый уровень работы с Redis в приложении — это один или несколько долгоживущих клиентов, тонкий слой обёртки вокруг команд и явная схема ключей в одном месте.\n\nЕсли сразу разделить ответственность между Redis и основной БД и не пускать сырые команды по всему коду, дальнейшая эволюция и отладка приложения становятся намного проще.\n\n\n"
    },
    {
      "title": "Подключения, пулы и таймауты",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "clients",
      "sectionTitle": "Клиенты и работа из приложений",
      "sectionOrder": 13,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "clients",
        "slug": "02-connections-pools-timeouts",
        "lang": "ru"
      },
      "path": "/content/materials/redis/clients/02-connections-pools-timeouts.ru.md",
      "content": "\nПодключение к Redis — дешёвая операция по сравнению с классическими базами, но даже его можно использовать неправильно. Чрезмерное количество соединений, отсутствие таймаутов и большие очереди запросов легко превращают быстрый Redis в узкое место.\n\nРазберём практичные настройки подключений, пулов и таймаутов, которые стоит закладывать по умолчанию.\n\n## Сколько соединений нужно приложению\n\nВ простом сервисе часто достаточно одного подключения на процесс или на инстанс приложения. При высокой конкуренции и блокирующих командах может понадобиться несколько соединений или пул.\n\nОриентиры:\n\n- небольшое веб‑приложение — один клиент на процесс;\n- высоконагруженный сервис — пул из нескольких соединений;\n- фоновые воркеры — отдельное подключение для каждого воркера или батча задач.\n\nВажно не плодить тысячи соединений без нужды: Redis хорошо работает с сотнями клиентов, но чрезмерное количество TCP‑сессий увеличивает накладные расходы и сложнее диагностируется.\n\n## Пулы соединений\n\nПул — это набор заранее открытых соединений, которые приложение переиспользует между запросами.\n\nПреимущества:\n\n- нет задержек на установку TCP‑сессии;\n- можно ограничить максимальное число параллельных запросов;\n- проще контролировать нагрузку на Redis.\n\nПрактические рекомендации:\n\n- задавать разумный минимум и максимум соединений в пуле;\n- следить за метриками: сколько времени запрос ждёт свободное соединение;\n- не забывать корректно закрывать пул при остановке приложения.\n\nЕсли библиотека по умолчанию открывает новые подключения без ограничений, лучше явно включить режим пула.\n\n## Таймауты подключений и команд\n\nРабота без таймаутов — прямой путь к «висящим» запросам и забитым потокам приложения.\n\nНужны два вида таймаутов:\n\n- на установку соединения;\n- на выполнение команды.\n\nОриентировочные значения:\n\n- connect timeout — десятки или сотни миллисекунд для внутренней сети;\n- command timeout — от нескольких миллисекунд до пары секунд, в зависимости от операции.\n\nПри превышении таймаута:\n\n- запрос должен завершаться ошибкой;\n- приложение должно уметь решить, повторять ли его или деградировать.\n\n## Ограничение очередей и защита от перегрузки\n\nЕсли приложение генерирует запросы быстрее, чем Redis успевает их обрабатывать, соединения и пулы начинают накапливать очереди команд.\n\nПризнаки:\n\n- растущее время ответа при неизменной нагрузке;\n- длинные очереди в клиентской библиотеке;\n- повышенный instantaneous_ops_per_sec и задержки.\n\nПрактичные меры:\n\n- ограничить размер очереди запросов на клиента;\n- при переполнении — возвращать ошибку вверх по стеку;\n- включить backpressure: замедлять источники нагрузки или временно отказывать.\n\nЛучше честно вернуть пользователю ошибку, чем позволить сервису повиснуть из‑за бесконтрольной очереди к Redis.\n\n## Итог\n\nГрамотная работа с подключениями к **Redis** — это небольшое число долгоживущих соединений, аккуратный пул, чёткие таймауты и ограничения на очереди запросов.\n\nЕсли настроить это один раз в клиентской обёртке, большинство проблем с «зависшими» запросами и неожиданными перегрузками Redis исчезнут ещё до того, как попадут в продакшен.\n\n\n"
    },
    {
      "title": "Ошибки, ретраи и деградация при сбоях Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "clients",
      "sectionTitle": "Клиенты и работа из приложений",
      "sectionOrder": 13,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "clients",
        "slug": "03-errors-retries-degradation",
        "lang": "ru"
      },
      "path": "/content/materials/redis/clients/03-errors-retries-degradation.ru.md",
      "content": "\nRedis обычно работает стабильно, но сеть, диски и люди иногда ломаются. Важно заранее решить, что делает приложение, если Redis внезапно недоступен: бесконечно ретраит, сразу падает с ошибкой или аккуратно деградирует.\n\nГрамотная обработка ошибок часто важнее, чем сама конфигурация Redis.\n\n## Какие ошибки бывают на стороне клиента\n\nЧаще всего встречаются:\n\n- ошибка подключения (сервер недоступен, таймаут при connect);\n- таймаут команды (сервер не ответил за отведённое время);\n- протокольные ошибки (редко, обычно при баге в клиенте или модуле);\n- логические ошибки Redis (например, операция над неправильным типом ключа).\n\nПриложение должно:\n\n- различать сетевые/инфраструктурные проблемы и ошибки логики;\n- логировать и метриковать оба типа по‑разному;\n- не глушить исключения молча.\n\n## Когда стоит делать ретраи\n\nРетраи уместны для кратковременных сбоев сети и перегрузки, но легко превратить их в «шторм», когда каждый сервис ещё сильнее давит на Redis.\n\nПрактичные правила:\n\n- ретраить только операции, которые безопасны при повторе (идемпотентные);\n- ставить ограничение по числу попыток (2–3, а не бесконечно);\n- использовать экспоненциальную паузу между попытками.\n\nНапример, для чтения кэша:\n\n- одна повторная попытка через короткую задержку;\n- при повторной неудаче — пропускаем кэш и идём в основное хранилище либо возвращаем упрощённый ответ.\n\nДля записи логов и метрик иногда проще не ретраить вовсе, чтобы не создавать дополнительную нагрузку.\n\n## Деградация: когда Redis не критичен\n\nВо многих системах Redis используется как кэш или вспомогательное хранилище. В таких случаях важнее, чтобы пользователь получил хоть какой‑то ответ, чем чтобы кэш отработал идеально.\n\nПримеры деградации:\n\n- при ошибке чтения кэша страницы — собрать ответ без кэша, пусть медленнее;\n- при недоступности Redis для логов — временно писать меньше метрик;\n- при падении кэша рекомендаций — показать дефолтный список или ничего не показывать.\n\nХорошо, когда в коде есть явное разделение:\n\n- операции, без которых сервис не может работать;\n- операции, которые можно пропустить или упростить при сбое Redis.\n\n## Когда лучше сразу падать с ошибкой\n\nЕсли Redis — часть критичной бизнес‑логики (например, хранит заказы или сессии авторизации в единственном экземпляре), попытка «как‑нибудь продолжить» может только усугубить ситуацию.\n\nВ таких случаях:\n\n- лучше быстро и явно вернуть пользователю ошибку;\n- сработает алертинг, команда поймёт масштаб проблемы;\n- не появится скрытых несогласованных состояний.\n\nВажно заранее задокументировать, какие операции относятся к этой категории, и не пытаться чинить их ретраями без изменения архитектуры.\n\n## Итог\n\nОбработка ошибок при работе с **Redis** — это выбор между ретраями, деградацией и явным отказом, в зависимости от того, насколько критична операция.\n\nЕсли отделить сетевые сбои от логических ошибок, ретраить только безопасные вызовы и честно признавать фатальные ситуации, приложение станет предсказуемым и устойчивым даже при временных проблемах с Redis.\n\n\n"
    },
    {
      "title": "Идемпотентность и безопасные операции при повторах",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "clients",
      "sectionTitle": "Клиенты и работа из приложений",
      "sectionOrder": 13,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "clients",
        "slug": "04-idempotency-and-safety",
        "lang": "ru"
      },
      "path": "/content/materials/redis/clients/04-idempotency-and-safety.ru.md",
      "content": "\nКогда появляются ретраи, сетевые сбои и сложная логика, легко дважды выполнить одну и ту же операцию. Если команда не идемпотентна, это приводит к удвоенным списаниям, дубликатам задач или странным состояниям в очередях.\n\nИдемпотентность — это свойство операции давать тот же результат при повторном выполнении. В связке с Redis это можно и нужно использовать осознанно.\n\n## Простейшие идемпотентные операции\n\nМногие команды Redis по сути уже идемпотентны:\n\n- SET с одним и тем же значением для ключа;\n- EXPIRE и PEXPIRE с одинаковым временем;\n- записи, где значение полностью определено содержимым команды.\n\nПример:\n\n```\nSET user:42:name \"Alice\"\nSET user:42:name \"Alice\"\n```\n\nПовтор второй команды не меняет состояние. Если операция реализована именно как установка значения, а не как сложная последовательность шагов, ретраи становятся безопаснее.\n\n## Использование SETNX и атомарных операций\n\nДля сценариев «сделать что‑то один раз» помогают команды **SETNX** и атомарные инкременты.\n\nПример: один раз выполнить инициализацию для пользователя.\n\n```\nSETNX user:42:initialized 1\n```\n\nЕсли ключ уже существует, команда вернёт 0, и повторный вызов не изменит состояние. Аналогично, атомарные операции вроде INCR и HINCRBY гарантируют корректный результат даже при параллельных вызовах.\n\n## Идемпотентность на уровне бизнес‑идентификаторов\n\nЧасто удобнее считать идемпотентной не отдельную команду Redis, а всю бизнес‑операцию с собственным идентификатором.\n\nПример: обработка платежа с идентификатором операции.\n\nШаги:\n\n1. До начала логики проверить, обрабатывался ли уже этот **payment_id**.\n2. Если да — просто вернуть сохранённый результат.\n3. Если нет — выполнить бизнес‑логику и пометить операцию как завершённую.\n\nХранение статуса:\n\n```\nSETNX payment:op:12345 \"processed\"\n```\n\nЕсли SETNX вернул 1, мы считаем, что именно этот инстанс сервиса «выиграл гонку» и будет обрабатывать операцию. Остальные при повторе увидят, что статус уже есть.\n\n## Lua-скрипты для сложных идемпотентных операций\n\nКогда нужно сделать несколько шагов атомарно и при этом сохранить идемпотентность, выручает Lua.\n\nИдея:\n\n- перед выполнением основной логики проверить специальный ключ с идентификатором операции;\n- если ключ уже существует — вернуть сохранённый результат или код;\n- если нет — выполнить логику и записать маркер выполнения.\n\nПростейший шаблон:\n\n```\nEVAL \"\n  local status = redis.call('GET', KEYS[1])\n  if status then\n    return status\n  end\n  redis.call('SET', KEYS[1], ARGV[1])\n  return ARGV[1]\n\" 1 op:12345 \"done\"\n```\n\nОдин и тот же скрипт можно безопасно вызывать несколько раз — результат будет предсказуемым.\n\n## Итог\n\nИдемпотентность в связке с **Redis** достигается за счёт простых и атомарных команд, аккуратного использования SETNX и INCR, а при необходимости — Lua‑скриптов, которые проверяют и помечают выполнение операций.\n\nЕсли проектировать ключи и операции так, чтобы повторный вызов не ломал данные, можно смело использовать ретраи и не бояться случайных дубликатов и двойных списаний.\n\n\n"
    },
    {
      "title": "Структуры данных в Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "data",
      "sectionTitle": "Структуры данных",
      "sectionOrder": 2,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "data",
        "slug": "01-data-structures",
        "lang": "ru"
      },
      "path": "/content/materials/redis/data/01-data-structures.ru.md",
      "content": "\n**Redis** — это не просто хранилище строк. Его особенность в том, что данные могут быть представлены разными структурами, и каждая из них подходит под определённые задачи. В отличие от обычной базы данных, где обычно работают с таблицами и строками, здесь используются более простые и быстрые модели: списки, наборы, хеши, упорядоченные коллекции и потоки. Благодаря этому многие задачи решаются естественно и без сложных запросов.\n\n## Строки\n\n**Строка** — самая базовая форма данных. Это просто значение, связанное с ключом. Внутри строки может лежать что угодно: текст, число, JSON в виде текста. Такой тип чаще всего используют там, где нужно хранить простые значения — например, токен, число, небольшую структуру или результат вычисления.\n\n**Пример данных:**  \n\"hello world\"\n\n**Пример команды:**  \n```\nSET message \"hello world\"\n```\n\n**Когда использовать:**  \nКогда нужно хранить простое значение: текст, число, флаг, токен, JSON в виде строки.\n\n## Хеши\n\n**Хеш** похож на маленький объект или словарь. У одного ключа Redis может быть несколько полей, у каждого — своё значение. Это удобный вариант, когда нужно хранить сущность с несколькими свойствами: профиль пользователя, настройки, краткую информацию о товаре. Хеши позволяют получать или менять отдельные поля без перезаписи всей структуры.\n\n**Пример данных:**  \n{a: \"hello\", b: \"world\"}\n\n**Пример команды:**  \n```\nHSET user name \"Alice\" age 25\n```\n\n**Когда использовать:**  \nКогда требуется небольшая сущность с несколькими полями, обновляемыми отдельно.\n\n## Списки\n\n**Списки** ведут себя как обычная очередь или стек. В начало и конец можно быстро добавлять элементы, извлекать их, просматривать нужные участки. Это хорошее решение для задач, где важен порядок: хранение последних действий пользователя, формирование очередей задач, временные журналы событий.\n\n**Пример данных:**  \n[A > B > C]\n\n**Пример команды:**  \n```\nLPUSH logs \"event1\"\n```\n\n**Когда использовать:**  \nКогда важен порядок: очереди задач, последние записи, журналы действий.\n\n## Множества\n\n**Множество** — коллекция уникальных значений. Здесь нельзя хранить дубликаты, и порядок элементов не важен. Такой тип помогает решать задачи вроде хранения уникальных ID, отслеживания пользователей, которые выполнили действие, или быстрого определения, находится ли элемент в наборе.\n\n**Пример данных:**  \n{A, B, C}\n\n**Пример команды:**  \n```\nSADD online_users \"user1\"\n```\n\n**Когда использовать:**  \nКогда нужен набор уникальных значений без повторов.\n\n## Упорядоченные множества\n\n**Упорядоченные множества** отличаются от обычных тем, что каждый элемент имеет числовой «вес», по которому Redis сортирует коллекцию. Этот тип хорошо подходит для рейтингов, лидбордов, статистики, где важно быстро узнать позиции элементов или взять часть списка по определённому диапазону.\n\n**Пример данных:**  \n{A:1, B:2, C:3}\n\n**Пример команды:**  \n```\nZADD rating 100 \"player1\"\n```\n\n**Когда использовать:**  \nКогда нужен рейтинг, сортировка или выборка по диапазону числовых значений.\n\n## Bitmaps\n\n**Bitmaps** позволяют хранить и изменять данные на уровне отдельных битов. Это даёт возможность создавать компактные структуры для отметок присутствия/отсутствия. Часто используется в аналитике, когда нужно отслеживать активность пользователей по дням или отмечать события в большом массиве данных без большого расхода памяти.\n\n**Пример данных:**  \n01101101 01101111 01101101\n\n**Пример команды:**  \n```\nSETBIT days 5 1\n```\n\n**Когда использовать:**  \nКогда нужно отмечать состояния по битам: активности по дням, флаги, быстрые отметки.\n\n## HyperLogLog\n\n**HyperLogLog** — структура для приближённого подсчёта количества уникальных значений. Она не хранит сами элементы, зато позволяет оценить, сколько уникальных записей прошло через систему. Подходит для огромных массивов данных, где точность важна меньше, чем компактность и скорость (например, количество уникальных посетителей).\n\n**Пример данных:**  \n010110101 011011111 01101101\n\n**Пример команды:**  \n```\nPFADD visitors \"user123\"\n```\n\n**Когда использовать:**  \nКогда требуется приблизительно посчитать количество уникальных значений в большом потоке данных.\n\n## Streams\n\n**Streams** — структура для обработки последовательных событий. Каждый элемент имеет автоинкрементный идентификатор и набор полей. Это природный способ создавать очереди событий, собирать логи, обмениваться сообщениями между сервисами. В отличие от списков, потоки умеют работать с группами потребителей и гарантируют доставку данных тем, кто их обрабатывает.\n\n**Пример данных:**  \n{id1 = time.seq { a: \"foo\", b: \"bar\" }}\n\n**Пример команды:**  \n```\nXADD mystream * message \"hello\"\n```\n\n**Когда использовать:**  \nКогда нужно работать с последовательными событиями, логами или очередями с группами потребителей.\n\n## Зачем столько типов?\n\n**Каждая структура** существует не ради разнообразия, а чтобы решать конкретные задачи максимально быстро. Где-то важен порядок, где-то уникальность, где-то возможность работать с огромными потоками данных без потери производительности. Понимание различий помогает выбирать правильный инструмент и строить более эффективные решения.\n\n**Redis выигрывает именно за счёт того, что позволяет использовать разные структуры там, где они логичнее и быстрее всего.**\n"
    },
    {
      "title": "Основные операции",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "data",
      "sectionTitle": "Структуры данных",
      "sectionOrder": 2,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "data",
        "slug": "02-basic-operations",
        "lang": "ru"
      },
      "path": "/content/materials/redis/data/02-basic-operations.ru.md",
      "content": "\n**Основные операции** в Redis сводятся к простым и быстрым действиям над ключами и значениями. Большинство команд работает мгновенно, потому что сервер обрабатывает данные в оперативной памяти. Ниже — самые важные операции, которые используются практически в любом проекте.\n\n## Установка и получение значений\n\n```\nSET message \"hello\"\nGET message\n```\n\nКоманда **SET** создаёт или обновляет значение по ключу, а **GET** возвращает его. Это самый распространённый способ работы со строками.\n\n## Проверка существования ключа\n\n```\nEXISTS message\n```\n\nКоманда **EXISTS** возвращает 1, если ключ существует, и 0, если нет.\n\n## Удаление данных\n\n```\nDEL message\n```\n\nКоманда **DEL** удаляет ключ и его значение.\n\n## Инкремент и декремент\n\nЕсли значение является числом, его можно увеличивать и уменьшать:\n\n```\nINCR counter\nDECR counter\n```\n\nКоманды **INCR** и **DECR** особенно удобны для счётчиков кликов, лайков и просмотров.\n\n## Работа со списками\n\n```\nLPUSH logs \"event1\"\nRPUSH logs \"event2\"\nLPOP logs\nRPOP logs\n```\n\nДобавление через **LPUSH** и **RPUSH** происходит слева или справа, и извлечение через **LPOP** и **RPOP** — тоже. Со списками часто строят очереди.\n\n## Работа с множествами\n\n```\nSADD users \"alice\"\nSADD users \"bob\"\nSMEMBERS users\n```\n\nМножество хранит только уникальные значения, и команда **SMEMBERS** возвращает весь набор.\n\n## Работа с хешами\n\n```\nHSET user name \"Alice\"\nHSET user age 25\nHGET user name\n```\n\nХеши удобно использовать для сущностей с несколькими полями, которые удобно заполнять через **HSET** и читать через **HGET**.\n\n## Упорядоченные множества\n\n```\nZADD rating 100 \"player1\"\nZADD rating 150 \"player2\"\nZRANGE rating 0 -1 WITHSCORES\n```\n\nКоманда **ZADD** добавляет элементы с «весом», а **ZRANGE** помогает их читать в нужном порядке. Подходит для рейтингов и систем, где важна сортировка по числовому значению.\n\n## Работа с потоками\n\n```\nXADD mystream * message \"hello\"\nXREAD COUNT 1 STREAMS mystream 0\n```\n\nПотоки через **XADD** и **XREAD** используются для событий, логов и очередей с высокой нагрузкой.\n\n**Эти команды — фундамент работы с Redis.** Освоив их, можно уверенно двигаться дальше и использовать более сложные механизмы и структуры.\n"
    },
    {
      "title": "TTL и управление временем жизни ключей",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "data",
      "sectionTitle": "Структуры данных",
      "sectionOrder": 2,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "data",
        "slug": "03-ttl-and-key-expiration",
        "lang": "ru"
      },
      "path": "/content/materials/redis/data/03-ttl-and-key-expiration.ru.md",
      "content": "\n**TTL** позволяет сделать ключи «временными». По умолчанию данные в Redis живут вечно, пока их явно не удалить. Время жизни ключа задаётся отдельно и измеряется в секундах или миллисекундах.\n\n## Основная идея\n\nМожно записать значение, дать ему срок жизни и не думать о ручной очистке. После истечения срока Redis удалит ключ сам. Это удобно для кэша, сессий, одноразовых кодов и временных флагов.\n\n**Простейший пример:**\n\n```\nSET session:123 \"user data\"\nEXPIRE session:123 60\n```\n\nКлюч session:123 будет жить 60 секунд, потом исчезнет.\n\n**Проверка оставшегося времени:**\n\n```\nTTL session:123\n```\n\nЕсли ключ ещё жив, возвращается число секунд. Возможны специальные значения:\n- **-1** — у ключа нет срока жизни;\n- **-2** — ключ уже не существует.\n\n## Запись сразу с временем жизни\n\nМожно не вызывать EXPIRE отдельно, а задать срок прямо при записи.\n\n**SETEX — запись сразу с временем жизни (в секундах):**\n\n```\nSETEX cache:user:1 300 \"{\\\"name\\\":\\\"Alice\\\"}\"\n```\n\nКлюч cache:user:1 будет автоматически удалён через 300 секунд.\n\n**PSETEX — вариант с миллисекундами:**\n\n```\nPSETEX cache:page:1 1500 \"html...\"\n```\n\n## Снятие срока жизни\n\n**PERSIST — сделать ключ снова постоянным:**\n\n```\nPERSIST session:123\n```\n\nПосле этого у ключа больше нет таймера удаления.\n\nВажно помнить: если перезаписать значение, TTL сбрасывается. Новое значение будет без срока жизни, пока его не задать заново.\n\n## Поведение при истечении\n\nRedis не удаляет ключи строго в ту же миллисекунду, когда истечёт время. Он периодически проверяет истекающие ключи и дополнительно удаляет их при обращении. Для приложения это выглядит так, будто ключ просто перестал существовать:\n\n```\nGET session:123     # до истечения\n# \"user data\"\n\n# проходит время\n\nGET session:123     # после истечения\n# (nil)\n```\n\n## Практические случаи\n\n**Кэш.** Хранить результат тяжёлого запроса несколько секунд или минут.\n\n```\nSETEX cache:popular:posts 60 \"...\"\n```\n\n**Сессии.** Хранить данные пользователя, пока он активен.\n\n```\nSET session:456 \"data\"\nEXPIRE session:456 1800\n```\n\n**Одноразовые коды и токены.** Срок действия задаётся сразу и не требует ручной очистки.\n\nГрамотная работа с TTL помогает не захламлять память Redis и автоматически удалять ненужные данные.\n\n## Итого по TTL и командам\n\nTTL делает ключи временными и позволяет не заниматься ручной очисткой. У каждого ключа может быть свой срок жизни: его можно задать при записи, изменить, снять или проверить.\n\nКоманды, которые важно знать:\n\n- **EXPIRE key seconds** — установить время жизни в секундах.\n- **PEXPIRE key milliseconds** — то же самое, но в миллисекундах.\n- **EXPIREAT key timestamp** — истечение по Unix-времени в секундах.\n- **PEXPIREAT key milliseconds-timestamp** — истечение по Unix-времени в миллисекундах.\n- **TTL key** — показать оставшееся время жизни в секундах.\n- **PTTL key** — показать оставшееся время жизни в миллисекундах.\n- **SETEX key seconds value** — записать значение и сразу задать срок жизни.\n- **PSETEX key milliseconds value** — вариант с миллисекундами.\n- **PERSIST key** — убрать время жизни и сделать ключ постоянным.\n\nПонимая, как работают эти команды, можно строить кэш, сессии, временные токены и любые другие механизмы, которые должны исчезать сами через заданный промежуток времени.\n"
    },
    {
      "title": "Работа с ключами и пространством имен",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "data",
      "sectionTitle": "Структуры данных",
      "sectionOrder": 2,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "data",
        "slug": "04-keys-and-namespaces",
        "lang": "ru"
      },
      "path": "/content/materials/redis/data/04-keys-and-namespaces.ru.md",
      "content": "\nРабота с ключами в Redis важна не меньше, чем выбор структуры данных. От того, как называются ключи, зависит удобство отладки, простота поиска и риск случайно удалить или перезаписать чужие данные.\n\n## Что такое ключ в Redis\n\nКлюч в Redis — это строка, по которой сервер находит значение. В одном экземпляре Redis все ключи лежат в общем пространстве. Никаких таблиц или схем, как в классических базах, здесь нет.\n\nПростейший пример записи значения по ключу:\n\n```\nSET user:1 \"Alice\"\nGET user:1\n```\n\nКлючи могут быть любыми строками, но на практике используют понятные имена, которые отражают назначение данных.\n\n## Пространства имён через разделитель\n\nТак как формальных схем нет, пространство имён организуют самим названием ключа. Часто используют двоеточие как разделитель.\n\nПример ключей для пользователей:\n\n```\nSET user:1:name \"Alice\"\nSET user:1:email \"alice@example.com\"\nSET user:2:name \"Bob\"\n```\n\nЗдесь user — логическая группа, число после двоеточия — идентификатор, а последнее слово — поле или тип данных.\n\nЕщё один пример для сессий и кэша:\n\n```\nSET session:token:abc123 \"user:1\"\nSET cache:article:42 \"html...\"\n```\n\nТакой подход помогает:\n\n**Визуально группировать данные.** По ключу сразу видно, к чему относится запись.\n\n**Избегать конфликтов.** Ключи разных подсистем не пересекаются: session:..., cache:..., user:....\n\n**Удобно искать и чистить.** Можно выбрать группу ключей по шаблону.\n\n## Поиск и обход ключей\n\nДля поиска ключей по шаблону есть несколько команд. В учебных примерах часто используют KEYS, но в реальных проектах её лучше избегать: она может блокировать сервер, если ключей много.\n\nПример KEYS для понимания работы шаблонов:\n\n```\nKEYS user:*\n```\n\nБолее безопасный вариант для продакшена — команда SCAN. Она обходит ключи постепенно и не блокирует сервер.\n\nПример выборки сессий по шаблону:\n\n```\nSCAN 0 MATCH session:* COUNT 100\n```\n\nКлиент вызывает SCAN несколько раз, пока не обойдёт все подходящие ключи.\n\n## Тип ключа и удаление\n\nИногда важно понять, какое значение лежит по ключу. Для этого есть команда TYPE.\n\n```\nTYPE user:1\n```\n\nОтвет покажет тип: string, hash, list, set и так далее.\n\nУдалить ключ можно простой командой:\n\n```\nDEL user:1\n```\n\nЕсли ключ крупный и его много, иногда используют UNLINK. Эта команда помечает данные на удаление и возвращается быстрее, чем DEL.\n\n```\nUNLINK big:list\n```\n\nКакую бы команду ни использовать, важно аккуратно выбирать ключи. Ошибка в шаблоне или названии может удалить лишние данные.\n\n## Практические схемы именования\n\nНесколько типичных вариантов, которые хорошо приживаются в проектах.\n\nПользователи:\n\n```\nuser:42\nuser:42:name\nuser:42:settings\n```\n\nСессии и авторизация:\n\n```\nsession:token:abc123\nsession:user:42\n```\n\nКэш:\n\n```\ncache:article:10\ncache:profile:42\n```\n\nСчётчики и метрики:\n\n```\nmetrics:views:article:10\nmetrics:logins:2025-11-20\n```\n\nГлавная идея простая: один логический блок — один префикс. Так ключи остаются читаемыми, их легко искать и удалять по шаблону, а риск конфликтов между разными частями системы заметно снижается.\n"
    },
    {
      "title": "Redis Sentinel",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "ha-cluster",
      "sectionTitle": "Высокая доступность и кластеризация",
      "sectionOrder": 8,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "ha-cluster",
        "slug": "01-redis-sentinel",
        "lang": "ru"
      },
      "path": "/content/materials/redis/ha-cluster/01-redis-sentinel.ru.md",
      "content": "\n**Redis Sentinel** — это отдельный компонент, который следит за master и репликами, замечает сбои и при необходимости сам переключает роль на одну из реплик. Можно считать его «наблюдателем» и «аварийным переключателем» для Redis.\n\nГлавная цель Sentinel — убрать ручной failover и сделать так, чтобы приложение всегда знало, куда писать, даже если один из узлов упал.\n\n## Что делает Sentinel\n\nSentinel выполняет сразу несколько задач:\n\n- мониторит состояние master и replica;\n- решает, когда master считается недоступным;\n- выбирает подходящую реплику и продвигает её в новый master;\n- сообщает клиентам, где сейчас активный master.\n\nСписок наблюдаемых узлов и параметры порогов задаются в конфиге Sentinel.\n\n## Минимальная конфигурация Sentinel\n\nSentinel — это отдельный процесс Redis, запущенный в специальном режиме.\n\nПример простого конфига для одного мастера:\n\n```\nport 26379\n\nsentinel monitor mymaster 10.0.0.1 6379 2\nsentinel down-after-milliseconds mymaster 5000\nsentinel parallel-syncs mymaster 1\nsentinel failover-timeout mymaster 60000\n```\n\nЗдесь:\n\n- **mymaster** — имя наблюдаемого кластера Redis;\n- **10.0.0.1 6379** — адрес master;\n- **2** — сколько Sentinel должно согласиться, чтобы признать master мёртвым;\n- **down-after-milliseconds** — через сколько миллисекунд без ответа считать master недоступным;\n- **parallel-syncs** — сколько реплик можно одновременно пересинхронизировать после failover;\n- **failover-timeout** — окно времени, в котором должен уложиться процесс переключения.\n\nОбычно запускают минимум три экземпляра Sentinel, чтобы решения принимались большинством.\n\n## Как клиенты узнают о новом master\n\nSentinel сам меняет роли узлов, но приложение должно знать, куда теперь отправлять записи.\n\nЕсть два основных подхода:\n\n- клиенты, умеющие работать с Sentinel (драйверы для Redis), сами запрашивают у него адрес актуального master;\n- дополнительный слой (прокси, сервис‑дискавери) использует информацию Sentinel, чтобы отдавать клиентам правильный адрес.\n\nПример запроса из клиента к Sentinel для получения адреса master:\n\n```\nSENTINEL get-master-addr-by-name mymaster\n```\n\nОтветом будет текущий host и port активного master.\n\n## Итог\n\n**Redis Sentinel** добавляет к репликации слой наблюдения и автоматического переключения: он следит за узлами, решает, что master недоступен, и продвигает реплику в новую роль.\n\nПри правильно настроенных порогах и нескольких экземплярах Sentinel можно избавиться от ручного failover и сделать Redis заметно более устойчивым к сбоям отдельных серверов.\n\n\n"
    },
    {
      "title": "Автоматическое переключение",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "ha-cluster",
      "sectionTitle": "Высокая доступность и кластеризация",
      "sectionOrder": 8,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "ha-cluster",
        "slug": "02-automatic-failover",
        "lang": "ru"
      },
      "path": "/content/materials/redis/ha-cluster/02-automatic-failover.ru.md",
      "content": "\nАвтоматическое переключение (failover) в связке Redis + Sentinel означает, что при падении master система сама выбирает новую реплику и делает её основным узлом. Задача приложения — уметь быстро узнать новый адрес и продолжить работу без ручного вмешательства.\n\nРазберём, как выглядит процесс failover шаг за шагом и какие настройки влияют на его поведение.\n\n## Как Sentinel принимает решение о failover\n\nSentinel периодически пингует master и реплики. Когда master не отвечает дольше заданного порога, начинается процедура выбора нового master.\n\nКлючевые параметры:\n\n```\nsentinel down-after-milliseconds mymaster 5000\nsentinel failover-timeout mymaster 60000\nsentinel parallel-syncs mymaster 1\n```\n\nСмысл:\n\n- **down-after-milliseconds** — сколько миллисекунд без ответа считать master недоступным;\n- **failover-timeout** — общее окно для проведения failover;\n- **parallel-syncs** — сколько реплик можно одновременно пересинхронизировать с новым master.\n\nРешение о том, что master действительно мёртв (not reachable), принимается большинством Sentinel. Поэтому обычно поднимают минимум три экземпляра на разных серверах.\n\n## Процесс автоматического переключения\n\nКогда quorum Sentinel согласился, что master недоступен, начинается failover:\n\n1. Из доступных реплик выбирается кандидат в новый master (учитываются задержка, отставание, приоритет).\n2. Кандидату посылается команда стать самостоятельным master:\n\n```\nREPLICAOF NO ONE\n```\n\n3. Остальным репликам указывают новый master:\n\n```\nREPLICAOF <ip-нового-master> 6379\n```\n\n4. Информация о новом master публикуется через Sentinel, и клиенты, которые умеют с ним общаться, получают обновлённый адрес.\n\nВесь этот процесс занимает от нескольких секунд до десятков секунд, в зависимости от настроек и качества сети.\n\n## Как клиенты находят новый master\n\nКлиенты, поддерживающие Sentinel, обычно:\n\n1. Подключаются к набору Sentinel (например, по трём адресам).\n2. Запрашивают у него координаты master по имени:\n\n```\nSENTINEL get-master-addr-by-name mymaster\n```\n\n3. Подключаются к полученному адресу и используют его для команд записи.\n4. При ошибках подключения к Redis снова идут к Sentinel за обновлённым адресом.\n\nЕсли драйвер Redis в вашем языке не умеет работать с Sentinel, это можно обернуть отдельным слоем (прокси, сервис‑дискавери), который сам следит за Sentinel и отдаёт клиентам актуальный endpoint.\n\n## Типичные грабли при автоматическом переключении\n\nНа практике проблемы чаще всего связаны не с самим Sentinel, а с окружением:\n\n- слишком маленький **down-after-milliseconds** — частые ложные срабатывания при временных задержках сети;\n- клиенты закэшировали старый адрес master и не ходят к Sentinel за новым;\n- DNS или балансировщик не обновляют конфигурацию после failover;\n- реплики отстают слишком сильно, и новый master поднимается с устаревшими данными.\n\nПоэтому важно:\n\n- тестировать сценарии failover на тестовой среде;\n- проверять, как реальные клиенты узнают о новом master;\n- мониторить отставание реплик и время проведения failover.\n\n## Итог\n\nАвтоматическое переключение с помощью **Redis Sentinel** позволяет переживать падение master без ручного вмешательства: система сама выбирает реплику, продвигает её в master и перенастраивает остальные узлы.\n\nЕсли клиенты правильно интегрированы с Sentinel и настройки порогов подобраны под реальную сеть, Redis становится заметно устойчивее к сбоям отдельных серверов и кратковременным проблемам с инфраструктурой.\n\n\n"
    },
    {
      "title": "Redis Cluster",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "ha-cluster",
      "sectionTitle": "Высокая доступность и кластеризация",
      "sectionOrder": 8,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "ha-cluster",
        "slug": "03-redis-cluster",
        "lang": "ru"
      },
      "path": "/content/materials/redis/ha-cluster/03-redis-cluster.ru.md",
      "content": "\n**Redis Cluster** — это режим работы, в котором данные автоматически распределяются по нескольким узлам (шартам), а внутри каждого шарда всё ещё может быть master и реплики. Задача кластера — одновременно дать масштабирование по объёму данных и по нагрузке, сохраняя при этом отказоустойчивость.\n\nВ отличие от схемы «один master + несколько реплик», Redis Cluster умеет сам решать, на какой узел положить ключ, и как перенаправить клиента, если он обратился не туда.\n\n## Базовая идея кластера\n\nВ кластере Redis есть:\n\n- несколько master‑узлов, каждый хранит свою часть ключей;\n- опционально — реплики у каждого master для высокой доступности;\n- специальный механизм распределения ключей по **16384 слотам**.\n\nКаждый ключ попадает в один из 16384 хэш‑слотов по хешу:\n\n```\nhash_slot = CRC16(key) mod 16384\n```\n\nКаждый слот закреплён за конкретным master. Если мастер уходит из строя, и у него есть реплика, кластер может автоматически переключить слот на реплику.\n\n## Минимальная конфигурация кластера\n\nДля запуска кластера нужно несколько инстансов Redis с включённым режимом cluster.\n\nЧасть настроек в redis.conf:\n\n```\nport 6379\ncluster-enabled yes\ncluster-config-file nodes.conf\ncluster-node-timeout 5000\n```\n\nПосле запуска нескольких таких инстансов их объединяют в кластер с помощью утилиты:\n\n```\nredis-cli --cluster create \\\n  10.0.0.1:6379 10.0.0.2:6379 10.0.0.3:6379 \\\n  --cluster-replicas 1\n```\n\nФлаг **--cluster-replicas 1** говорит, что для каждого master будет создана одна реплика. В итоге получится набор мастер‑реплика пар, между которыми распределены все 16384 слота.\n\n## Маршрутизация запросов и редиректы\n\nКлиент кластера может попасть не на тот мастер, который хранит нужный ключ. В этом случае Redis отвечает редиректом:\n\n- **MOVED** — ключ живёт на другом узле, и этот слот уже закреплён за ним;\n- **ASK** — временный редирект во время переноса слотов между узлами.\n\nПример:\n\n```\nSET user:42 \"Alice\"\n```\n\nЕсли запрос пришёл не на тот узел, клиент получит ответ вида:\n\n```\nMOVED 12539 10.0.0.2:6379\n```\n\nДальше драйвер Redis, умеющий работать с кластером, сам перенаправит запрос на правильный узел и обновит у себя карту слотов.\n\n## Когда Redis Cluster уместен\n\nКластер имеет смысл, когда:\n\n- данных становится слишком много для одного сервера (по памяти или по диску);\n- нагрузка на один инстанс Redis превышает комфортный предел;\n- нужно горизонтально масштабировать чтение и запись по нескольким узлам.\n\nВажно помнить:\n\n- в режиме кластера не все команды доступны в прежнем виде (особенно мульти‑ключевые);\n- транзакции и Lua‑скрипты должны работать с ключами из одного слота;\n- есть свои особенности при миграции данных и смене топологии.\n\nДля сценариев, где достаточно одного узла с репликами, кластер может быть излишне сложным. Но для крупных систем с ростом данных это стандартный путь масштабирования Redis.\n\n## Итог\n\n**Redis Cluster** распределяет ключи по нескольким master‑узлам, добавляя к репликации автоматический шардинг и встроенный механизм отказоустойчивости.\n\nЕсли драйверы клиентов умеют работать с кластером, а ограничения по командам приняты в расчёт, кластер позволяет плавно наращивать объём данных и обрабатывать всё более высокую нагрузку без единой точки отказа.\n\n\n"
    },
    {
      "title": "Шардинг",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "ha-cluster",
      "sectionTitle": "Высокая доступность и кластеризация",
      "sectionOrder": 8,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "ha-cluster",
        "slug": "04-sharding",
        "lang": "ru"
      },
      "path": "/content/materials/redis/ha-cluster/04-sharding.ru.md",
      "content": "\n**Шардинг** в Redis — это разбиение ключей по нескольким узлам так, чтобы каждый узел хранил только часть данных. В режиме Redis Cluster шардинг встроен: кластер сам решает, на каком узле должен жить каждый ключ.\n\nЗадача разработчика — понимать, как работает распределение по слотам, и при необходимости управлять тем, какие ключи должны храниться вместе.\n\n## Хэш‑слоты и распределение ключей\n\nВ Redis Cluster пространство ключей разбито на **16384 хэш‑слота**. Каждый ключ попадает в один слот по формуле:\n\n```\nhash_slot = CRC16(key) mod 16384\n```\n\nКаждый мастер в кластере отвечает за подмножество этих слотов. При изменении топологии (добавление/удаление узлов) слоты могут мигрировать между мастерами.\n\nПосмотреть распределение слотов можно через:\n\n```\nCLUSTER SLOTS\n```\n\nОтвет покажет диапазоны слотов и узлы, за которые они отвечают.\n\n## Управление группами ключей через hash tags\n\nИногда нужно, чтобы несколько ключей гарантированно оказались на одном и том же узле — например, для транзакций, Lua‑скриптов или операций с несколькими ключами. Для этого используют **hash tags**.\n\nИдея простая: если в имени ключа есть фигурные скобки, для расчёта слота берётся только содержимое внутри скобок.\n\nПример:\n\n```\nSET user:{42}:profile \"{...}\"\nSET user:{42}:settings \"{...}\"\n```\n\nОба ключа попадут в один и тот же слот, потому что для хеша используется только подстрока **42**. Это позволяет безопасно использовать операции, которые требуют, чтобы все задействованные ключи были на одном мастере.\n\n## Добавление и удаление шардов\n\nКогда нагрузка растёт, в кластер можно добавить новые узлы и распределить слоты заново.\n\nПример добавления нового мастера:\n\n```\nredis-cli --cluster add-node 10.0.0.4:6379 10.0.0.1:6379\n```\n\nПосле этого слоты нужно перенести на новый узел:\n\n```\nredis-cli --cluster reshard 10.0.0.1:6379\n```\n\nИнтерактивно выбирается, сколько слотов и откуда переносить. Кластер во время миграции использует редиректы **ASK**, но для клиентов, поддерживающих Redis Cluster, этот процесс прозрачен.\n\nУдаление шардов работает похоже, только слоты сначала переносятся на другие мастера, а потом узел выбывает из кластера.\n\n## Классический client-side шардинг\n\nПомимо встроенного шардинга кластера, есть старый подход — **client-side шардинг**, когда приложение само решает, на какой Redis отправить ключ.\n\nПример идеи:\n\n- есть три инстанса Redis;\n- приложение считает хеш от ключа и по модулю количества инстансов выбирает нужный.\n\nТакой подход проще на старте, но:\n\n- не умеет автоматически перераспределять данные при изменении числа узлов;\n- не даёт встроенного failover;\n- требует много ручной работы при миграции.\n\nПоэтому для новых проектов чаще выбирают Redis Cluster, а client-side шардинг оставляют для специфических случаев.\n\n## Итог\n\nШардинг в **Redis Cluster** основан на 16384 хэш‑слотах, которые автоматически распределяются между мастер‑узлами и могут мигрировать при изменении топологии.\n\nИспользуя hash tags и штатные команды кластера для добавления и удаления узлов, можно контролировать, какие ключи лежат вместе, и плавно масштабировать систему, не переписывая логику приложения.\n\n\n"
    },
    {
      "title": "Масштабирование по нагрузке",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "ha-cluster",
      "sectionTitle": "Высокая доступность и кластеризация",
      "sectionOrder": 8,
      "order": 5,
      "id": {
        "category": "redis",
        "section": "ha-cluster",
        "slug": "05-scaling-and-load",
        "lang": "ru"
      },
      "path": "/content/materials/redis/ha-cluster/05-scaling-and-load.ru.md",
      "content": "\nRedis хорошо масштабируется вертикально (больше памяти и CPU на одном сервере), но в какой‑то момент этого становится мало. Тогда в игру вступают репликация, Sentinel и Redis Cluster — вместе они позволяют распределять нагрузку по нескольким узлам и переживать рост трафика.\n\nВажно понимать, какие рычаги масштабирования есть и как выбрать подходящий набор под конкретную систему.\n\n## Масштабирование чтения: реплики\n\nСамый простой шаг — разгрузить master, отправив часть чтений на реплики.\n\nПример идеи:\n\n- все записи идут на master;\n- часть чтений (например, отчёты, фоновые выборки) перенаправляется на replica.\n\nВыбор узла на стороне приложения:\n\n- для критичных к консистентности операций (балансы, заказы) читать только с master;\n- для менее критичных (отчёты, статистика, ленты новостей) — использовать реплики.\n\nРепликация настраивается так же, как в разделе про master–replica:\n\n```\nREPLICAOF 10.0.0.1 6379\n```\n\nТак можно постепенно добавлять новые реплики и горизонтально масштабировать чтение.\n\n## Масштабирование записи: кластер и шардинг\n\nЕсли упираемся уже не только в чтение, но и в запись, одного master становится мало. Здесь помогает Redis Cluster:\n\n- данные распределяются по нескольким master‑узлам;\n- каждый мастер обслуживает только свою часть ключей и нагрузку;\n- при необходимости каждому мастер‑узлу добавляются свои реплики.\n\nСоздание кластера:\n\n```\nredis-cli --cluster create \\\n  10.0.0.1:6379 10.0.0.2:6379 10.0.0.3:6379 \\\n  --cluster-replicas 1\n```\n\nДальше масштабирование сводится к добавлению новых шардов и перераспределению слотов. Клиенты, которые понимают Redis Cluster, автоматически разруливают маршрутизацию запросов.\n\n## Горизонтальное масштабирование с Sentinel\n\nSentinel сам по себе не масштабирует Redis по данным, но помогает масштабировать по доступности:\n\n- добавляем несколько master–replica пар для разных подсистем (кэш, сессии, очереди);\n- над каждой парой работает свой набор Sentinel;\n- клиенты знают только имена логических master и не привязаны к конкретным адресам.\n\nТак можно:\n\n- разделить нагрузку по функциям (один Redis под кэш, другой под сессии);\n- независимо масштабировать каждую часть;\n- при сбоях на уровне узла получать автоматический failover без даунтайма.\n\n## Выбор стратегии под задачу\n\nУсловно можно выделить несколько стадий развития:\n\n- один Redis‑узел с репликами для чтения — достаточно для большинства средних проектов;\n- несколько master–replica пар под разные задачи — когда важно изоляция и предсказуемость;\n- Redis Cluster — когда общий объём данных и нагрузка выходят за рамки одного сервера.\n\nПри этом Sentinel обычно присутствует на всех стадиях, где важна высокая доступность: он не масштабирует, но держит систему живой при отказах.\n\n## Итог\n\nМасштабирование по нагрузке в **Redis** строится слоями: сначала реплики для чтения, затем несколько master–replica пар под разные подсистемы и, при необходимости, Redis Cluster для горизонтального шардинга.\n\nЕсли заранее продумать, какие данные где хранятся и как клиенты находят актуальный master, можно плавно наращивать инфраструктуру Redis без резких архитектурных переделок.\n\n\n"
    },
    {
      "title": "Что такое Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "intro",
      "sectionTitle": "Что такое Redis",
      "sectionOrder": 1,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "intro",
        "slug": "01-what-is-redis",
        "lang": "ru"
      },
      "path": "/content/materials/redis/intro/01-what-is-redis.ru.md",
      "content": "\nRedis — это быстрый инструмент для хранения данных в формате «ключ–значение», который работает в оперативной памяти. Благодаря этому он отвечает практически мгновенно. Если сравнивать образно, то обычная база данных — это шкаф с полками, где каждая книга стоит на своём месте, а Redis — это стол, на котором лежат самые нужные вещи. До шкафа нужно идти, а со стола — взял и работаешь.\n\nЭта скорость делает Redis особенно полезным там, где данные нужно получать или обновлять очень часто: корзины интернет-магазинов, пользовательские сессии, системные счётчики, краткоживущие данные, проверки лимитов и многое другое. Redis не заменяет обычную базу данных, а выступает быстрым слоем между приложением и основным хранилищем.\n\n## Чем Redis отличается от обычной СУБД\n\nТрадиционные базы данных хранят информацию на диске. Это надёжно, но медленнее: данные нужно найти, считать, обработать. Redis сохраняет данные в оперативной памяти, поэтому доступ к ним происходит почти так же быстро, как доступ к переменной программы.\n\nSQL-базы предназначены для сложных запросов и больших наборов данных.  \nRedis — для ситуаций, где важны скорость и мгновенная реакция.\n\nПри необходимости Redis может сохранять данные на диск, но это дополнительная возможность, а не основная. Поэтому его чаще используют для временных или часто меняющихся данных.\n\n## Насколько Redis быстрее\n\nРазница в скорости заметна даже без глубоких измерений. Вставка и обновление значений в Redis занимает доли миллисекунды. В MySQL или Postgres аналогичная операция может занимать миллисекунды и больше, особенно под нагрузкой.\n\nВ реальных задачах это означает, что Redis выдерживает десятки или сотни тысяч операций в секунду без существенной потери производительности.\n\n### Сравнение вставки (INSERT)\n\n![Insert comparison](images/insert.png)\n\n### Сравнение обновления (UPDATE)\n\n![Update comparison](images/update.png)\n\nПо графикам видно, что Redis стабильно остаётся самым быстрым среди популярных СУБД.  \nЕго производительность почти не падает при росте количества операций — ключевое преимущество для высоконагруженных систем.\n\n## Когда Redis действительно удобен\n\nRedis используют там, где важно, чтобы данные появлялись быстро и не задерживали работу приложения:\n\n- кратковременные данные — сессии, корзины, черновики;\n- счётчики кликов, лайков, просмотров;\n- быстрый кэш, уменьшающий нагрузку на основную базу;\n- обмен сообщениями и событиями между частями системы;\n- временные блокировки, лимиты запросов, токены.\n\n## Итог\n\nRedis — это инструмент, который помогает приложениям работать быстрее и устойчивее под нагрузкой. Он прост, реактивен и значительно ускоряет операции, которые в обычной базе данных выполнялись бы заметно дольше. Именно поэтому Redis стал стандартом для тех случаев, где скорость играет ключевую роль."
    },
    {
      "title": "Архитектура и основные принципы работы",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "intro",
      "sectionTitle": "Архитектура и принципы работы",
      "sectionOrder": 1,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "intro",
        "slug": "02-architecture-and-principles",
        "lang": "ru"
      },
      "path": "/content/materials/redis/intro/02-architecture-and-principles.ru.md",
      "content": "\nАрхитектура Redis устроена достаточно просто, и именно в этой простоте скрывается его скорость. В отличие от традиционных баз данных, где много слоёв, модулей и механизмов синхронизации, Redis работает как компактный и быстрый сервер, который держит все данные в оперативной памяти и отвечает на команды последовательно, одну за другой.\n\nРабота в памяти — ключевой элемент. Когда данные лежат в RAM, нет необходимости читать их с диска, ждать позиционирования, проверки индексов и других операций. Сервер получает команду и сразу же выполняет её над объектом, который уже находится в памяти. Поэтому многие действия занимают не миллисекунды, а доли миллисекунды.\n\nRedis работает в одном потоке. Это может звучать неожиданно, ведь большинство систем стремится использовать как можно больше процессорных ядер. Но однопоточность позволяет избежать конфликтов при одновременном доступе, сложных блокировок и задержек. Сервер просто идёт по очереди команд, одна за другой, и обрабатывает их так быстро, что этот подход отлично справляется даже с большими нагрузками. Клиенты подключаются по сети и отправляют простые текстовые инструкции — получить значение, изменить его, добавить элемент в коллекцию. Сервер отвечает сразу после выполнения.\n\nИнтересной особенностью Redis является то, что он работает не только со строками. В основе лежит набор встроенных структур данных — от списков и хешей до упорядоченных множеств и потоков. Каждая структура спроектирована так, чтобы операции над ней выполнялись за минимальное время и не приводили к неожиданным задержкам.\n\nХотя Redis ориентирован на память, он умеет сохранять данные на диск. Это два разных режима: периодические снимки состояния и журнал команд, который фиксирует каждое изменение. При желании можно включить один из способов или оба сразу, в зависимости от того, насколько важна скорость и насколько критична надёжность.\n\nМеханизмы репликации и масштабирования тоже встроены в архитектуру. Основной сервер может передавать данные копии, на которую переносятся операции чтения. При необходимости к системе добавляют Sentinel для автоматического переключения в случае сбоя или запускают кластер, где данные распределяются по нескольким узлам. Но все эти возможности существуют не как тяжёлые и сложные модули, а как расширение базового принципа простоты и предсказуемости.\n\nВ итоге архитектура Redis строится вокруг идеи: чем меньше лишних слоёв и чем ближе данные к процессору, тем быстрее реагирует система. Эта прямолинейность делает Redis не только быстрым, но и понятным в использовании — даже человеку, который впервые с ним работает.\n\n"
    },
    {
      "title": "Установка и запуск Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "intro",
      "sectionTitle": "Установка и запуск Redis",
      "sectionOrder": 1,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "intro",
        "slug": "03-installation-and-setup",
        "lang": "ru"
      },
      "path": "/content/materials/redis/intro/03-installation-and-setup.ru.md",
      "content": "\nУстановка Redis на Linux выполняется через стандартные системные пакеты. Ниже приведён простой рабочий набор команд, который подходит для Ubuntu, Debian, Linux Mint и других систем на базе APT.\n\n## Установка\n\n```\nsudo apt update\nsudo apt install redis-server\n```\n\nПосле установки сервер запускается автоматически.\n\n## Проверка работы\n\nПроверяем статус службы:\n\n```\nsystemctl status redis-server\n```\n\nЕсли сервер работает, можно подключиться:\n\n```\nredis-cli\n```\n\nИ отправить тестовую команду:\n\n```\nPING\n```\n\nОжидаемый ответ:\n\n```\nPONG\n```\n\nЭто означает, что всё установлено корректно.\n\n## Управление сервером\n\n```\nsudo systemctl start redis-server\nsudo systemctl stop redis-server\nsudo systemctl restart redis-server\n```\n\n## Конфигурация\n\nОсновной конфигурационный файл расположен здесь:\n\n```\n/etc/redis/redis.conf\n```\n\nПосле изменений требуется перезапуск.\n\n## Минимальная проверка сохранения\n\n```\nredis-cli set test \"hello\"\nredis-cli get test\n```\n\nЕсли значение сохраняется после перезапуска, Redis корректно работает с диском.\n\n## Запуск через Docker\n\nЕсли не хочется устанавливать Redis в систему напрямую, его можно запустить в контейнере Docker. Это удобный способ получить изолированный экземпляр сервера.\n\n### Запуск контейнера\n\n```\ndocker run -d --name redis \\\n  -p 6379:6379 \\\n  redis:latest\n```\n\nПосле запуска Redis будет доступен на порту 6379, как и при обычной установке.\n\n### Проверка работы\n\n```\ndocker exec -it redis redis-cli ping\n```\n\nОжидаемый ответ:\n\n```\nPONG\n```\n\n### Остановка и удаление контейнера\n\n```\ndocker stop redis\ndocker rm redis\n```\n\nЭтот способ подходит, если нужно быстро развернуть сервер без изменения системы или когда проект полностью работает в контейнерах.\n"
    },
    {
      "title": "Политики вытеснения",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "memory",
      "sectionTitle": "Управление памятью",
      "sectionOrder": 5,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "memory",
        "slug": "01-eviction-policies",
        "lang": "ru"
      },
      "path": "/content/materials/redis/memory/01-eviction-policies.ru.md",
      "content": "\n**Redis** обычно держит все данные в памяти. Если её не хватает, поведение сервера зависит от настроек: он либо начнёт вытеснять старые ключи, либо просто перестанет принимать записи с ошибкой. За это отвечает связка **maxmemory** и **maxmemory-policy**.\n\nЧтобы не получить неожиданный отказ от записи в продакшене, важно понимать, какие есть политики и в каких сценариях какую выбирать.\n\n## Лимит памяти maxmemory\n\nСначала задаётся общий лимит, сколько памяти **Redis** может использовать под данные.\n\nПосмотреть текущий лимит:\n\n```\nCONFIG GET maxmemory\n```\n\nУстановить, например, 1 гигабайт:\n\n```\nCONFIG SET maxmemory 1gb\n```\n\nПосле достижения лимита начинает работать политика вытеснения. Если лимит не задан (0), Redis будет пытаться использовать всю доступную память процесса и операционной системы — в продакшене это почти всегда плохая идея.\n\nОбычно лимит фиксируют на уровне, который удобно мониторить и под который рассчитан сервер.\n\n## Основные политики вытеснения\n\nПолитику можно узнать так:\n\n```\nCONFIG GET maxmemory-policy\n```\n\nИ поменять:\n\n```\nCONFIG SET maxmemory-policy allkeys-lru\n```\n\nРаспространённые варианты:\n\n- **noeviction** — новая запись при нехватке памяти завершится ошибкой. Подходит для сценариев, где нельзя терять данные и есть внешний контроль за объёмом.\n- **volatile-lru** — выталкивать по принципу LRU только те ключи, у которых есть **TTL**.\n- **allkeys-lru** — выталкивать по LRU любые ключи. Часто используется для кэша.\n- **volatile-ttl** — удалять в первую очередь ключи с минимальным оставшимся **TTL**.\n- **allkeys-random** и **volatile-random** — выбирать ключи для удаления случайно.\n\nВ новых версиях есть также варианты на основе **LFU** (частоты использования): **allkeys-lfu** и **volatile-lfu**.\n\n## Практические сценарии выбора политики\n\nДля чистого кэша, где данные всегда можно восстановить из основной базы, чаще всего выбирают:\n\n```\nCONFIG SET maxmemory-policy allkeys-lru\n```\n\nСценарий: хранение ключей вида **cache:article:42**, **cache:profile:10** без строгих гарантий сохранности. Redis сам будет удалять давно неиспользуемые записи, чтобы укладываться в заданный лимит.\n\nЕсли в Redis лежит не только кэш, но и важные данные, и при этом у временных ключей всегда есть **TTL**, уместен вариант:\n\n```\nCONFIG SET maxmemory-policy volatile-lru\n```\n\nТогда при нехватке памяти будут удаляться только ключи с временем жизни, а постоянные данные останутся нетронутыми. Важно следить, чтобы все «одноразовые» и кэширующие ключи действительно имели TTL.\n\n## Типичные ошибки при настройке\n\nЧастые проблемы:\n\n- лимит **maxmemory** не задан, Redis занимает всю память сервера;\n- выбрана политика **noeviction**, а приложение не умеет обрабатывать ошибку записи;\n- политика требует **TTL**, но ключи кэша и сессий создаются без явного времени жизни;\n- разные типы данных смешаны в одном инстансе Redis: и кэш, и критичные данные, и очереди.\n\nПрактичный подход — разделять назначения по разным инстансам: один Redis только под кэш с политикой **allkeys-lru**, другой — под сессии и очереди с аккуратной работой с TTL и без агрессивного вытеснения.\n\n## Итог\n\nПолитики вытеснения в **Redis** определяют, что произойдёт, когда сервер упрётся в лимит памяти: какие ключи будут удаляться и будут ли операции записи вообще успешны.\n\nГрамотный выбор **maxmemory** и **maxmemory-policy** под конкретный сценарий (кэш, сессии, очереди, критичные данные) помогает избежать неожиданного падения сервиса и контролировать поведение Redis под нагрузкой.\n\n\n"
    },
    {
      "title": "Оценка размера ключей",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "memory",
      "sectionTitle": "Управление памятью",
      "sectionOrder": 5,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "memory",
        "slug": "02-key-size-estimation",
        "lang": "ru"
      },
      "path": "/content/materials/redis/memory/02-key-size-estimation.ru.md",
      "content": "\nКогда данных становится много, важно понимать, сколько памяти реально занимает каждый ключ и какие структуры «съедают» больше всего. В **Redis** для этого есть отдельные инструменты: команды **MEMORY USAGE**, **MEMORY STATS** и **MEMORY DOCTOR**.\n\nС их помощью можно найти самые тяжёлые ключи, сравнить разные варианты хранения и принять осознанное решение по оптимизации.\n\n## MEMORY USAGE — размер одного ключа\n\nПроще всего начать с оценки конкретного ключа. Команда **MEMORY USAGE** показывает примерный объём памяти в байтах, который занимает значение.\n\nПример с простым кэшем статьи:\n\n```\nSET cache:article:42 \"{...json статьи...}\"\nMEMORY USAGE cache:article:42\n```\n\nВ ответ Redis вернёт число, например:\n\n```\n(integer) 2048\n```\n\nЭто не точный, но достаточно близкий к реальности размер. Полезно запускать **MEMORY USAGE** на разных типах ключей:\n\n- строки с JSON;\n- хеши с теми же данными;\n- списки, множества, упорядоченные множества.\n\nТак можно быстро увидеть, какой формат для вашей задачи дешевле по памяти.\n\n## Поиск «тяжёлых» ключей через SCAN\n\nЧтобы понять, какие ключи в инстансе самые крупные, можно пройтись по ним через **SCAN** и для каждого посмотреть **MEMORY USAGE**.\n\nНапример, ищем тяжёлые ключи кэша:\n\n```\nSCAN 0 MATCH cache:* COUNT 100\nMEMORY USAGE cache:article:1\nMEMORY USAGE cache:article:2\nMEMORY USAGE cache:profile:42\n```\n\nСкрипт на стороне приложения:\n\n- вызывает **SCAN** в цикле;\n- для каждого найденного ключа делает **MEMORY USAGE**;\n- сортирует по размеру и показывает топ-10–20 самых больших.\n\nТакой подход помогает быстро найти неожиданные «пожиратели» памяти: огромные списки логов, ключи без **TTL**, слишком крупные JSON-объекты.\n\n## MEMORY STATS и MEMORY DOCTOR\n\nДля общей картины по памяти можно использовать:\n\n```\nMEMORY STATS\n```\n\nКоманда возвращает большой набор метрик: общую использованную память, накладные расходы на структуры, настройки аллокатора, фрагментацию. Полезно сохранить этот вывод и сравнивать его до и после изменений в схеме хранения.\n\nЕсли хочется быстрой подсказки от самого Redis:\n\n```\nMEMORY DOCTOR\n```\n\nОтвет будет в текстовом виде и может содержать советы уровня:\n\n- уменьшить количество маленьких ключей;\n- обратить внимание на фрагментацию;\n- посмотреть на конфигурацию аллокатора.\n\nЭти рекомендации не всегда точечные, но часто помогают заметить общие проблемы.\n\n## Сравнение вариантов хранения на примере\n\nДопустим, у нас есть 1000 настроек пользователей. Можно хранить их как 1000 отдельных ключей:\n\n```\nSET user:1:settings \"{...}\"\nSET user:2:settings \"{...}\"\n...\nSET user:1000:settings \"{...}\"\n```\n\nА можно как один хеш:\n\n```\nHSET user:settings 1 \"{...}\"\nHSET user:settings 2 \"{...}\"\n...\nHSET user:settings 1000 \"{...}\"\n```\n\nЧтобы сравнить, достаточно измерить:\n\n```\nMEMORY USAGE user:1:settings\nMEMORY USAGE user:settings\n```\n\nВо многих случаях один хеш будет экономичнее, чем множество мелких ключей, за счёт меньших накладных расходов. Но лучше всегда проверять на своих данных.\n\n## Итог\n\nИнструменты **MEMORY USAGE**, **MEMORY STATS** и **MEMORY DOCTOR** помогают превратить оптимизацию памяти в измеряемый процесс, а не в угадывание.\n\nРегулярная оценка размеров ключей и поиск самых тяжёлых записей позволяет вовремя заметить неэффективные структуры и переработать схему хранения до того, как Redis начнёт упираться в лимит.\n\n\n"
    },
    {
      "title": "Оптимизация потребления памяти",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "memory",
      "sectionTitle": "Управление памятью",
      "sectionOrder": 5,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "memory",
        "slug": "03-memory-optimization",
        "lang": "ru"
      },
      "path": "/content/materials/redis/memory/03-memory-optimization.ru.md",
      "content": "\nДаже при правильно настроенных лимитах и политиках вытеснения важно, как именно данные лежат в **Redis**. Те же самые объёмы информации можно хранить по-разному: где‑то тратится в разы больше памяти, где‑то — значительно меньше.\n\nОптимизация обычно сводится к трём вещам: выбор структуры данных, аккуратные ключи и разумное время жизни.\n\n## Выбор подходящей структуры\n\nРазные структуры в **Redis** по‑разному расходуют память. Часто можно заметно выиграть, если заменить россыпь мелких ключей на один хеш или использовать упорядоченное множество вместо списка.\n\nПример с профилями пользователей.\n\nВариант 1 — много отдельных строк:\n\n```\nSET user:42:name \"Alice\"\nSET user:42:email \"alice@example.com\"\nSET user:42:city \"Berlin\"\n```\n\nВариант 2 — один хеш:\n\n```\nHSET user:42 name \"Alice\" email \"alice@example.com\" city \"Berlin\"\n```\n\nВо втором случае меньше накладных расходов на ключи, а отдельные поля по‑прежнему можно читать и обновлять независимо. На практике хеши хорошо подходят для компактного хранения небольших сущностей.\n\n## Экономные названия ключей\n\nКаждый ключ сам по себе занимает память. Если в проекте миллионы ключей, лишние символы в имени начинают стоить дорого.\n\nПример:\n\n```\nSET very-long-namespace:users:profiles:42 \"{...}\"\n```\n\nМожно упростить схему, не теряя смысла:\n\n```\nSET user:profile:42 \"{...}\"\n```\n\nГлавные идеи:\n\n- избегать излишне длинных префиксов;\n- не дублировать одну и ту же часть названия несколько раз;\n- держать схему ключей понятной, но без лишних слов.\n\nПеред массовым вводом новой схемы ключей полезно оценить реальный выигрыш через **MEMORY USAGE** на тестовом наборе данных.\n\n## TTL и очистка ненужных данных\n\nЧасть данных в **Redis** по своей природе временная: кэш, одноразовые токены, черновики, сессии. Если не задавать им **TTL**, они будут накапливаться и занимать память даже после того, как перестанут быть нужны.\n\nПримеры с разумным временем жизни:\n\n```\nSETEX cache:article:42 300 \"{...json статьи...}\"\nSETEX session:token:abc123 1800 \"user:42\"\n```\n\nПара практических правил:\n\n- у любых кэширующих ключей должен быть **TTL**;\n- у сессий — срок жизни, соответствующий бизнес‑логике;\n- временные флаги и коды подтверждения всегда создаются с ограничением по времени.\n\nДля удаления крупных ключей лучше использовать **UNLINK**, чтобы не блокировать сервер:\n\n```\nUNLINK big:list\nUNLINK cache:heavy:result\n```\n\n## Разделение данных по инстансам\n\nИногда оптимизация — это не только про байты, но и про поведение под нагрузкой. Стоит разделять:\n\n- чистый кэш;\n- сессии и авторизацию;\n- очереди задач и события.\n\nНапример:\n\n- один инстанс **Redis** работает как кэш с агрессивной политикой **allkeys-lru** и короткими **TTL**;\n- другой инстанс хранит сессии и очереди, где память используется более предсказуемо, а вытеснение либо отключено, либо настроено мягко.\n\nТак проще контролировать потребление памяти и поведение каждой части системы, не пытаясь впихнуть все сценарии в один набор настроек.\n\n## Итог\n\nОптимизация памяти в **Redis** — это в первую очередь про правильный выбор структур данных, аккуратную схему ключей и осознанное использование **TTL**.\n\nЕсли регулярно измерять размер ключей, пересматривать схему хранения и разделять разные типы нагрузки по инстансам, Redis остаётся компактным и предсказуемым даже при росте объёмов данных.\n\n\n"
    },
    {
      "title": "Основные метрики и команда INFO",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "monitoring",
      "sectionTitle": "Мониторинг и отладка",
      "sectionOrder": 10,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "monitoring",
        "slug": "01-info-and-metrics",
        "lang": "ru"
      },
      "path": "/content/materials/redis/monitoring/01-info-and-metrics.ru.md",
      "content": "\nДля нормальной эксплуатации **Redis** важно не только писать и читать данные, но и понимать, как чувствует себя сервер: хватает ли памяти, не зашкаливает ли число подключений, нет ли проблем с репликацией. Базовый инструмент для этого — команда **INFO**.\n\nЧерез INFO можно быстро посмотреть ключевые метрики и на их основе настроить мониторинг в Prometheus, Grafana и других системах.\n\n## Команда INFO по разделам\n\nВ самом простом виде:\n\n```\nINFO\n```\n\nRedis вернёт большой блок текста, разбитый на разделы: Server, Clients, Memory, Persistence, Stats, Replication и так далее.\n\nМожно запрашивать конкретный раздел:\n\n```\nINFO memory\nINFO stats\nINFO replication\n```\n\nЭто удобнее для автоматического сбора метрик и для быстрой диагностики проблем в конкретной области.\n\n## Важные метрики памяти\n\nРаздел **memory** помогает оценить, сколько ресурсов реально съедает Redis.\n\nПример:\n\n```\nINFO memory\n```\n\nКлючевые поля:\n\n- used_memory — сколько памяти реально занято под данные и структуры Redis;\n- used_memory_rss — сколько памяти занят процесс в системе (с учётом фрагментации);\n- maxmemory — лимит памяти, если он настроен;\n- mem_fragmentation_ratio — отношение RSS к used_memory, показывает уровень фрагментации.\n\nНа практике:\n\n- если used_memory близко к maxmemory, скоро начнут работать политики вытеснения;\n- если mem_fragmentation_ratio сильно больше 1, есть смысл расследовать фрагментацию и настройки аллокатора.\n\n## Общие статистики и нагрузка\n\nРаздел **stats** даёт представление о том, насколько активно используется Redis.\n\nПример:\n\n```\nINFO stats\n```\n\nПолезные поля:\n\n- total_commands_processed — сколько команд всего обработано;\n- instantaneous_ops_per_sec — текущий QPS (команды в секунду);\n- keyspace_hits и keyspace_misses — попадания и промахи по ключам;\n- expired_keys — сколько ключей было удалено по TTL.\n\nЭти метрики хорошо подходят:\n\n- для графиков нагрузки во времени;\n- для понимания эффективности кэша (по hit/miss);\n- для оценки того, сколько ключей реально живёт за счёт TTL.\n\n## Клиенты и соединения\n\nРаздел **clients** помогает увидеть, сколько подключений открыто и нет ли «утечек» клиентов.\n\nПример:\n\n```\nINFO clients\n```\n\nСмотрим:\n\n- connected_clients — число активных соединений;\n- blocked_clients — сколько клиентов сейчас заблокировано (например, на BLPOP или командах, ожидающих данных).\n\nЕсли connected_clients растёт без остановки или часто достигает лимитов, стоит:\n\n- проверить, правильно ли приложения закрывают подключения;\n- настроить пулы соединений;\n- при необходимости увеличить лимиты и ресурсы.\n\n## Итог\n\nКоманда **INFO** — центральный инструмент быстрой диагностики и базового мониторинга Redis: через неё можно увидеть память, нагрузку, клиентов и состояние репликации.\n\nЕсли регулярно смотреть на ключевые поля и вытащить их в систему мониторинга, многие проблемы с Redis становятся заметны задолго до того, как превратятся в реальные аварии.\n\n\n"
    },
    {
      "title": "MONITOR, SLOWLOG и медленные команды",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "monitoring",
      "sectionTitle": "Мониторинг и отладка",
      "sectionOrder": 10,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "monitoring",
        "slug": "02-monitor-and-slowlog",
        "lang": "ru"
      },
      "path": "/content/materials/redis/monitoring/02-monitor-and-slowlog.ru.md",
      "content": "\nКогда Redis начинает «тормозить», важно понять, какие именно команды его грузят: кто шлёт слишком тяжёлые запросы, какие операции работают медленно и почему. Для этого в Redis есть две мощные вещи: **MONITOR** для живого просмотра команд и **SLOWLOG** для истории медленных операций.\n\nЭти инструменты удобно использовать в паре: MONITOR — для оперативной отладки, SLOWLOG — для системного анализа.\n\n## MONITOR — живой поток команд\n\nКоманда **MONITOR** показывает все команды, которые выполняются на сервере, в режиме реального времени.\n\nПример:\n\n```\nMONITOR\n```\n\nПосле этого клиент начнёт получать строки вида:\n\n```\n1669212345.123456 [0 10.0.0.5:53421] \"SET\" \"user:42\" \"Alice\"\n1669212345.234567 [0 10.0.0.6:53422] \"GET\" \"cache:article:42\"\n```\n\nЧто это даёт:\n\n- видно, какие ключи активно используются;\n- можно отследить, какие сервисы шлют неожиданные команды;\n- удобно в отладке на тестовой среде.\n\nВажно:\n\n- MONITOR сильно нагружает сервер и сеть, особенно под высокой нагрузкой;\n- его не стоит использовать постоянно в продакшене;\n- лучше подключаться к MONITOR с отдельного, временного клиента и на ограниченное время.\n\n## SLOWLOG — журнал медленных команд\n\n**SLOWLOG** хранит записи о командах, которые выполнялись дольше заданного порога.\n\nПосмотреть текущие настройки:\n\n```\nCONFIG GET slowlog-log-slower-than\nCONFIG GET slowlog-max-len\n```\n\nТипичные значения:\n\n- slowlog-log-slower-than — порог в микросекундах (например, 10000 = 10 мс);\n- slowlog-max-len — сколько записей хранить в журнале.\n\nПример настройки:\n\n```\nCONFIG SET slowlog-log-slower-than 10000\nCONFIG SET slowlog-max-len 128\n```\n\nПросмотр журнала:\n\n```\nSLOWLOG GET 10\n```\n\nОтвет содержит:\n\n- идентификатор записи;\n- время выполнения;\n- саму команду и её аргументы.\n\nТак можно увидеть, какие конкретные запросы стабильно занимают десятки или сотни миллисекунд.\n\n## Как использовать эти инструменты на практике\n\nТиповой сценарий:\n\n1. В продакшене всегда включён разумный SLOWLOG (порог в районе 5–10 мс).\n2. При первых жалобах на тормоза смотрим SLOWLOG и ищем паттерны:\n\n```\nSLOWLOG GET 20\n```\n\n3. Если нужно понять, откуда точно приходят проблемные команды, временно включаем MONITOR на тесте или на отдельной реплике.\n4. По результатам:\n\n- оптимизируем ключи и команды;\n- пересматриваем использование тяжёлых операций (например, KEYS, большие LRANGE, массовые скрипты).\n\n## Итог\n\n**MONITOR** даёт живую картинку всех команд, а **SLOWLOG** — аккуратный список самых медленных операций за последнее время.\n\nЕсли держать SLOWLOG настроенным постоянно и подключать MONITOR точечно для сложных случаев, отладка производительности Redis превращается из угадывания в понятный и воспроизводимый процесс.\n\n\n"
    },
    {
      "title": "Логи Redis и настройки логирования",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "monitoring",
      "sectionTitle": "Мониторинг и отладка",
      "sectionOrder": 10,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "monitoring",
        "slug": "03-logging",
        "lang": "ru"
      },
      "path": "/content/materials/redis/monitoring/03-logging.ru.md",
      "content": "\nПомимо команд INFO и SLOWLOG, много ценной информации о работе **Redis** можно получить из обычных логов сервера. Они помогают понять, когда сервер перезапускался, были ли ошибки при сохранении snapshot, как ведёт себя репликация и что происходило перед аварией.\n\nВажно правильно настроить, куда пишет Redis, какой уровень логирования использовать и как забирать эти данные в централизованную систему.\n\n## Куда пишет Redis: logfile и syslog\n\nОсновные параметры логирования:\n\n```\nlogfile \"\"\nsyslog-enabled no\nsyslog-ident redis\nsyslog-facility local0\n```\n\nЕсли **logfile** пустой, Redis пишет логи в stdout/stderr — это удобно для контейнеров и систем, где логи собирает оркестратор.\n\nЕсли нужно писать в файл:\n\n```\nlogfile \"/var/log/redis/redis-server.log\"\n```\n\nВ продакшене чаще всего:\n\n- или оставляют вывод в stdout и забирают его средствами платформы;\n- или пишут в файл и ротируют через logrotate.\n\n## Уровень логирования\n\nЗа уровень отвечает параметр **loglevel**.\n\nВарианты:\n\n```\nloglevel notice\n```\n\nДоступные уровни:\n\n- debug — максимально подробные логи (только для отладки на dev);\n- verbose — расширенная информация;\n- notice — разумный уровень по умолчанию;\n- warning — только предупреждения и ошибки.\n\nДля продакшена обычно достаточно **notice** или, при очень чувствительном диске, **warning**. Для отладки сложных проблем можно временно включить **verbose** или **debug**, но не оставлять так надолго.\n\n## Что искать в логах\n\nТипичные вещи, которым стоит уделять внимание:\n\n- сообщения о запуске и остановке сервера;\n- ошибки сохранения RDB или записи AOF;\n- предупреждения о блокирующих операциях;\n- события, связанные с репликацией и Sentinel;\n- сообщения о переполнении памяти и срабатывании политик вытеснения.\n\nПримеры:\n\n- ошибки BGSAVE;\n- предупреждения о частых полных синхронизациях реплик;\n- записи о failover при использовании Sentinel.\n\nИмея централизованный сбор логов, легко построить алерты на появление критичных сообщений.\n\n## Интеграция с внешним мониторингом\n\nЧасто логи Redis отправляют в:\n\n- системные журналы (journald, syslog);\n- централизованные стеки (ELK, Loki, Cloud Logging);\n- системы алертинга (через парсинг логов).\n\nОбщий подход:\n\n- настроить единый формат логов;\n- добавить метки окружения и инстанса;\n- фильтровать только важные сообщения для алертов.\n\nНа практике это позволяет быстро ответить на вопросы вида «что случилось с Redis в момент X» без подключения к серверу по SSH.\n\n## Итог\n\nЛоги **Redis** дополняют INFO и SLOWLOG: они показывают историю событий сервера — от перезапусков и ошибок snapshot до проблем с репликацией и памятью.\n\nЕсли настроить удобный вывод логов, выбрать адекватный loglevel и собрать их в централизованную систему, поиск причин сбоев и странного поведения Redis становится гораздо проще и быстрее.\n\n\n"
    },
    {
      "title": "Диагностика памяти и горячих ключей",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "monitoring",
      "sectionTitle": "Мониторинг и отладка",
      "sectionOrder": 10,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "monitoring",
        "slug": "04-memory-hotkeys-diagnostics",
        "lang": "ru"
      },
      "path": "/content/materials/redis/monitoring/04-memory-hotkeys-diagnostics.ru.md",
      "content": "\nКогда Redis начинает упираться в лимит памяти или отдельные ключи вызывают всплески нагрузки, важно уметь быстро понять, кто именно виноват. Для этого пригодятся команды **MEMORY** и инструменты вроде **LATENCY DOCTOR**, а также аккуратный обход ключей.\n\nЧасть этих приёмов уже встречалась в разделе про управление памятью, здесь посмотрим на них с точки зрения мониторинга и быстрой диагностики.\n\n## Быстрая оценка памяти через INFO и MEMORY STATS\n\nПервый шаг — посмотреть общую картину:\n\n```\nINFO memory\n```\n\nЕсли used_memory близок к maxmemory или mem_fragmentation_ratio заметно больше 1, стоит копнуть глубже.\n\nБолее детальный снимок:\n\n```\nMEMORY STATS\n```\n\nКоманда возвращает массив статистик: сколько памяти уходит на данные, на служебные структуры, на аллокатор. Эти данные удобно загонять в мониторинг, чтобы отслеживать тренды роста и понимать, где именно «толстеет» Redis.\n\n## Поиск тяжёлых ключей через MEMORY USAGE\n\nЧтобы найти, какие ключи занимают больше всего памяти, можно пройтись по ним через SCAN и для каждого замерить размер.\n\nПример ручного подхода:\n\n```\nSCAN 0 MATCH cache:* COUNT 100\nMEMORY USAGE cache:article:1\nMEMORY USAGE cache:article:2\n```\n\nНа практике:\n\n- скрипт на стороне приложения обходит ключи по SCAN;\n- вызывает **MEMORY USAGE** для каждого;\n- строит топ‑N самых тяжёлых ключей.\n\nТак легко обнаружить:\n\n- слишком крупные JSON‑значения;\n- ключи без TTL, которые накопили огромные структуры;\n- неожиданные коллекции логов и очередей.\n\n## Поиск горячих ключей через мониторинг\n\nГорячие ключи — это те, к которым идёт непропорционально много обращений. Они могут становиться узким местом: один ключ с тяжёлым значением, который читают тысячи раз в секунду.\n\nПростейший приём:\n\n- временно включить **MONITOR** на тестовой реплике или в ограниченное время;\n- отфильтровать поток команд по ключам и посчитать частоту обращений.\n\nПример:\n\n```\nMONITOR\n```\n\nДальше парсер или отдельный инструмент считает, какие ключи встречаются чаще всего. Такие ключи:\n\n- кандидаты на оптимизацию структуры данных;\n- могут требовать кэширования на стороне приложения;\n- иногда подсказка, что данные стоит разнести по нескольким ключам.\n\n## LATENCY DOCTOR и неожиданные задержки\n\nRedis имеет встроенный инструмент для анализа задержек:\n\n```\nLATENCY DOCTOR\n```\n\nОн пытается автоматически найти и описать проблемы:\n\n- длительные блокирующие операции;\n- резкие скачки в работе диска;\n- аномалии в репликации.\n\nВывод команды даёт текстовые рекомендации и может указать, где искать корень проблемы — в памяти, диске, сети или конкретных командах.\n\n## Итог\n\nДиагностика памяти и горячих ключей в **Redis** опирается на INFO и MEMORY STATS для общей картины, MEMORY USAGE и SCAN для поиска тяжёлых ключей, а также MONITOR и LATENCY DOCTOR для анализа частоты обращений и задержек.\n\nЕсли держать под рукой эти инструменты и периодически смотреть на них не только во время аварий, многие проблемы с памятью и узкими местами можно поймать и исправить заранее.\n\n\n"
    },
    {
      "title": "Типичные проблемы производительности и диагностика",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "monitoring",
      "sectionTitle": "Мониторинг и отладка",
      "sectionOrder": 10,
      "order": 5,
      "id": {
        "category": "redis",
        "section": "monitoring",
        "slug": "05-common-performance-issues",
        "lang": "ru"
      },
      "path": "/content/materials/redis/monitoring/05-common-performance-issues.ru.md",
      "content": "\nКогда Redis «медленный», реальная причина почти всегда одна из нескольких: крупные блокирующие команды, неподходящие структуры данных, проблемы с диском (snapshot, AOF), перегруженный сетью или CPU сервер. Хорошая новость — эти ситуации повторяются из проекта в проект, и для них есть устойчивые приёмы диагностики.\n\nРазберём несколько типичных симптомов и шаги, которые помогают быстро сузить поиск.\n\n## Высокая задержка ответов\n\nСимптом: время ответа Redis скачет, иногда подскакивает до десятков и сотен миллисекунд.\n\nЧто проверить:\n\n1. Общую картину:\n\n```\nINFO stats\nINFO clients\nLATENCY DOCTOR\n```\n\n2. SLOWLOG:\n\n```\nSLOWLOG GET 20\n```\n\nЕсли в SLOWLOG видно команды вроде:\n\n- большие LRANGE на сотни тысяч элементов;\n- KEYS с широкими шаблонами;\n- тяжёлые Lua‑скрипты;\n\nто это первые кандидаты на оптимизацию.\n\n## Просадки из‑за snapshot и AOF\n\nСимптом: периодические пики задержек и нагрузки на диск, совпадающие с BGSAVE или BGREWRITEAOF.\n\nЧто смотреть:\n\n```\nINFO persistence\n```\n\nПолезные поля:\n\n- rdb_last_bgsave_status и rdb_last_bgsave_time_sec;\n- aof_last_bgrewrite_status и aof_last_bgrewrite_time_sec.\n\nЕсли длительность фоновых операций велика, а в логах часто видны запуск BGSAVE/BGREWRITEAOF, стоит:\n\n- уменьшить частоту snapshot;\n- убедиться, что диск достаточно быстрый;\n- по возможности выносить Redis и тяжёлые дисковые операции на разные устройства.\n\n## Перегруженный одним узлом кластер\n\nВ кластере возможна ситуация, когда одна нода обрабатывает непропорционально много запросов.\n\nПроверить:\n\n```\nCLUSTER NODES\nINFO stats\n```\n\nЕсли один мастер показывает значительно больший instantaneous_ops_per_sec и used_memory, чем остальные, возможно:\n\n- распределение слотов неравномерно;\n- hash tags ведут слишком много ключей на одну ноду.\n\nРешения:\n\n- перераспределить слоты через redis-cli --cluster reshard;\n- пересмотреть схему ключей и использование hash tags.\n\n## Застрявшие или блокирующие клиенты\n\nСимптом: растёт число blocked_clients, часть команд «висят».\n\nПроверить:\n\n```\nINFO clients\nCLIENT LIST\n```\n\nblocked_clients > 0 говорит, что есть операции, ожидающие данных (BLPOP, BRPOP, XREAD с BLOCK), или другие блокировки.\n\nНужно:\n\n- убедиться, что продюсеры действительно пишут в очереди;\n- проверить, нет ли ситуаций, когда потребители забывают подтверждать сообщения в Streams и переполняют PEL;\n- при необходимости ограничить время блокировки и предусмотреть таймауты на стороне приложения.\n\n## Итог\n\nТипичные проблемы производительности в **Redis** почти всегда сводятся к тяжёлым командам, неудачной конфигурации персистентности или неравномерному распределению нагрузки.\n\nЕсли использовать INFO, SLOWLOG, LATENCY DOCTOR, CLIENT LIST и, при необходимости, команды кластера, диагностика превращается в понятный набор шагов, а не в хаотичный поиск вслепую.\n\n\n"
    },
    {
      "title": "Кэширование",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "01-caching",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/01-caching.ru.md",
      "content": "\nКэширование — одна из самых частых причин использовать Redis. Идея простая: дорогой по времени или ресурсоёмкий результат один раз считается, сохраняется в Redis и потом быстро читается оттуда.\n\n## Простой кэш для тяжёлого запроса\n\nПредставим, что есть запрос к базе данных, который занимает сотни миллисекунд. Вместо того чтобы каждый раз ходить в БД, приложение сначала проверяет Redis.\n\nЛогика на уровне приложения выглядит так:\n\n1. Посмотреть значение в Redis по заранее известному ключу.\n2. Если значение есть — вернуть его.\n3. Если значения нет — взять данные из БД, положить в Redis и вернуть пользователю.\n\nПример работы с ключом cache:article:42:\n\n```\nGET cache:article:42\n```\n\nЕсли ответ пустой, приложение читает статью из базы и записывает результат с временем жизни:\n\n```\nSETEX cache:article:42 60 \"{...json статьи...}\"\n```\n\nКлюч живёт 60 секунд, после чего удаляется. Следующий запрос снова обратится к БД, обновит кэш и цикл продолжится.\n\n**Плюс такого подхода:** кэш не переполнен старыми данными, потому что они автоматически истекают.\n\n## Кэширование страниц и HTTP-ответов\n\nRedis удобно использовать как кэш для целых страниц или фрагментов HTML.\n\nНапример, есть страница товара `/products/10`. Приложение может сформировать HTML один раз и сохранить его в Redis:\n\n```\nSETEX cache:page:/products/10 30 \"<html>...\" \n```\n\nПри следующем запросе к странице сначала проверяется Redis:\n\n```\nGET cache:page:/products/10\n```\n\nЕсли HTML найден, сервер сразу отдаёт его пользователю, не тратя время на повторную сборку страницы.\n\n## Обновление и сброс кэша\n\nКэш всегда связан с исходными данными. Если данные поменялись, старый кэш становится бесполезным.\n\n**Простой подход:** после изменения данных удалить связанный ключ.\n\n```\nDEL cache:article:42\n```\n\nСледующий запрос создаст свежий кэш через SETEX.\n\nИногда кэш обновляют не только при чтении, но и сразу после записи в основное хранилище: как только данные изменились, новое значение кладут в Redis, чтобы не ждать первого запроса.\n\n## Что кэшировать имеет смысл\n\n**Тяжёлые запросы.** То, что долго считается или часто запрашивается.\n\n**Редко меняющиеся данные.** Справочники, популярные статьи, публичные профили.\n\n**Результаты сложных агрегатов.** Статистика, подготовленные выборки.\n\nЧем дороже получение данных без Redis, тем больше выигрывает кэш.\n\n## Чего кэшировать не стоит\n\nДанные, которые меняются каждую секунду и при этом всегда должны быть строго актуальными (например, баланс счёта в банковской системе), плохо подходят для простого кэширования. В таких случаях используют другие механизмы согласованности.\n\nКэширование в Redis не требует сложных схем: достаточно выбрать понятные ключи, задать разумный TTL и обновлять кэш при изменении исходных данных.\n"
    },
    {
      "title": "Rate Limiting",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "02-rate-limiting",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/02-rate-limiting.ru.md",
      "content": "\nRate limiting — это ограничение числа операций за промежуток времени. Чаще всего его используют, чтобы защитить API, формы логина и другие чувствительные точки от злоупотреблений.\n\nИдея простая: считать события (запросы, попытки входа) и не давать делать их слишком часто.\n\n## Простой лимит: не больше N запросов за окно\n\nКлассический пример: не больше 10 запросов в минуту с одного пользователя или IP.\n\nВ качестве ключа можно взять что‑то вроде:\n\n```\nrate:login:ip:127.0.0.1\n```\n\nКаждый запрос увеличивает счётчик и задаёт срок жизни ключа:\n\n```\nINCR rate:login:ip:127.0.0.1\nEXPIRE rate:login:ip:127.0.0.1 60\n```\n\nЛогика в приложении:\n\n1. Увеличить счётчик через INCR.\n2. Если это первый запрос (ответ 1) — задать время жизни через EXPIRE.\n3. Если значение счётчика больше порога (например, 10) — вернуть ошибку «слишком много запросов».\n\nТак получается простое «окно» на 60 секунд: после паузы счётчик сам обнуляется.\n\n## Болеe ровный лимит: скользящее окно на ZSET\n\nФиксированное окно иногда даёт «скачки»: пользователь может сделать почти 2× лимита на границе минут. Чтобы сгладить это, используют скользящее окно на упорядоченном множестве.\n\nКлюч для пользователя:\n\n```\nrate:api:user:42\n```\n\nПри каждом запросе берём текущий timestamp (например, в миллисекундах) и выполняем последовательность команд:\n\n1. Добавить метку времени в ZSET.\n2. Удалить из ZSET все записи старше окна (например, старше 60 секунд).\n3. Посчитать, сколько записей осталось.\n\nПример команд:\n\n```\nZADD rate:api:user:42 1710000000000 \"req1\"\nZREMRANGEBYSCORE rate:api:user:42 -inf 1709999940000\nZCARD rate:api:user:42\n```\n\nЕсли ZCARD показывает, что запросов больше лимита, новый запрос отклоняется.\n\n**Плюсы такого подхода:** более честное ограничение «N запросов за последние X секунд», а не за календарную минуту.\n\n## Что именно ограничивать\n\nВ качестве части ключа для лимита можно использовать:\n\n- идентификатор пользователя;\n- IP‑адрес;\n- комбинацию метода и пути API;\n- любое другое значение, которое нужно защитить.\n\nПримеры ключей:\n\n```\nrate:api:user:42\nrate:api:ip:10.0.0.1\nrate:login:user:42\n```\n\nГлавное — чтобы по ключу было понятно, что именно вы ограничиваете.\n\n## Итого\n\n**Rate limiting на Redis** сводится к двум идеям:\n\n- простой счётчик с TTL для грубого лимита «N запросов за окно»;\n- упорядоченное множество с метками времени для более ровного скользящего окна.\n\nДальше всё зависит от логики приложения: где именно вы добавляете запрос в счётчик и как обрабатываете ситуацию, когда лимит превышен.\n"
    },
    {
      "title": "Очереди задач",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "03-task-queues",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/03-task-queues.ru.md",
      "content": "\n\nОчереди задач помогают вынести тяжёлую или долгую работу из основного потока приложения. Вместо того чтобы делать всё сразу во время HTTP-запроса, задача кладётся в очередь, а отдельный рабочий процесс (worker) забирает её и выполняет в фоне.\n\n## Простой вариант на списках\n\nСамый доступный вариант очереди в Redis — обычный список. Один или несколько производителей кладут задачи в список, а воркеры их забирают.\n\nПример: очередь писем.\n\nПроизводитель кладёт задачу:\n\n```\nLPUSH queue:email \"{\\\"to\\\":\\\"user@example.com\\\",\\\"subject\\\":\\\"Hello\\\"}\"\n```\n\nВоркер забирает задачи с конца списка:\n\n```\nRPOP queue:email\n```\n\nЕсли очередь пустая, RPOP вернёт пустой результат, и воркер может подождать перед следующей попыткой.\n\nЧтобы не опрашивать Redis в цикле, используют блокирующую команду:\n\n```\nBRPOP queue:email 5\n```\n\nКоманда ждёт до 5 секунд, пока не появится новый элемент. Если за это время ничего не пришло, возвращается пустой результат, и можно повторить попытку.\n\n**Плюсы списков:** простая модель, минимум команд, легко начать.\n\n## Несколько очередей и приоритеты\n\nЧасто задач несколько типов: срочные и обычные. Для этого удобно завести несколько списков.\n\nНапример:\n\n```\nLPUSH queue:email:high \"{...}\"\nLPUSH queue:email:default \"{...}\"\n```\n\nВоркер сначала пытается забрать задачу из приоритетной очереди, потом из обычной:\n\n```\nBRPOP queue:email:high queue:email:default 5\n```\n\nRedis сам вернёт задачу из первой непустой очереди.\n\n## Очередь на Streams\n\nСписки просты, но у них есть минус: если воркер забрал задачу и упал до обработки, задача потеряется. Потоки (Streams) дают более надёжную схему.\n\nПример очереди на Streams:\n\nДобавление задачи:\n\n```\nXADD queue:email * to \"user@example.com\" subject \"Hello\"\n```\n\nСоздание группы потребителей (делается один раз):\n\n```\nXGROUP CREATE queue:email workers $ MKSTREAM\n```\n\nЧтение задач воркером из группы:\n\n```\nXREADGROUP GROUP workers worker-1 COUNT 1 STREAMS queue:email >\n```\n\nПосле успешной обработки воркер подтверждает задачу:\n\n```\nXACK queue:email workers <id-записи>\n```\n\nЕсли воркер упал и не успел отправить XACK, запись можно забрать другим воркером из «подвисших» задач через XCLAIM или XPENDING. Так задачи не теряются.\n\n## Что класть в задачу\n\nОбычно в очередь кладут не весь объём данных, а только то, что нужно для повторного поиска:\n\n**Идентификатор.** Например, **user_id**, **order_id**, **notification_id**.\n\n**Тип действия.** Что именно нужно сделать: **send_email**, **rebuild_cache**, **generate_report**.\n\n**Минимальные параметры.** Всё, что нельзя потом достать из основной базы.\n\nПример полезной структуры для задачи:\n\n```\n{\n  \"type\": \"send_email\",\n  \"user_id\": 42,\n  \"template\": \"welcome\"\n}\n```\n\nВоркер по этим данным берёт остальное из основной базы и выполняет нужную операцию.\n\n## Итого\n\n**Очереди задач на Redis** позволяют разгружать основной поток приложения и выполнять тяжёлые операции в фоне. Для простых случаев достаточно списков и команд LPUSH/BRPOP. Когда важно не терять задачи и распределять их между несколькими воркерами, удобнее использовать Streams с группами потребителей."
    },
    {
      "title": "Pub/Sub",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "04-pubsub",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/04-pubsub.ru.md",
      "content": "\nPub/Sub в Redis — это способ отправлять сообщения сразу многим получателям. Один отправитель публикует событие в канал, а все подписчики этого канала получают его почти мгновенно.\n\nЭтот механизм удобен для чатов, уведомлений, сигналов между сервисами и любых ситуаций, где важно «рассказать всем, кто слушает, что что‑то произошло».\n\n## Основная идея\n\nЕсть три участника:\n\n**Канал.** Имя, по которому объединяются отправители и получатели. Например, news:sport.\n\n**Подписчик.** Клиент, который говорит Redis: «хочу получать всё из этого канала».\n\n**Публикатор.** Клиент или сервис, который отправляет сообщения в каналы.\n\nВажно: Pub/Sub не хранит историю. Сообщение видят только те, кто был подписан в момент отправки.\n\n## Простой пример\n\nОдин клиент подписывается на канал:\n\n```\nSUBSCRIBE news:sport\n```\n\nТеперь всё, что придёт в канал news:sport, сразу попадёт этому клиенту.\n\nДругой клиент публикует сообщение:\n\n```\nPUBLISH news:sport \"Гол на 90-й минуте\"\n```\n\nПодписчик увидит это сообщение мгновенно. Если в этот канал подписано несколько клиентов, все они получат один и тот же текст.\n\nЧтобы перестать слушать канал, можно отписаться:\n\n```\nUNSUBSCRIBE news:sport\n```\n\n## Шаблоны каналов\n\nЕсли нужно слушать сразу много каналов, удобно использовать шаблоны.\n\nПодписка по шаблону:\n\n```\nPSUBSCRIBE news:*\n```\n\nТак клиент получит сообщения из всех каналов, которые начинаются с news:. Например, news:sport, news:it, news:world.\n\nОтписка от шаблонов:\n\n```\nPUNSUBSCRIBE news:*\n```\n\n## Пример: уведомления для пользователей\n\nПусть у каждого пользователя есть свой канал уведомлений.\n\nСхема ключей для каналов:\n\n```\nnotifications:user:42\nnotifications:user:100\n```\n\nКлиент пользователя 42 подписывается на свой канал:\n\n```\nSUBSCRIBE notifications:user:42\n```\n\nКогда в системе что‑то происходит (новое сообщение, лайк, комментарий), сервер отправляет событие в нужный канал:\n\n```\nPUBLISH notifications:user:42 \"Новое сообщение в чате\"\n```\n\nКлиент сразу получает уведомление и может показать его в интерфейсе.\n\n## Когда Pub/Sub подходит, а когда нет\n\nPub/Sub хорошо работает, когда:\n\n**Нужна онлайн‑доставка.** Важны только те, кто сейчас подключён.\n\n**Сообщения одноразовые.** Не нужно хранить историю.\n\n**Много слушателей.** Одно сообщение сразу получает несколько клиентов.\n\nPub/Sub плохо подходит, когда:\n\n**Сообщения нельзя терять.** Если получатель отключился, событие ему не придёт.\n\n**Нужна история событий.** Нельзя «догнать» старые сообщения после переподключения.\n\nВ таких случаях лучше смотреть в сторону Streams или очередей задач.\n\n## Итого\n\nPub/Sub в Redis — простой способ делать вещание событий: отправитель публикует сообщение в канал, все подписчики получают его сразу. Никакой истории, только живой поток. Для чатов, сигналов между сервисами и онлайн‑уведомлений этого часто достаточно, особенно на ранних этапах проекта.\n"
    },
    {
      "title": "Хранение сессий",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 5,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "05-session-storage",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/05-session-storage.ru.md",
      "content": "\nХранение сессий в Redis позволяет быстро проверять, авторизован ли пользователь, и не нагружать основную базу лишними запросами. Сессия связывает случайный токен с информацией о пользователе и временем жизни.\n\n## Зачем хранить сессии в Redis\n\n**Redis** хорошо подходит для сессий, потому что:\n\n**Быстро.** Проверка токена — это один запрос к памяти.\n\n**Есть TTL.** Срок действия сессии задаётся автоматически и не требует ручной очистки.\n\n**Удобно масштабировать.** Несколько экземпляров приложения могут работать с одним Redis и видеть одни и те же сессии.\n\n## Простая схема сессии\n\nОбычно сессия выглядит так:\n\n- у пользователя есть случайный токен, который хранится в cookie или заголовке;\n- по этому токену в Redis лежит информация о пользователе.\n\nПример ключа для сессии:\n\n```\nsession:token:abc123\n```\n\nВнутри можно хранить:\n\n- идентификатор пользователя (**user_id**);\n- нужные флаги (например, **is_admin**);\n- время создания, если требуется.\n\nВ Redis это можно записать строкой (JSON) или хешем. Простейший вариант со строкой и временем жизни 30 минут:\n\n```\nSETEX session:token:abc123 1800 \"{\\\"user_id\\\":42}\"\n```\n\n## Создание сессии при логине\n\nПоследовательность шагов при успешном входе:\n\n1. Проверить логин и пароль в основной базе.\n2. Сгенерировать случайный токен.\n3. Сохранить сессию в Redis с TTL.\n4. Отдать токен клиенту.\n\nПример записи сессии в виде хеша:\n\n```\nHSET session:token:abc123 user_id 42\nEXPIRE session:token:abc123 1800\n```\n\nКлиент получает токен **abc123** и отправляет его с каждым запросом (через cookie или заголовок).\n\n## Проверка сессии при запросе\n\nНа каждом запросе сервер:\n\n1. Достаёт токен из cookie или заголовка.\n2. Проверяет, есть ли такая сессия в Redis.\n3. Если сессия найдена — считает пользователя авторизованным.\n\nПример проверки:\n\n```\nHGET session:token:abc123 user_id\n```\n\nЕсли Redis вернул значение, можно считать, что пользователь вошёл. Если пусто — сессия истекла или никогда не существовала.\n\nИногда при каждом запросе с TTL делают «продление» сессии:\n\n```\nEXPIRE session:token:abc123 1800\n```\n\nТак время жизни сдвигается вперёд, пока пользователь активен.\n\n## Выход из аккаунта\n\nПри выходе из аккаунта достаточно удалить запись о сессии:\n\n```\nDEL session:token:abc123\n```\n\nПосле этого токен больше не будет найден, и следующий запрос с этим токеном будет считаться неавторизованным.\n\nЕсли у пользователя много одновременных сессий (несколько устройств), можно делать ключи вида:\n\n```\nsession:user:42:device:phone\nsession:user:42:device:laptop\n```\n\nИ удалять только нужную сессию или сразу все, если требуется принудительный выход везде.\n\n## Итого\n\n**Сессии в Redis** — это связка «токен → данные пользователя с TTL». Приложение быстро проверяет токен, не ходит лишний раз в основную базу и может гибко управлять сроком жизни авторизации.\n\n"
    },
    {
      "title": "Реализация счетчиков и метрик",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 6,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "06-counters-and-metrics",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/06-counters-and-metrics.ru.md",
      "content": "\n\nСчётчики и метрики в Redis используют, чтобы быстро понимать, что происходит в системе: сколько раз нажали кнопку, сколько было логинов, просмотров страниц, ошибок и так далее. Всё держится на простых операциях инкремента.\n\n## Простые счётчики\n\nБазовый вариант — общий счётчик события. Например, сколько всего раз пользователи вошли в систему.\n\nУвеличить счётчик:\n\n```\nINCR metrics:logins\n```\n\nПрочитать текущее значение:\n\n```\nGET metrics:logins\n```\n\nКоманда **INCR** создаст ключ, если его ещё нет, и начнёт отсчёт с 1.\n\nАналогично можно считать клики по кнопке или отправки формы:\n\n```\nINCR metrics:click:buy\nINCR metrics:form:feedback:submit\n```\n\n## Счётчики по дням\n\nЧтобы не просто знать общий итог, а видеть статистику по времени, в ключ добавляют дату.\n\nНапример, логины по дням:\n\n```\nINCR metrics:logins:2025-11-21\n```\n\nПросмотры страницы:\n\n```\nINCR metrics:views:article:42:2025-11-21\n```\n\nТак легко построить график: приложение или аналитика просто считывают значения по датам.\n\nИногда у таких ключей задают время жизни, чтобы старая статистика не висела вечно:\n\n```\nEXPIRE metrics:views:article:42:2025-11-21 2592000\n```\n\nЗдесь данные удалятся через 30 дней.\n\n## Несколько метрик в одном ключе\n\nЕсли метрик много, удобно собирать их в один хеш.\n\nПример общего хеша по системе:\n\n```\nHINCRBY metrics:global logins 1\nHINCRBY metrics:global registrations 1\nHINCRBY metrics:global errors 1\n```\n\nПрочитать все значения сразу:\n\n```\nHGETALL metrics:global\n```\n\nТак можно быстро получить набор ключевых показателей без обхода десятков отдельных ключей.\n\n## Уникальные значения и HyperLogLog\n\nОбычный счётчик показывает количество событий, но не количество уникальных пользователей. Для приблизительного подсчёта уникальных значений в Redis есть **HyperLogLog**.\n\nДобавить пользователя в структуру:\n\n```\nPFADD metrics:uv:2025-11-21 user_42\n```\n\nПолучить оценку числа уникальных пользователей за день:\n\n```\nPFCOUNT metrics:uv:2025-11-21\n```\n\nЭто даёт быстрый и компактный способ считать уникальных посетителей, клиенты, сессии и другие объекты, которых может быть очень много.\n\n## Сброс и чтение показателей\n\nЕсли нужно обнулить счётчик, его просто удаляют:\n\n```\nDEL metrics:logins\n```\n\nИли сбрасывают только отдельное поле в хеше, записав нужное значение через **HSET**.\n\nДля сбора метрик приложение обычно:\n\n- увеличивает счётчики там, где происходят события;\n- периодически читает значения и отправляет их в систему мониторинга или отчётов.\n\n## Итого\n\nСчётчики и метрики в Redis строятся вокруг нескольких команд: **INCR**, **HINCRBY**, **PFADD**, **PFCOUNT**. С их помощью можно считать события, разрезать статистику по дням, хранить несколько показателей в одном ключе и оценивать количество уникальных пользователей без тяжёлых запросов к основной базе."
    },
    {
      "title": "RDB: снимки данных на диск",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "persistence",
      "sectionTitle": "Персистентность данных",
      "sectionOrder": 6,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "persistence",
        "slug": "01-rdb",
        "lang": "ru"
      },
      "path": "/content/materials/redis/persistence/01-rdb.ru.md",
      "content": "\nРежим **RDB** — это периодические снимки состояния Redis на диск. Сервер в какой‑то момент «замораживает» данные и записывает их в бинарный файл **RDB**, чтобы при перезапуске быстро восстановиться до этого состояния.\n\nТакой подход минимально влияет на производительность в обычное время и хорошо подходит для резервного копирования, но при аварии между снимками часть последних изменений может потеряться.\n\n## Как работает RDB на практике\n\nRedis сохраняет снимок либо по расписанию, либо по явной команде. Внутри используется механизм **BGSAVE**: сервер делает fork процесса, и дочерний процесс пишет данные в RDB‑файл, пока основной продолжает принимать команды.\n\nПосмотреть текущие настройки сохранения:\n\n```\nCONFIG GET save\nCONFIG GET dbfilename\nCONFIG GET dir\n```\n\nПример типичной конфигурации:\n\n```\nsave 900 1\nsave 300 10\nsave 60 10000\ndbfilename dump.rdb\ndir /var/lib/redis\n```\n\nЭто значит, что Redis создаст snapshot, если за 900 секунд произошёл хотя бы 1 апдейт, или за 300 секунд — 10 апдейтов, или за 60 секунд — 10000 апдейтов.\n\n## Ручное создание snapshot\n\nИногда нужно сделать снимок «по требованию», например перед обновлением приложения.\n\nСинхронное сохранение (блокирует сервер):\n\n```\nSAVE\n```\n\nАсинхронное сохранение (рекомендуется для продакшена):\n\n```\nBGSAVE\n```\n\nПосле **BGSAVE** в каталоге **dir** появится обновлённый **dump.rdb**. Этот файл можно:\n\n- скопировать на удалённый сервер как резервную копию;\n- использовать для поднятия тестового окружения;\n- хранить в бэкап‑хранилище вместе с другими бэкапами.\n\n## Что происходит при перезапуске\n\nКогда Redis стартует и находит в каталоге **dump.rdb**, он:\n\n1. Загружает данные из RDB в память.\n2. Начинает принимать команды, как обычно.\n\nВсе изменения, сделанные после последнего snapshot, будут потеряны. Если, например, RDB создавался раз в 5 минут, а сервер упал через 4 минуты после сохранения, эти 4 минуты операций не восстановятся.\n\nПоэтому RDB воспринимают как вариант «периодической» персистентности, где допускается небольшой временной лаг в данных.\n\n## Когда RDB уместен, а когда нет\n\nRDB хорошо подходит для:\n\n- резервного копирования состояния Redis;\n- сценариев, где допустима потеря части последних данных;\n- относительно спокойных по записи систем, где snapshot не слишком нагружает диск и память.\n\nRDB хуже подходит, когда:\n\n- важна почти нулевая потеря данных при сбое;\n- нагрузка на запись высокая, и частые snapshot создают заметную нагрузку;\n- Redis используется как основной источник финансовых или других критичных данных.\n\nВ таких случаях RDB часто комбинируют с **AOF** или включают отдельные механизмы репликации и бэкапов.\n\n## Итог\n\nRDB — это простой и быстрый способ периодически сохранять состояние Redis на диск в одном бинарном файле.\n\nЭтот режим почти не мешает производительности в обычной работе и удобен для бэкапов, но всегда нужно помнить, что между снимками часть недавних операций может быть потеряна при аварийном перезапуске.\n\n\n"
    },
    {
      "title": "AOF: журнал команд",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "persistence",
      "sectionTitle": "Персистентность данных",
      "sectionOrder": 6,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "persistence",
        "slug": "02-aof",
        "lang": "ru"
      },
      "path": "/content/materials/redis/persistence/02-aof.ru.md",
      "content": "\nРежим **AOF** (Append Only File) записывает каждую команду изменения данных в журнал на диск. При перезапуске Redis читает этот журнал и «проигрывает» команды заново, восстанавливая состояние почти до момента сбоя.\n\nЗа счёт этого AOF даёт более надёжную персистентность, чем одни только RDB‑снимки, но требует аккуратных настроек и периодической перепаковки файла.\n\n## Как устроен AOF\n\nКогда AOF включён, Redis:\n\n1. При каждом изменении данных дописывает команду в AOF‑файл.\n2. Периодически «сбрасывает» буфер на диск в зависимости от настроек синхронизации.\n3. В фоне может переписывать файл, убирая из него лишние старые команды.\n\nОсновные настройки можно посмотреть так:\n\n```\nCONFIG GET appendonly\nCONFIG GET appendfilename\nCONFIG GET appendfsync\n```\n\nЕсли **appendonly** равен yes, то режим AOF включён. Имя файла по умолчанию — **appendonly.aof**.\n\n## Настройка частоты fsync\n\nКлючевой параметр, влияющий на надёжность и производительность, — **appendfsync**. Он определяет, как часто Redis будет вызывать fsync для записи данных на диск.\n\nВарианты:\n\n```\nCONFIG SET appendfsync always\nCONFIG SET appendfsync everysec\nCONFIG SET appendfsync no\n```\n\nСмысл:\n\n- **always** — fsync после каждой команды. Максимальная надёжность, но может сильно замедлить запись.\n- **everysec** — fsync раз в секунду. Компромисс: в худшем случае теряется около секунды данных.\n- **no** — Redis полагается на буферы ОС. Быстро, но потеря последних изменений при сбое может быть больше.\n\nНа практике чаще всего выбирают **everysec** как баланс между безопасностью и скоростью.\n\n## Включение AOF на живом инстансе\n\nЕсли AOF был выключен, его можно включить без остановки сервера:\n\n```\nCONFIG SET appendonly yes\n```\n\nRedis:\n\n1. Создаст начальный AOF‑файл на основе текущего состояния (под капотом использует RDB + преобразование в набор команд).\n2. Начнёт дописывать новые команды в файл.\n\nЭтот процесс может занять время и временно увеличить нагрузку на диск и память, поэтому включать AOF лучше в спокойный период.\n\n## Перепаковка AOF (AOF rewrite)\n\nСо временем AOF‑файл растёт, потому что в нём остаются старые команды, которые много раз перезаписывали одни и те же ключи. Чтобы файл не раздувался бесконечно, Redis умеет переписывать его в компактный вариант.\n\nЯвный запуск перепаковки:\n\n```\nBGREWRITEAOF\n```\n\nRedis:\n\n1. Создаёт новый временный AOF‑файл с «сжатым» набором команд.\n2. В момент переключения аккуратно заменяет старый файл новым.\n\nТипичный пример:\n\n- старый файл содержит множество SET одного и того же ключа;\n- новый файл будет содержать только один последний SET, который даёт то же итоговое состояние.\n\nПерепаковка может запускаться автоматически при росте файла, если настроены соответствующие параметры в конфиге.\n\n## Когда AOF уместен\n\nРежим AOF хорошо подходит, когда:\n\n- важна минимальная потеря данных при сбое;\n- Redis хранит критичную бизнес‑информацию, а не только кэш;\n- нужно иметь детальный журнал операций для отладки или анализа.\n\nНужно учитывать:\n\n- AOF создаёт дополнительную нагрузку на диск;\n- при некорректных настройках appendfsync запись может стать узким местом;\n- при очень высоких нагрузках на запись иногда используют отдельные инстансы под AOF и под кэш.\n\nЧасто AOF комбинируют с RDB, чтобы ускорить запуск и иметь два независимых источника восстановления.\n\n## Итог\n\n**AOF** превращает Redis в систему с почти непрерывной персистентностью: каждая команда записывается в журнал и может быть воспроизведена после перезапуска.\n\nГрамотный выбор режима **appendfsync**, регулярная перепаковка AOF‑файла и понимание нагрузок на диск позволяют использовать этот механизм без ощутимого удара по производительности.\n\n\n"
    },
    {
      "title": "Комбинированные режимы RDB + AOF",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "persistence",
      "sectionTitle": "Персистентность данных",
      "sectionOrder": 6,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "persistence",
        "slug": "03-combined-modes",
        "lang": "ru"
      },
      "path": "/content/materials/redis/persistence/03-combined-modes.ru.md",
      "content": "\nВ реальных системах редко ограничиваются только RDB или только AOF. Чаще всего их комбинируют: RDB даёт быстрый старт с готовым снимком, а AOF добавляет поверх почти непрерывный журнал изменений.\n\nТакой гибридный режим позволяет ускорить запуск, повысить надёжность и иметь два независимых источника восстановления.\n\n## Как Redis сочетает RDB и AOF\n\nКогда включены оба механизма:\n\n- Redis периодически делает RDB‑snapshot (по настройкам **save**);\n- параллельно каждое изменение записывается в **AOF**;\n- при запуске сервер по умолчанию сначала пытается загрузить AOF, а если его нет или он повреждён — использует RDB.\n\nПорядок загрузки можно проверить и настроить в конфиге, но общая идея проста: AOF считается более «свежим» источником, потому что хранит последние команды.\n\n## Типичная схема: RDB для бэкапов, AOF для минимума потерь\n\nОдин из рабочих вариантов:\n\n1. Оставить включённые snapshot через **save** для периодических RDB‑файлов.\n2. Включить AOF с режимом **appendfsync everysec**.\n3. Настроить автоматическую перепаковку AOF.\n\nКонфигурация будет выглядеть примерно так:\n\n```\nsave 900 1\nsave 300 10\nsave 60 10000\n\nappendonly yes\nappendfilename \"appendonly.aof\"\nappendfsync everysec\n```\n\nВ этом режиме:\n\n- RDB‑файлы удобно использовать для бэкапов и переноса данных;\n- AOF даёт возможность восстановиться почти до момента сбоя с потерей максимум одной секунды изменений.\n\n## Оптимизация запуска: AOF поверх RDB\n\nДля очень больших баз запуск только по AOF может быть медленным: Redis нужно прочитать и выполнить большой журнал команд. Чтобы ускорить старт, есть механизм создания «сложного» AOF на основе snapshot.\n\nСхема работы:\n\n1. Redis делает RDB‑snapshot.\n2. Этот snapshot конвертируется в AOF‑формат как набор начальных команд.\n3. Поверх него продолжается обычный лог AOF.\n\nКоманды управления зависят от конкретной версии Redis, но общая идея в том, чтобы:\n\n- хранить компактное начальное состояние (аналог RDB);\n- иметь короткий хвост AOF с последними изменениями.\n\nЭто уменьшает время запуска и размер файла, сохраняя при этом семантику журнала команд.\n\n## Когда комбинированный режим оправдан\n\nИмеет смысл включать оба механизма, когда:\n\n- Redis хранит данные, потеря которых нежелательна;\n- нужен удобный способ регулярно забирать снимки для бэкапов;\n- объём данных достаточно большой, чтобы волноваться о времени старта и размере AOF.\n\nВместе с этим:\n\n- растёт нагрузка на диск (snapshot + журнал);\n- нужно внимательно следить за настройками памяти и частотой BGSAVE и BGREWRITEAOF;\n- важно мониторить время выполнения фоновых операций, чтобы они не пересекались в самый неудачный момент.\n\nЕсли же Redis используется как чистый кэш, а потеря данных при перезапуске некритична, комбинированный режим чаще всего избыточен — достаточно настроить политику вытеснения и, при необходимости, отдельные RDB‑snapshot для диагностики.\n\n## Итог\n\nКомбинация **RDB + AOF** даёт более гибкий и надёжный вариант персистентности: быстрый старт с готовым снимком и минимальную потерю данных за счёт журнала команд.\n\nВажно подобрать частоту snapshot, режим **appendfsync** и стратегию перепаковки AOF так, чтобы баланс между надёжностью, скоростью и нагрузкой на диск соответствовал реальным требованиям проекта.\n\n\n"
    },
    {
      "title": "Настройки персистентности и бэкапы",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "persistence",
      "sectionTitle": "Персистентность данных",
      "sectionOrder": 6,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "persistence",
        "slug": "04-persistence-settings-and-backups",
        "lang": "ru"
      },
      "path": "/content/materials/redis/persistence/04-persistence-settings-and-backups.ru.md",
      "content": "\nДаже зная разницу между **RDB** и **AOF**, легко запутаться в реальных настройках: как часто делать snapshot, какой режим **appendfsync** выбрать, куда складывать файлы и как организовать бэкапы.\n\nЗадача этого раздела — дать практичные схемы настройки персистентности под разные сценарии и показать простые приёмы резервного копирования Redis.\n\n## Базовые настройки персистентности\n\nПроверить текущие параметры можно так:\n\n```\nCONFIG GET save\nCONFIG GET appendonly\nCONFIG GET appendfsync\nCONFIG GET dir\nCONFIG GET dbfilename\nCONFIG GET appendfilename\n```\n\nЭти команды показывают:\n\n- расписание snapshot (**save**);\n- включён ли AOF (**appendonly**);\n- частоту fsync для AOF (**appendfsync**);\n- каталог и имена файлов для RDB и AOF.\n\nМенять настройки на лету можно через **CONFIG SET**, но для долгосрочных конфигураций лучше фиксировать их в redis.conf и держать под контролем через систему управления конфигурациями.\n\n## Сценарий: Redis как кэш\n\nЕсли Redis используется только как кэш, основной источник данных находится в другой базе, а потеря содержимого Redis не критична.\n\nПрактичная схема:\n\n- отключить snapshot и AOF;\n- настроить лимит памяти и политику вытеснения.\n\nПример:\n\n```\nCONFIG SET save \"\"\nCONFIG SET appendonly no\n\nCONFIG SET maxmemory 2gb\nCONFIG SET maxmemory-policy allkeys-lru\n```\n\nВ этом режиме Redis не делает дисковые записи ради персистентности, работает максимально быстро, а восстановление после перезапуска сводится к прогреву кэша из основного хранилища.\n\n## Сценарий: Redis хранит важные данные\n\nЕсли Redis хранит сессии, очереди задач или бизнес‑данные, которые терять нельзя, имеет смысл включить и RDB, и AOF.\n\nПример настроек:\n\n```\nsave 900 1\nsave 300 10\nsave 60 10000\n\nappendonly yes\nappendfilename \"appendonly.aof\"\nappendfsync everysec\n```\n\nВажные моменты:\n\n- **appendfsync everysec** даёт баланс между скоростью и надёжностью;\n- snapshot по **save** создают регулярные RDB‑файлы, удобные для бэкапов;\n- лог AOF позволяет восстановиться почти до момента сбоя.\n\nДополнительно стоит включить репликацию на резервный инстанс и следить за временем выполнения BGSAVE и BGREWRITEAOF по метрикам.\n\n## Простые бэкапы RDB и AOF\n\nБэкап Redis сводится к копированию файлов RDB и, при необходимости, AOF.\n\nАлгоритм для RDB:\n\n1. Убедиться, что snapshot свежий (при необходимости вызвать **BGSAVE**).\n2. Подождать завершения сохранения (по логам или метрикам).\n3. Скопировать файл **dump.rdb** в безопасное хранилище.\n\nПример ручной последовательности:\n\n```\nBGSAVE\n```\n\nпосле завершения:\n\n```\ncp /var/lib/redis/dump.rdb /backups/redis/dump-2025-11-23.rdb\n```\n\nЕсли используется AOF:\n\n1. Убедиться, что нет активного BGREWRITEAOF.\n2. При желании запустить **BGREWRITEAOF**, чтобы получить компактный файл.\n3. Скопировать **appendonly.aof** в хранилище бэкапов.\n\nВ продакшене эти шаги обычно автоматизируют скриптами и кронами или средствами оркестрации.\n\n## Практические советы по персистентности\n\nНесколько правил, которые часто спасают от проблем:\n\n- выбирать режимы персистентности под конкретный сценарий, а не «на всякий случай всё включить»;\n- не запускать **SAVE** на больших базах, использовать только **BGSAVE**;\n- не забывать про влияние RDB и AOF на память и диск при настройке **maxmemory**;\n- регулярно проверять, что файлы RDB и AOF реально попадают в внешние бэкапы;\n- периодически тестировать восстановление на отдельном стенде, а не надеяться, что всё заработает само.\n\n## Итог\n\nНастройки персистентности в **Redis** — это компромисс между скоростью, надёжностью и простотой эксплуатации.\n\nЕсли осознанно выбирать между режимами «только кэш», «критичные данные» и гибридными схемами, а бэкапы делать и проверять регулярно, Redis остаётся предсказуемым и надёжным даже в сложных продакшен‑окружениях.\n\n\n"
    },
    {
      "title": "Принципы репликации",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "replication",
      "sectionTitle": "Репликация",
      "sectionOrder": 7,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "replication",
        "slug": "01-principles",
        "lang": "ru"
      },
      "path": "/content/materials/redis/replication/01-principles.ru.md",
      "content": "\n**Репликация** в Redis позволяет копировать данные с одного узла на один или несколько реплик. Основной узел принимает записи, а реплики получают поток изменений и поддерживают у себя почти такое же состояние. Это нужно для отказоустойчивости и разгрузки чтения.\n\nБазовая идея: есть один ведущий сервер, который принимает все изменения, и несколько ведомых, которые синхронно или с небольшой задержкой подтягивают данные.\n\n## Роль master и replica\n\nВ простейшем варианте конфигурации есть:\n\n- один основной узел, который принимает команды записи;\n- несколько реплик, которые получают данные только от master.\n\nПосмотреть роли можно через:\n\n```\nINFO replication\n```\n\nНа master вывод будет содержать примерно такое:\n\n```\nrole:master\nconnected_slaves:1\nslave0:ip=10.0.0.2,port=6379,state=online,offset=12345,lag=0\n```\n\nНа реплике:\n\n```\nrole:slave\nmaster_host:10.0.0.1\nmaster_port:6379\nmaster_link_status:up\n```\n\nПо умолчанию реплики работают только на чтение. Это защищает от случайных изменений данных на нескольких узлах и упрощает логику приложения: все записи идут в один master.\n\n## Односторонний поток данных\n\nРепликация в Redis всегда идёт в одну сторону: replica копирует состояние с master, но не наоборот.\n\nПри первом подключении реплика:\n\n1. Запрашивает полную синхронизацию.\n2. Получает snapshot данных от master.\n3. Применяет к себе этот snapshot.\n4. Дальше принимает поток новых команд и применяет их по мере прихода.\n\nЕсли соединение временно обрывается, Redis пытается сделать частичную синхронизацию, используя журнал смещений, чтобы не пересылать всю базу заново. Но в простом понимании важно помнить: master считается источником правды, а replica — копией.\n\n## Зачем нужна репликация\n\nРепликация решает сразу несколько задач:\n\n- распределение нагрузки по чтению — запросы могут идти на реплики;\n- резервная копия данных в реальном времени;\n- подготовка площадки для быстрого переключения в случае сбоя master.\n\nТипичные сценарии:\n\n- выделить master для записи, а отчётные запросы и тяжёлые чтения отправлять на реплики;\n- держать одну replica в другом датацентре для аварийного восстановления;\n- использовать набор master и нескольких replica как основу для автоматического failover через Sentinel или кластер.\n\n## Итог\n\nРепликация в **Redis** строится вокруг простой модели master–replica: один узел принимает изменения, остальные получают от него поток данных и поддерживают актуальное состояние.\n\nТакой подход помогает масштабировать чтение и повышать отказоустойчивость, не усложняя приложение сложной логикой записи на несколько узлов одновременно.\n\n\n"
    },
    {
      "title": "Настройка master–replica",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "replication",
      "sectionTitle": "Репликация",
      "sectionOrder": 7,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "replication",
        "slug": "02-master-replica",
        "lang": "ru"
      },
      "path": "/content/materials/redis/replication/02-master-replica.ru.md",
      "content": "\nНастроить схему master–replica в Redis можно двумя способами: через конфигурационные файлы при запуске или через команды во время работы сервера. В обоих случаях идея одна и та же — указать реплике, у какого master она должна забирать данные.\n\nРазберём минимальную конфигурацию и практические команды, которые пригодятся в разработке и продакшене.\n\n## Базовая конфигурация через redis.conf\n\nПредставим, что у нас два сервера:\n\n- основной: **10.0.0.1:6379**;\n- реплика: **10.0.0.2:6379**.\n\nНа master конфигурация может быть минимальной:\n\n```\nbind 0.0.0.0\nport 6379\n```\n\nНа реплике достаточно указать, откуда брать данные:\n\n```\nbind 0.0.0.0\nport 6379\n\nreplicaof 10.0.0.1 6379\n```\n\nПосле запуска:\n\n- master принимает все записи;\n- replica подключается к master, делает полную синхронизацию и дальше подтягивает изменения.\n\nПроверить роли можно командой:\n\n```\nINFO replication\n```\n\nНа реплике важно держать включённым режим только для чтения, чтобы случайно не писать в неё напрямую:\n\n```\nreplica-read-only yes\n```\n\n## Настройка через команды во время работы\n\nИногда удобнее настраивать репликацию «на лету» без перезапуска.\n\nПусть Redis уже запущен на обоих серверах. Тогда на реплике достаточно выполнить:\n\n```\nREPLICAOF 10.0.0.1 6379\n```\n\nС этого момента узел станет replica указанного master. Если позднее нужно вернуть его к одиночному режиму:\n\n```\nREPLICAOF NO ONE\n```\n\nЭта команда отключает репликацию, и узел снова становится самостоятельным master с теми данными, которые у него есть.\n\nПолезно проверять текущую роль:\n\n```\nROLE\n```\n\nОтвет покажет, является ли сервер master, replica и какие есть соединения.\n\n## Настройка доступа и безопасности\n\nЕсли на master включена авторизация, реплика должна знать пароль, чтобы подключиться.\n\nНа master:\n\n```\nrequirepass \"strong-master-password\"\n```\n\nНа реплике:\n\n```\nmasterauth \"strong-master-password\"\nreplicaof 10.0.0.1 6379\n```\n\nВ новых версиях можно использовать ACL и более гибкие правила, но базовая идея остаётся той же: реплика аутентифицируется к master и после этого начинает получать данные.\n\nВажно:\n\n- не использовать один и тот же Redis для разных окружений (dev, stage, prod);\n- ограничивать доступ по сети к портам Redis;\n- следить, чтобы реплика не «убежала» синхронизироваться с неправильным master.\n\n## Итог\n\nНастройка master–replica в **Redis** сводится к простым шагам: указать реплике адрес master, проверить роли и, при необходимости, настроить авторизацию.\n\nДальше Redis сам берёт на себя полную и частичную синхронизацию, а задача разработчика — правильно встроить эту схему в инфраструктуру и не писать напрямую в реплики.\n\n\n"
    },
    {
      "title": "Поведение при сбоях",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "replication",
      "sectionTitle": "Репликация",
      "sectionOrder": 7,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "replication",
        "slug": "03-failover-behavior",
        "lang": "ru"
      },
      "path": "/content/materials/redis/replication/03-failover-behavior.ru.md",
      "content": "\nРепликация в Redis сама по себе не даёт автоматического переключения при сбоях, но задаёт базовую модель, как система ведёт себя, когда падает master или отваливается сеть. Понимание этого поведения важно, чтобы не потерять данные и правильно строить сценарии аварийного восстановления.\n\nРазберём типичные ситуации: отказ master, потеря связи с replica и ручной перевод роли.\n\n## Если упал master\n\nКогда основной узел недоступен:\n\n- записи на него перестают работать — приложение получает ошибки подключения;\n- реплики продолжают обслуживать запросы на чтение с теми данными, которые у них уже есть;\n- репликация останавливается до восстановления связи.\n\nПриложение может временно переключить чтение на реплики, но записи всё равно придётся куда‑то направлять. Без Sentinel или кластера переключение ролей происходит вручную.\n\nПростой сценарий ручного failover:\n\n1. Убедиться, что master действительно недоступен и не вернётся.\n2. Выбрать одну из реплик как новую основную.\n3. На этой реплике выполнить:\n\n```\nREPLICAOF NO ONE\n```\n\nТеперь узел станет самостоятельным master. Приложение переводит записи на этот адрес.\n\n## Если потерялась связь с репликой\n\nКогда сеть между master и replica рвётся:\n\n- master продолжает работать как обычно;\n- replica перестаёт получать новые данные, но всё ещё обслуживает чтение на своём старом состоянии;\n- в **INFO replication** на master видно, что состояние реплики offline, а offset не растёт.\n\nЕсли реплика используется для чтения, важно понимать, что данные на ней могут отставать на минуту, час или дольше, в зависимости от того, сколько длится проблема с сетью.\n\nКогда связь восстанавливается, Redis пытается сделать частичную синхронизацию. Если это невозможно (слишком большое отставание, переполнен журнал), происходит полная ресинхронизация заново.\n\n## Риск потери данных при принудительном переключении\n\nВ ручном failover есть важная тонкость. Если:\n\n- master успел принять часть записей;\n- эти записи ещё не долетели до replica из‑за задержки или сети;\n- мы переводим replica в master;\n\nто эти «последние» записи на старом master будут потеряны.\n\nПоэтому:\n\n- при возможности стоит использовать Sentinel или кластер, которые учитывают задержки и согласованность;\n- в критичных системах полезно применять команду **WAIT**, чтобы убедиться, что запись дошла до нужного числа реплик:\n\n```\nSET user:42:name \"Alice\"\nWAIT 1 1000\n```\n\nЗдесь Redis вернёт, на сколько реплик запись точно дошла за 1000 миллисекунд. Это не полностью решает проблему, но даёт больше контроля.\n\n## Автоматический failover: куда смотреть дальше\n\nЧистая репликация решает задачу копирования данных, но не управляет ролями master и replica. Для автоматического переключения при сбоях используют:\n\n- **Redis Sentinel** — наблюдает за узлами, голосует о недоступности master и продвигает одну из реплик;\n- **Redis Cluster** — распределяет данные по шартам и имеет встроенный механизм failover.\n\nОсновные принципы остаются прежними, но логика выбора нового master и перенастройки клиентов перекладывается на инфраструктуру.\n\n## Итог\n\nПри сбоях в репликации **Redis** ведёт себя предсказуемо: master остаётся единственной точкой записи, реплики продолжают обслуживать чтение, а переключение ролей нужно делать вручную или через Sentinel и кластер.\n\nЕсли учитывать возможное отставание реплик и аккуратно подходить к ручному failover, можно избежать потери последних записей и построить надёжную схему аварийного восстановления.\n\n\n"
    },
    {
      "title": "Синхронизация и задержки",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "replication",
      "sectionTitle": "Репликация",
      "sectionOrder": 7,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "replication",
        "slug": "04-sync-and-lag",
        "lang": "ru"
      },
      "path": "/content/materials/redis/replication/04-sync-and-lag.ru.md",
      "content": "\nРепликация в Redis асинхронная: master не ждёт, пока все реплики применят изменения, прежде чем ответить клиенту. Это делает систему очень быстрой, но всегда оставляет небольшой риск отставания и потери части последних данных при сбое.\n\nЧтобы управлять этим риском, важно понимать, как работает синхронизация, как измерять задержки и в каких ситуациях имеет смысл ждать подтверждения от реплик.\n\n## Полная и частичная синхронизация\n\nПри первом подключении replica делает полную синхронизацию:\n\n1. master создаёт snapshot и отправляет его реплике;\n2. replica загружает snapshot и применяет его;\n3. после этого replica продолжает принимать поток новых команд.\n\nЕсли соединение временно обрывается, Redis пытается использовать частичную синхронизацию. Для этого он:\n\n- ведёт журнал смещений репликации (offset);\n- хранит недавние команды в буфере.\n\nЕсли отставание реплики укладывается в этот буфер, мастер досылает только недостающие команды. Если нет — запускается новая полная синхронизация.\n\nПонять, что происходит, можно через:\n\n```\nINFO replication\n```\n\nТам видно смещения, состояние связей и отставание по каждой реплике.\n\n## Измерение задержек между master и replica\n\nВ разделе репликации **INFO** показывает показатель **lag** для каждой реплики:\n\n```\nslave0:ip=10.0.0.2,port=6379,state=online,offset=12345,lag=1\n```\n\nПолезные значения:\n\n- **lag** — сколько секунд прошло с момента последнего подтверждения от replica;\n- **offset** — позиция в потоке репликации.\n\nЕсли **lag** растёт и долго держится на больших значениях, это сигнал, что:\n\n- сеть между master и replica нестабильна;\n- ресурсы на реплике не успевают переваривать поток команд;\n- или есть проблемы с диском, если включены тяжёлые режимы персистентности.\n\nТакие ситуации стоит мониторить и настраивать алерты.\n\n## Когда надо ждать подтверждения от реплик (WAIT)\n\nДля операций, которые нельзя потерять, Redis предлагает команду **WAIT**. Она позволяет дождаться, пока данные будут гарантированно записаны на заданное число реплик.\n\nПример:\n\n```\nSET order:501 \"...\"\nWAIT 1 1000\n```\n\nЗдесь:\n\n- первое число — сколько реплик нужно дождаться;\n- второе — таймаут в миллисекундах.\n\nRedis вернёт число реплик, которые подтвердили запись за отведённое время. Если это число меньше ожидаемого, приложение может принять решение:\n\n- повторить операцию позже;\n- зафиксировать факт частичной репликации;\n- временно остановить критичные операции.\n\nВажно помнить, что **WAIT** увеличивает задержку ответа для клиента и не превращает Redis в полностью синхронную систему, но даёт больше контроля для отдельных особо важных операций.\n\n## Практические рекомендации по работе с задержками\n\nНесколько рабочих правил:\n\n- не считать, что replica всегда идеально синхронизирована с master — небольшое отставание нормально;\n- мониторить **lag** и **offset** через **INFO replication**;\n- аккуратно относиться к чтению с реплик там, где нужны строго консистентные данные;\n- использовать **WAIT** только для критичных операций, где допустима дополнительная задержка;\n- следить, чтобы полная синхронизация не запускалась слишком часто — это признак проблем с сетью, памятью или конфигурацией.\n\n## Итог\n\nСинхронизация и задержки в репликации **Redis** — это баланс между скоростью и консистентностью: асинхронная модель делает систему очень быстрой, но требует осознанного отношения к отставанию реплик.\n\nЕсли регулярно смотреть на метрики репликации и точечно использовать инструменты вроде **WAIT**, можно контролировать риск потери данных и при этом не потерять главное преимущество Redis — высокую производительность.\n\n\n"
    },
    {
      "title": "Базовая защита Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "security",
        "slug": "01-basic-security",
        "lang": "ru"
      },
      "path": "/content/materials/redis/security/01-basic-security.ru.md",
      "content": "\nПо умолчанию **Redis** настроен скорее для доверенной среды: локальная разработка, внутренняя сеть, отсутствие прямого доступа из интернета. В продакшене такой подход опасен — сервер может стать открытым для всех, кто видит его порт.\n\nНачинать защиту Redis стоит с трёх вещей: сетевые ограничения, базовая аутентификация и отключение лишних команд в уязвимой среде.\n\n## Сетевые ограничения: bind и protected-mode\n\nПервый слой — не давать лишнего сетевого доступа к Redis.\n\nТипичная безопасная настройка:\n\n```\nbind 127.0.0.1\nprotected-mode yes\nport 6379\n```\n\nСмысл:\n\n- bind 127.0.0.1 — принимать подключения только с локальной машины;\n- protected-mode yes — включён защищённый режим, который запрещает опасные операции при подозрительной конфигурации.\n\nЕсли нужно принимать подключения по сети, лучше явно указать адрес внутреннего интерфейса и защитить доступ firewall, VPN или отдельным уровнем прокси:\n\n```\nbind 10.0.0.10\nprotected-mode yes\n```\n\nОткрывать Redis напрямую в интернет почти никогда не нужно и очень рискованно.\n\n## Пароль и команда AUTH\n\nДаже во внутренней сети стоит включить аутентификацию.\n\nВ конфиге:\n\n```\nrequirepass \"strong-password\"\n```\n\nПосле этого любой клиент должен сначала аутентифицироваться:\n\n```\nAUTH strong-password\nSET cache:page:/ \"...\"\n```\n\nПростые правила:\n\n- использовать длинный случайный пароль;\n- не хранить пароль в открытом виде в репозиториях;\n- передавать пароль в переменных окружения или менеджере секретов.\n\nЕсли требуется несколько ролей с разными правами, лучше использовать ACL, о которых пойдёт речь отдельно.\n\n## Отключение опасных команд\n\nНа некоторых окружениях имеет смысл отключить команды, которые позволяют вызывать shell или управлять модулями.\n\nПримеры:\n\n```\nrename-command FLUSHALL \"\"\nrename-command FLUSHDB \"\"\nrename-command CONFIG \"\"\nrename-command SHUTDOWN \"\"\n```\n\nПустая строка в качестве нового имени фактически отключает команду. Это не защита от всего, но позволяет случайно не стереть данные через FLUSHALL или не дать внешнему пользователю крутить CONFIG.\n\nВажные моменты:\n\n- такие настройки нужно хорошо документировать для команды;\n- инструменты администрирования Redis должны учитывать, что некоторые команды переименованы или отключены.\n\n## Итог\n\nБазовая защита **Redis** — это в первую очередь про сетевую изоляцию, включённый protected-mode, адекватный bind и обязательную аутентификацию.\n\nЕсли с самого начала ограничить доступ к серверу и отключить самые опасные команды в продакшене, риск случайных и умышленных проблем с безопасностью резко снижается даже до внедрения более сложных механизмов.\n\n\n"
    },
    {
      "title": "ACL и разграничение прав",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "security",
        "slug": "02-acl",
        "lang": "ru"
      },
      "path": "/content/materials/redis/security/02-acl.ru.md",
      "content": "\nПароль на весь Redis — это минимум. В более сложных системах хочется давать разным сервисам разные права: одним только чтение, другим ограниченный набор команд, третьим полный доступ. Для этого в **Redis** есть **ACL** — списки контроля доступа.\n\nИдея проста: создаём пользователей с разными правами, выдаём каждому свои учётные данные и описываем, что им можно.\n\n## Просмотр и базовые команды ACL\n\nПосмотреть текущих пользователей:\n\n```\nACL LIST\n```\n\nПолучить информацию о конкретном пользователе:\n\n```\nACL GETUSER default\n```\n\nСоздать нового пользователя и выдать ему права:\n\n```\nACL SETUSER app-reader on >strong-pass ~* +GET +MGET +INFO\n```\n\nРазбор:\n\n- on — включить пользователя;\n- >strong-pass — задать пароль;\n- ~* — разрешить доступ ко всем ключам (ограничения по шаблонам разберём ниже);\n- +GET +MGET +INFO — список разрешённых команд.\n\nПосле этого клиент может аутентифицироваться как app-reader:\n\n```\nAUTH app-reader strong-pass\nGET cache:article:42\n```\n\n## Ограничения по ключам\n\nКроме команд, можно ограничивать доступ по шаблонам ключей.\n\nПример: сервис, который должен видеть только свои ключи сессий.\n\nСоздадим пользователя:\n\n```\nACL SETUSER session-service on >session-pass ~session:* +GET +SET +DEL\n```\n\nЗдесь:\n\n- ~session:* — разрешён доступ только к ключам, начинающимся с session:;\n- +GET +SET +DEL — можно читать, записывать и удалять свои сессии.\n\nЕсли такой пользователь попробует обратиться к cache:article:42, Redis вернёт ошибку доступа.\n\n## Разделение ролей по сервисам\n\nПрактичный подход — завести отдельных пользователей под разные типы сервисов:\n\n- для фоновых задач — право на чтение и запись очередей и кэша;\n- для публичного API — ограниченный набор чтений и безопасных записей;\n- для административных инструментов — расширенный набор команд.\n\nПримеры:\n\nСервис кэша:\n\n```\nACL SETUSER cache-service on >cache-pass ~cache:* +GET +SET +DEL +EXPIRE\n```\n\nСервис метрик:\n\n```\nACL SETUSER metrics-service on >metrics-pass ~metrics:* +INCR +GET +MGET\n```\n\nАдмин:\n\n```\nACL SETUSER admin on >admin-pass allcommands allkeys\n```\n\nТакой расклад позволяет, даже при утечке одного пароля, сильно ограничить ущерб.\n\n## Итог\n\nACL в **Redis** позволяют задать тонкую модель доступа: какие команды доступны, к каким ключам можно обращаться и под какими учётными данными работает каждый сервис.\n\nЕсли для разных частей системы завести отдельных пользователей с минимально необходимыми правами, даже компрометация одной учётной записи не даст злоумышленнику полный контроль над всей базой.\n\n\n"
    },
    {
      "title": "Сетевая безопасность и TLS",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "security",
        "slug": "03-network-and-tls",
        "lang": "ru"
      },
      "path": "/content/materials/redis/security/03-network-and-tls.ru.md",
      "content": "\nДаже при правильных паролях и ACL Redis остаётся уязвимым, если его можно перехватить по сети: трафик без шифрования легко читать и подменять. Поэтому в продакшене важно одновременно ограничить сеть и, при необходимости, включить **TLS**.\n\nПрактически это сводится к трём шагам: изоляция по сети, защита порта Redis и настройка шифрования.\n\n## Изоляция по сети\n\nПервая линия защиты — не выпускать Redis в открытый мир.\n\nТипичные приёмы:\n\n- помещать Redis в приватную подсеть;\n- разрешать к нему доступ только с адресов приложений;\n- закрывать внешний порт на уровне firewall.\n\nПример грубой, но показательной настройки firewall на сервере:\n\n```\niptables -A INPUT -p tcp --dport 6379 -s 10.0.0.0/24 -j ACCEPT\niptables -A INPUT -p tcp --dport 6379 -j DROP\n```\n\nЗдесь 6379 открыт только для подсети 10.0.0.0/24. Остальные подключения режутся ещё до попадания в Redis.\n\nВ оркестраторах вроде Kubernetes те же правила реализуются через NetworkPolicy и настройки сервисов.\n\n## Включение TLS на стороне Redis\n\nНачиная с современных версий, Redis умеет принимать TLS‑подключения напрямую.\n\nВ конфиге:\n\n```\nport 0\ntls-port 6379\n\ntls-cert-file /etc/redis/tls/redis.crt\ntls-key-file /etc/redis/tls/redis.key\ntls-ca-cert-file /etc/redis/tls/ca.crt\n```\n\nЗдесь:\n\n- port 0 — отключаем нешифрованный порт;\n- tls-port 6379 — включаем порт только под TLS;\n- tls-cert-file, tls-key-file, tls-ca-cert-file — путь к сертификату, ключу и корневому сертификату.\n\nПосле этого клиенты должны подключаться с поддержкой TLS:\n\n```\nredis-cli -h my-redis-host -p 6379 --tls \\\n  --cert /etc/redis/tls/client.crt \\\n  --key /etc/redis/tls/client.key \\\n  --cacert /etc/redis/tls/ca.crt\n```\n\nВ бою сертификаты обычно выдаются через корпоративный PKI или автоматизированные системы вроде cert-manager.\n\n## TLS через прокси\n\nЕсли по каким‑то причинам нет возможности собрать Redis с поддержкой TLS, можно использовать внешний прокси.\n\nИдея:\n\n- Redis слушает только на локальном адресе без TLS;\n- снаружи доступен только прокси (например, stunnel, Envoy, Nginx‑стрим), который принимает TLS и прокидывает трафик внутрь.\n\nСхема:\n\n- приложение → TLS → прокси → plain‑TCP → Redis.\n\nПлюсы:\n\n- не нужно трогать конфиг Redis;\n- проще унифицировать шифрование для нескольких сервисов;\n- сертификатами управляет один слой.\n\nМинусы:\n\n- дополнительный компонент в инфраструктуре;\n- важно следить за его отказоустойчивостью и масштабированием.\n\n## Итог\n\nСетевая безопасность в **Redis** начинается с изоляции по сети и правильного bind, а завершается шифрованием трафика через TLS либо на самом Redis, либо через внешний прокси.\n\nЕсли не выпускать порт Redis в интернет, ограничивать список клиентов и шифровать соединения между датацентрами и внешними сервисами, риск перехвата и подмены данных заметно снижается.\n\n\n"
    },
    {
      "title": "Безопасность данных и бэкапы",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "security",
        "slug": "04-data-security-and-backups",
        "lang": "ru"
      },
      "path": "/content/materials/redis/security/04-data-security-and-backups.ru.md",
      "content": "\nПомимо защиты доступа к самому Redis, важно подумать о том, что происходит с данными на диске и в бэкапах. Если RDB‑ и AOF‑файлы лежат в открытом виде, их кража может быть не менее опасна, чем прямой доступ к серверу.\n\nЗадача — сделать так, чтобы потеря диска или бэкапного хранилища не означала автоматическую утечку всех пользовательских данных.\n\n## Где лежат файлы Redis\n\nСначала нужно чётко понимать, где именно находятся данные Redis.\n\nПосмотреть настройки:\n\n```\nCONFIG GET dir\nCONFIG GET dbfilename\nCONFIG GET appendfilename\n```\n\nТипичный ответ:\n\n```\ndir /var/lib/redis\ndbfilename dump.rdb\nappendfilename appendonly.aof\n```\n\nЭто означает, что:\n\n- snapshot RDB лежит в /var/lib/redis/dump.rdb;\n- журнал AOF — в /var/lib/redis/appendonly.aof.\n\nИменно эти файлы нужно включать в зону повышенной защиты: права доступа, мониторинг, шифрование диска.\n\n## Права доступа и изоляция на сервере\n\nМинимальные меры:\n\n- запускать Redis под отдельным пользователем (например, redis);\n- ограничить доступ к каталогу данных:\n\n```\nchown -R redis:redis /var/lib/redis\nchmod 700 /var/lib/redis\n```\n\nТак только пользователь redis будет иметь прямой доступ к файлам RDB и AOF. Остальные пользователи системы не смогут просто так их прочитать.\n\nВ контейнерных и облачных окружениях аналогичные ограничения задаются через политики безопасности и права на volume.\n\n## Шифрование диска и бэкапов\n\nЧтобы кража диска или snapshot в облаке не привела к мгновенной утечке, стоит использовать шифрование:\n\n- на уровне файловой системы (LUKS, BitLocker, eCryptfs и аналоги);\n- на уровне облачного диска (встроенное шифрование в облаке);\n- на уровне бэкапного хранилища (S3‑совместимые хранилища с включённым encryption at rest).\n\nАлгоритм простой:\n\n1. Включить шифрование для дисков, где лежит каталог Redis.\n2. Включить шифрование для хранилища бэкапов.\n3. Следить, чтобы ключи шифрования хранились отдельно от данных и были защищены.\n\nТак даже физическая кража диска не позволит прочитать содержимое без доступа к ключам.\n\n## Чувствительные данные в Redis\n\nОтдельный вопрос — какие именно данные вы кладёте в Redis.\n\nПрактика:\n\n- по возможности избегать хранения «голых» персональных данных (ФИО, адреса, документы);\n- для особо чувствительных полей использовать шифрование на уровне приложения и хранить в Redis уже зашифрованные значения;\n- не кэшировать в Redis то, что нельзя безопасно восстановить или аннулировать.\n\nПример:\n\nвместо хранения телефона как есть:\n\n```\nSET user:42:phone \"+123456789\"\n```\n\nприложение может хранить зашифрованную строку, а ключи шифрования держать отдельно, например в KMS:\n\n```\nSET user:42:phone \"ENC:.....\"\n```\n\nДаже если кто‑то прочитает dump.rdb, расшифровать содержимое без доступа к KMS будет значительно сложнее.\n\n## Итог\n\nБезопасность данных в **Redis** — это не только пароли и ACL, но и защита RDB/AOF‑файлов, дисков и бэкапов, а также осознанный подход к тому, какие данные и в каком виде мы туда кладём.\n\nЕсли ограничить права доступа к файлам, шифровать хранилища и не хранить в Redis лишнюю чувствительную информацию в открытом виде, последствия утечки или кражи инфраструктуры будут гораздо менее критичными.\n\n\n"
    },
    {
      "title": "Типичные ошибки безопасности",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 5,
      "id": {
        "category": "redis",
        "section": "security",
        "slug": "05-common-mistakes",
        "lang": "ru"
      },
      "path": "/content/materials/redis/security/05-common-mistakes.ru.md",
      "content": "\nБольшинство проблем безопасности с **Redis** возникают не из‑за сложных уязвимостей, а из‑за простых ошибок в конфигурации. Сервер оказывается доступен из интернета, пароли лежат в репозитории, а дампы данных никто не защищает.\n\nНиже — короткий список типичных промахов и способов их избежать.\n\n## Открытый Redis в интернет\n\nКлассическая ошибка — поднять Redis с bind 0.0.0.0 и без firewall.\n\nПример опасной конфигурации:\n\n```\nbind 0.0.0.0\nprotected-mode no\nrequirepass \"\"\n```\n\nТакой сервер становится добычей для автоматических сканеров: любой, кто найдёт порт 6379, может выполнять команды, читать и стирать данные.\n\nКак правильно:\n\n- не публиковать Redis напрямую в интернет;\n- использовать приватные сети, VPN и firewall;\n- включать protected-mode и аккуратно настраивать bind.\n\n## Отсутствие аутентификации и ACL\n\nЕщё одна частая проблема — отсутствие пароля и единый доступ ко всему Redis.\n\nОшибочный подход:\n\n- rely только на «внутреннюю сеть»;\n- использовать один пароль для всего и всех сервисов.\n\nЛучше:\n\n- всегда задавать requirepass или ACL;\n- создавать отдельных пользователей для разных сервисов;\n- выдавать каждому минимально необходимый набор команд и ключей.\n\n## Пароли и конфиги в репозитории\n\nДаже при хорошей настройке Redis можно всё испортить, если положить пароли и ключи в git.\n\nТипичный антипример:\n\n- redis.conf с реальными паролями в репозитории;\n- docker-compose.yml с открытыми секретами;\n- README с реальными командами AUTH.\n\nЛучше:\n\n- хранить секреты в менеджерах вроде Vault или встроенных секрета‑хранилищах облака;\n- передавать пароли через переменные окружения или отдельные файлы, не попадающие в git;\n- использовать шаблоны конфигураций с подстановкой секретов на этапе деплоя.\n\n## Незащещённые дампы и бэкапы\n\nДаже если сам Redis хорошо спрятан, RDB/AOF‑файлы и бэкапы часто лежат без шифрования и с широкими правами доступа.\n\nОшибки:\n\n- каталоги с dump.rdb и appendonly.aof доступны всем пользователям на сервере;\n- бэкапы в облаке не шифруются;\n- доступ к бэкапному хранилищу не ограничен.\n\nЧто делать:\n\n- ограничить права на каталог данных Redis;\n- включить шифрование дисков и хранилищ бэкапов;\n- регулярно проверять, кто имеет доступ к этим данным.\n\n## Игнорирование обновлений\n\nRedis активно развивается, и вместе с новыми фичами выходят исправления безопасности. Оставлять продакшен на старой версии на годы вперёд — рискованно.\n\nПрактичные шаги:\n\n- следить за релизами Redis и changelog;\n- периодически обновлять версию на стендах и в продакшене;\n- иметь простой процесс отката на прошлую версию в случае проблем.\n\n## Итог\n\nТипичные ошибки безопасности в **Redis** почти всегда связаны с простыми вещами: неправильный bind, отсутствие аутентификации, открытые в репозитории пароли и незащищённые бэкапы.\n\nЕсли осознанно пройтись по этим пунктам и привести конфигурацию в порядок, уровень защиты Redis заметно вырастет, не усложняя архитектуру и не требуя экзотических решений.\n\n\n"
    },
    {
      "title": "Принципы работы",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "streams",
      "sectionTitle": "Redis Streams",
      "sectionOrder": 4,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "streams",
        "slug": "01-principles",
        "lang": "ru"
      },
      "path": "/content/materials/redis/streams/01-principles.ru.md",
      "content": "\n**Redis Streams** — это способ работать с событиями как с непрерывной лентой записей. Вместо того чтобы просто хранить значение по ключу, мы получаем упорядоченный поток сообщений, к которому можно подключаться, читать новые элементы и обрабатывать их как очередь задач или лог событий.\n\nГлавная идея проста: в поток постоянно добавляются новые события, каждое получает уникальный идентификатор и набор полей. Клиенты могут читать эти события с нужного места, не теряя порядок, и строить вокруг этого надёжную обработку.\n\n## Поток как лог событий\n\nУ обычных структур данных в Redis мы работаем с текущим состоянием: значение ключа, содержимое списка, хеша или множества. В **Streams** мы работаем с историей изменений — каждое событие добавляется в конец потока и остаётся там, пока мы его явно не удалим или не обрежем.\n\nПредставим поток событий заказов:\n\n```\nXADD orders:stream * user_id 123 status \"created\" amount 1000\nXADD orders:stream * user_id 456 status \"paid\" amount 500\nXADD orders:stream * user_id 123 status \"shipped\" amount 1000\n```\n\nКаждый вызов **XADD** добавляет запись в конец **orders:stream** и возвращает её идентификатор вида время-последовательность, например:\n\n```\n1698249572-0\n1698249573-0\n1698249574-0\n```\n\nБазовая модель простая:\n\n- поток — это упорядоченная лента событий;\n- каждое событие имеет уникальный идентификатор;\n- данные события — это набор полей и значений.\n\nТакой подход удобно использовать для логов, журналов действий пользователей, бизнес-событий между сервисами.\n\n## Структура записи в потоке\n\nКаждое сообщение в **Streams** — это пара: идентификатор и набор полей. Полей может быть сколько угодно, главное — соблюдать разумную схему.\n\nТипичная запись для логирования действий пользователя:\n\n```\nXADD user:activity:stream * user_id 123 action \"login\" ip \"10.0.0.5\"\nXADD user:activity:stream * user_id 123 action \"view_page\" page \"/products/42\"\nXADD user:activity:stream * user_id 789 action \"logout\" reason \"timeout\"\n```\n\nЗдесь есть несколько важных моментов:\n\n- ключ потока **user:activity:stream** явно говорит о назначении;\n- поле **user_id** позволяет связать события с конкретным пользователем;\n- поля **action**, **page**, **ip**, **reason** дают контекст для аналитики и отладки.\n\nКогда позже мы будем читать поток, эти же поля используются для разбора сообщения и принятия решения, что с ним делать.\n\n## Идентификаторы сообщений и порядок\n\nИдентификатор в **Streams** обычно генерируется автоматически с помощью звёздочки:\n\n```\nXADD metrics:payments:stream * status \"ok\" amount 150\n```\n\nRedis подставляет текущее время и счётчик, формируя значение вида время-последовательность. Это обеспечивает строгий порядок: новые сообщения всегда идут после старых.\n\nИдентификаторы используются:\n\n- чтобы читать поток начиная с нужного места;\n- чтобы не пропускать сообщения при повторных чтениях;\n- чтобы понимать, какие события уже были обработаны.\n\nБазовое чтение потока выглядит так:\n\n```\nXREAD COUNT 2 STREAMS orders:stream 0-0\n```\n\nКоманда вернёт первые две записи из **orders:stream**, начиная с самого начала. Специальный идентификатор 0-0 означает «читать с начала потока». Если вместо него подставить последний прочитанный идентификатор, можно продолжить чтение с нужного места.\n\n## Когда Streams подходят, а когда нет\n\n**Streams** логичнее всего использовать там, где есть последовательность событий, которые нужно обрабатывать по порядку или раздавать нескольким потребителям:\n\n- логирование действий пользователей;\n- события от микросервисов;\n- очереди задач с подтверждением обработки;\n- аналитические события для последующей агрегации.\n\nЕсли задача — просто хранить последнее состояние объекта, например текущий баланс или актуальный профиль пользователя, **Streams** будут излишни. В таких случаях проще и дешевле по памяти использовать строки или хеши.\n\nВажно понимать, что поток сам по себе не очищается. Если не использовать обрезку, он будет расти бесконечно. В разделах про команды и очереди сообщений мы разберём, как управлять размером потока и не давать ему разрастаться.\n\n## Итог\n\n**Redis Streams** дают удобную модель лога событий: каждая запись добавляется в конец потока, получает уникальный идентификатор и остаётся доступной для чтения и повторной обработки.\n\nЭта структура идеально подходит для задач, где важна история и порядок событий, а не только текущее состояние. Главное — сразу продумать схему ключей, поля сообщений и политику очистки, чтобы поток оставался управляемым и полезным."
    },
    {
      "title": "XADD, XREAD, XGROUP",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "streams",
      "sectionTitle": "Redis Streams",
      "sectionOrder": 4,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "streams",
        "slug": "02-xadd-xread-xgroup",
        "lang": "ru"
      },
      "path": "/content/materials/redis/streams/02-xadd-xread-xgroup.ru.md",
      "content": "\nВ основе работы с **Redis Streams** лежат три команды: **XADD** для записи сообщений, **XREAD** для чтения и **XGROUP** для создания и управления группами потребителей. На практике этого уже достаточно, чтобы построить простую очередь задач или обработку событий между сервисами.\n\nРазберём, как они работают на реальных примерах: от простого «написать и прочитать» до подготовки потока к использованию с группами.\n\n## XADD — добавление сообщений в поток\n\nКоманда **XADD** добавляет новое сообщение в конец потока. Минимальный вариант:\n\n```\nXADD orders:stream * user_id 123 status \"created\" amount 1000\n```\n\nЧто здесь происходит:\n\n- создаётся поток **orders:stream**, если его ещё нет;\n- символ звёздочки говорит Redis сгенерировать идентификатор автоматически;\n- дальше идут пары поле–значение: **user_id 123**, **status \"created\"**, **amount 1000**.\n\nВ ответ Redis вернёт идентификатор сообщения, например:\n\n```\n\"1698249601-0\"\n```\n\nЕсли нужно ограничивать размер потока, можно сразу включить обрезку:\n\n```\nXADD orders:stream MAXLEN 1000 * user_id 123 status \"created\" amount 1000\n```\n\nВ этом случае в потоке будет храниться примерно 1000 последних записей, более старые Redis будет удалять по мере добавления новых. Это удобно для логов и аналитики, где не нужна бесконечная история.\n\n## XREAD — чтение сообщений из потока\n\nКоманда **XREAD** читает сообщения из одного или нескольких потоков. Простейший пример — прочитать всё с начала:\n\n```\nXREAD COUNT 3 STREAMS orders:stream 0-0\n```\n\nЗдесь:\n\n- **COUNT 3** ограничивает количество возвращаемых сообщений;\n- **STREAMS orders:stream** указывает, из какого потока читать;\n- **0-0** означает «начать с самого начала потока».\n\nОбычно **XREAD** используют для чтения только новых сообщений. Для этого вместо конкретного идентификатора передают доллар:\n\n```\nXREAD BLOCK 5000 STREAMS orders:stream $\n```\n\nВажные детали:\n\n- **$** означает «ждать только новые сообщения, которых ещё нет у клиента»;\n- **BLOCK 5000** говорит: подождать до 5 секунд появления новых данных, затем вернуть управление даже если сообщений нет.\n\nТак клиент может держать соединение с Redis и получать события почти в реальном времени, не опрашивая сервер в цикле.\n\nЕсли поток не существует, **XREAD** просто вернёт пустой результат. Ошибки не будет — это нужно учитывать в приложении и, при необходимости, создавать поток через **XADD** заранее.\n\n## XGROUP — подготовка потока для групп потребителей\n\nГруппы потребителей — это ключевая возможность **Streams**, которая позволяет нескольким воркерам обрабатывать поток, не дублируя работу. Чтобы использовать группы, поток сначала нужно подготовить командой **XGROUP CREATE**.\n\nСоздадим поток задач на отправку писем и группу обработчиков:\n\n```\nXGROUP CREATE email:tasks:stream email-workers 0-0 MKSTREAM\n```\n\nЗдесь:\n\n- **email:tasks:stream** — ключ потока;\n- **email-workers** — имя группы;\n- **0-0** — с какого идентификатора считать сообщения доступными группе;\n- **MKSTREAM** говорит Redis создать поток, если его ещё нет.\n\nЧаще на практике используют специальное значение доллара:\n\n```\nXGROUP CREATE email:tasks:stream email-workers $ MKSTREAM\n```\n\nТак группа начнёт работу только с новыми сообщениями, которые появятся после создания, не затрагивая старую историю.\n\nЕсли попытаться создать группу повторно с теми же именами потока и группы, Redis вернёт ошибку. Поэтому в автоматических скриптах часто используют вариант с игнорированием ошибки на создание или проверяют наличие группы заранее.\n\n## Связка XADD, XREAD и XGROUP в живой системе\n\nРеальная схема обычно выглядит так:\n\n1. Один или несколько сервисов добавляют задачи в поток с помощью **XADD**.\n2. Поток один раз подготавливается под группы с помощью **XGROUP CREATE**.\n3. Воркеры читают сообщения уже не через **XREAD**, а через **XREADGROUP** (об этом подробно в следующем разделе).\n\nПример — постановка задач на отправку писем:\n\nСоздание группы:\n\n```\nXGROUP CREATE email:tasks:stream email-workers $ MKSTREAM\n```\n\nДобавление задач:\n\n```\nXADD email:tasks:stream * user_id 123 template \"welcome\"\nXADD email:tasks:stream * user_id 456 template \"reset_password\"\n```\n\nЧтение новых задач без групп (для простого потребителя или отладки):\n\n```\nXREAD COUNT 10 STREAMS email:tasks:stream 0-0\n```\n\nВ боевом варианте вместо этого используют чтение через **XREADGROUP**, чтобы распределять задачи между несколькими воркерами и подтверждать успешную обработку.\n\n## Итог\n\nКоманды **XADD**, **XREAD** и **XGROUP** формируют базовый набор для работы с **Redis Streams**: первая пишет события, вторая читает их, третья готовит поток к распределённой обработке через группы потребителей.\n\nПонимание этих команд позволяет уже на этом уровне построить простую, но рабочую систему очередей и логов. В следующем разделе мы углубимся в **Consumer Groups** и посмотрим, как организовать надёжную обработку сообщений несколькими воркерами с подтверждением и повторными попытками."
    },
    {
      "title": "Consumer Groups",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "streams",
      "sectionTitle": "Redis Streams",
      "sectionOrder": 4,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "streams",
        "slug": "03-consumer-groups",
        "lang": "ru"
      },
      "path": "/content/materials/redis/streams/03-consumer-groups.ru.md",
      "content": "\n**Consumer Groups** в **Redis Streams** позволяют нескольким воркерам безопасно обрабатывать один и тот же поток сообщений, не дублируя работу и не теряя события. Каждый воркер входит в группу, получает свою порцию задач и подтверждает обработку, чтобы Redis мог переотдать незавершённые сообщения при сбоях.\n\nЕсли смотреть на это практическими глазами, Consumer Groups — это способ построить пул воркеров поверх одного потока: сколько бы экземпляров сервиса ни работало, каждое сообщение будет обработано ровно одним из них.\n\n## Базовая схема работы группы\n\nПредставим поток задач на обработку заказов:\n\n```\nXGROUP CREATE orders:stream orders-workers $ MKSTREAM\n```\n\nДальше в приложении поднимаются несколько воркеров, каждый со своим именем потребителя внутри группы:\n\n```\nXREADGROUP GROUP orders-workers worker-1 COUNT 10 STREAMS orders:stream >\nXREADGROUP GROUP orders-workers worker-2 COUNT 10 STREAMS orders:stream >\n```\n\nВажные детали:\n\n- **orders-workers** — имя группы потребителей;\n- **worker-1** и **worker-2** — имена конкретных потребителей (экземпляров сервиса);\n- символ **>** говорит «дай мне только новые сообщения, которые ещё никому не назначены».\n\nRedis раздаёт новые сообщения между потребителями внутри группы. Если воркеров несколько, задачи распределяются по ним, как в очереди.\n\n## Подтверждение обработки: XACK и PEL\n\nКогда воркер прочитал сообщение через **XREADGROUP** и успешно его обработал, он обязан подтвердить это командой **XACK**:\n\n```\nXACK orders:stream orders-workers 1698249601-0\n```\n\nЗдесь:\n\n- **orders:stream** — поток;\n- **orders-workers** — группа;\n- **1698249601-0** — идентификатор обработанного сообщения.\n\nПока подтверждения нет, сообщение считается «висящим» в специальном списке PEL (Pending Entries List). Посмотреть такие сообщения можно через **XPENDING**:\n\n```\nXPENDING orders:stream orders-workers\n```\n\nВ ответ Redis покажет:\n\n- сколько сообщений «в работе»;\n- минимальный и максимальный идентификаторы;\n- примеры по потребителям.\n\nЭто особенно полезно, когда один из воркеров упал и не успел подтвердить обработку. Сообщения не пропадают, их можно перераспределить.\n\n## Повторная выдача сообщений другим воркерам\n\nЕсли потребитель перестал отвечать, сообщения, которые числятся за ним в PEL, можно вручную или программно передать другому воркеру. Для этого используется команда **XCLAIM**.\n\nПример: за **worker-1** «зависли» сообщения, которые висят дольше 60 секунд. Мы хотим передать их **worker-2**:\n\nСначала смотрим, какие сообщения зависли у **worker-1**:\n\n```\nXPENDING orders:stream orders-workers - + 10 worker-1\n```\n\nДопустим, среди них есть **1698249601-0**. Тогда:\n\n```\nXCLAIM orders:stream orders-workers worker-2 60000 1698249601-0\n```\n\nЗдесь:\n\n- **worker-2** забирает себе сообщение;\n- **60000** — минимальное время в миллисекундах, которое сообщение должно провести в PEL, прежде чем его можно будет «забрать».\n\nПосле успешной обработки новый воркер так же делает **XACK**, и сообщение окончательно считается завершённым.\n\n## Типичный цикл жизни сообщения в группе\n\nЕсли собрать всё вместе, жизнь одной записи в **Streams** с Consumer Groups выглядит так:\n\n1. Продюсер добавляет запись в поток через **XADD**.\n2. Группа уже создана командой **XGROUP CREATE**.\n3. Один из воркеров читает запись через **XREADGROUP** с маркером **>**.\n4. Redis назначает сообщение этому потребителю и помещает его в PEL.\n5. Воркер обрабатывает задачу и вызывает **XACK**.\n6. Сообщение остаётся в потоке как часть истории, но больше не считается «висящим» в группе.\n\nЕсли воркер падает между шагами 3 и 5, сообщение остаётся в PEL и может быть перераспределено через **XPENDING** и **XCLAIM**.\n\n## Когда стоит использовать Consumer Groups\n\nConsumer Groups особенно полезны в сценариях:\n\n- есть поток задач, которые должны быть выполнены ровно один раз;\n- нагрузка плавает, и нужно просто добавлять или убирать воркеры;\n- важно не терять сообщения при падении отдельных экземпляров сервиса;\n- несколько сервисов читают один и тот же поток по-разному — для этого можно создать несколько независимых групп на одном потоке.\n\nЕсли же есть всего один потребитель, который читает поток линейно, можно обойтись обычным **XREAD** и собственным хранением последнего прочитанного идентификатора. Consumer Groups здесь дадут больше сложности, чем пользы.\n\n## Итог\n\n**Consumer Groups** превращают Redis Streams в полноценную основу для распределённых очередей: сообщения раздаются между воркерами, отслеживаются в PEL, подтверждаются и при необходимости перераспределяются.\n\nТакой подход позволяет строить надёжные системы обработки задач без потерь и дублирования, сохраняя при этом всю историю событий в самом потоке."
    },
    {
      "title": "Построение очередей сообщений",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "streams",
      "sectionTitle": "Redis Streams",
      "sectionOrder": 4,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "streams",
        "slug": "04-message-queues",
        "lang": "ru"
      },
      "path": "/content/materials/redis/streams/04-message-queues.ru.md",
      "content": "\nС помощью **Redis Streams** можно строить надёжные очереди сообщений: один или несколько сервисов кладут задачи в поток, а группа воркеров забирает их, обрабатывает и подтверждает выполнение. В отличие от простых списков, здесь есть подтверждение обработки, повторная выдача задач при сбоях и возможность масштабировать потребителей.\n\nРазберём, как собрать рабочую очередь пошагово: от постановки задач до обработки и очистки.\n\n## Очередь задач на одном потоке\n\nБазовая модель очереди — один поток для задач и одна группа потребителей.\n\nСоздадим поток и группу для воркеров, которые рассылают письма:\n\n```\nXGROUP CREATE email:tasks:stream email-workers $ MKSTREAM\n```\n\nТеперь любой сервис может положить задачу в очередь:\n\n```\nXADD email:tasks:stream * user_id 123 template \"welcome\"\nXADD email:tasks:stream * user_id 456 template \"reset_password\"\n```\n\nВоркеры читают задачи из группы:\n\n```\nXREADGROUP GROUP email-workers worker-1 COUNT 5 STREAMS email:tasks:stream >\n```\n\nКаждый воркер:\n\n- получает набор задач;\n- обрабатывает каждую (например, отправляет письмо);\n- подтверждает обработку через **XACK**:\n\n```\nXACK email:tasks:stream email-workers 1698249601-0 1698249602-0\n```\n\nТак формируется классическая очередь: задачи приходят в поток, распределяются по воркерам и отмечаются как выполненные.\n\n## Масштабирование: несколько воркеров и балансировка\n\nЧтобы увеличить пропускную способность, достаточно добавить ещё воркеры с разными именами потребителей в той же группе:\n\n```\nXREADGROUP GROUP email-workers worker-2 COUNT 5 STREAMS email:tasks:stream >\nXREADGROUP GROUP email-workers worker-3 COUNT 5 STREAMS email:tasks:stream >\n```\n\nRedis сам будет раздавать новые сообщения между **worker-1**, **worker-2**, **worker-3**. Сообщение попадает только одному потребителю, поэтому работа не дублируется.\n\nЕсли один из воркеров падает, его незавершённые сообщения остаются в PEL. Их можно:\n\n- либо автоматически переобрабатывать тем же воркером после перезапуска;\n- либо вручную перераспределить через **XPENDING** и **XCLAIM**, как описано в разделе про Consumer Groups.\n\nТаким образом, очередь остаётся живой даже при частичных сбоях.\n\n## Ограничение размера очереди и очистка\n\nЕсли в очередь постоянно добавляются новые задачи, важно не дать потоку вырасти бесконечно. Для этого используют обрезку через **MAXLEN** в **XADD**:\n\n```\nXADD email:tasks:stream MAXLEN 10000 * user_id 123 template \"welcome\"\n```\n\nЗдесь в потоке в среднем будет примерно 10000 последних задач. Старые записи удаляются. Для обычных рабочих очередей этого достаточно: нас интересуют только актуальные задачи.\n\nИногда нужно жёстко ограничить размер, чтобы контролировать память. Тогда используют опцию **MAXLEN ~** или без тильды — чем строже ограничение, тем чаще Redis будет тратить ресурсы на поддержание длины.\n\nЕсли требуется полностью очистить очередь, можно удалить поток:\n\n```\nDEL email:tasks:stream\n```\n\nПосле этого при первом **XADD** поток создастся заново, но группы потребителей тоже исчезнут. В боевых системах чаще регулируют длину и периодически чистят старые данные, не удаляя поток полностью.\n\n## Разделение очередей по типам задач\n\nВ реальных системах удобно делить очереди по типам работ:\n\n- **email:tasks:stream** — отправка писем;\n- **billing:tasks:stream** — операции с оплатами;\n- **reports:tasks:stream** — генерация отчётов.\n\nКаждая очередь получает свою группу потребителей и набор воркеров. Например, для биллинга создадим отдельную группу:\n\n```\nXGROUP CREATE billing:tasks:stream billing-workers $ MKSTREAM\n```\n\nПостановка задачи:\n\n```\nXADD billing:tasks:stream * user_id 999 type \"invoice\" amount 2500\n```\n\nОбработка:\n\n```\nXREADGROUP GROUP billing-workers billing-1 COUNT 5 STREAMS billing:tasks:stream >\n```\n\nТак можно независимо масштабировать только те очереди, которые действительно нагружены, не трогая остальные.\n\n## Итог\n\n**Redis Streams** позволяют строить очереди сообщений с подтверждением обработки, перераспределением «зависших» задач и масштабированием воркеров через Consumer Groups.\n\nПри грамотной схеме ключей, ограничении длины потока и аккуратной работе с подтверждениями получается гибкий и надёжный механизм фоновой обработки задач, который легко вписывается в микросервисную архитектуру."
    },
    {
      "title": "Практические сценарии",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "streams",
      "sectionTitle": "Redis Streams",
      "sectionOrder": 4,
      "order": 5,
      "id": {
        "category": "redis",
        "section": "streams",
        "slug": "05-practical-scenarios",
        "lang": "ru"
      },
      "path": "/content/materials/redis/streams/05-practical-scenarios.ru.md",
      "content": "\n**Redis Streams** хорошо раскрываются на живых задачах: когда нужно передать событие между сервисами, организовать фоновые работы или собрать последовательный лог действий пользователей. Ниже — несколько типичных сценариев, которые легко повторить и адаптировать под свои проекты.\n\nКаждый пример опирается на уже знакомые команды **XADD**, **XREAD**, **XGROUP** и **XREADGROUP**.\n\n## Фоновые задачи: отправка писем и уведомлений\n\nКлассика для Streams — вынести отправку писем, пушей и других уведомлений в отдельную очередь, чтобы не блокировать основной HTTP-запрос.\n\nПостановка задач в очередь:\n\n```\nXGROUP CREATE notify:tasks:stream notify-workers $ MKSTREAM\n\nXADD notify:tasks:stream * user_id 123 type \"email\" template \"welcome\"\nXADD notify:tasks:stream * user_id 456 type \"push\" template \"promo\" channel \"mobile\"\n```\n\nВоркеры читают задачи и обрабатывают их:\n\n```\nXREADGROUP GROUP notify-workers worker-1 COUNT 10 STREAMS notify:tasks:stream >\n```\n\nПосле успешной отправки:\n\n```\nXACK notify:tasks:stream notify-workers 1698249601-0 1698249602-0\n```\n\nТакое разделение позволяет:\n\n- не держать пользователя в ожидании долгой отправки;\n- масштабировать только воркеры уведомлений при росте нагрузки;\n- гибко управлять повторами при временных ошибках внешних сервисов.\n\n## Лог действий пользователей для аналитики\n\nВместо того чтобы сразу писать каждое действие в тяжёлую базу, можно сначала собрать события в поток, а затем асинхронно выгружать их в хранилище аналитики.\n\nЗапись событий:\n\n```\nXADD analytics:user:activity:stream * user_id 123 action \"view_page\" page \"/products/42\"\nXADD analytics:user:activity:stream * user_id 123 action \"add_to_cart\" product_id 42\nXADD analytics:user:activity:stream * user_id 789 action \"search\" query \"laptop\"\n```\n\nСервис аналитики периодически читает новые записи:\n\n```\nXREAD COUNT 100 STREAMS analytics:user:activity:stream $\n```\n\nЛибо работает через свою группу:\n\n```\nXGROUP CREATE analytics:user:activity:stream analytics-workers $ MKSTREAM\nXREADGROUP GROUP analytics-workers etl-1 COUNT 100 STREAMS analytics:user:activity:stream >\n```\n\nПреимущества:\n\n- события не теряются, даже если аналитическое хранилище временно недоступно;\n- можно повторно прогнать историю для отладки или перерасчёта метрик;\n- нагрузка на основную базу снижается, так как запись идёт батчами.\n\n## Шина событий между микросервисами\n\nStreams удобно использовать как простую шину событий: один сервис публикует бизнес-события, остальные подписываются на них через свои группы.\n\nПродюсер заказов пишет в поток:\n\n```\nXADD events:orders:stream * event \"order_created\" order_id 501 user_id 123 amount 1500\nXADD events:orders:stream * event \"order_cancelled\" order_id 502 user_id 456 reason \"payment_failed\"\n```\n\nСервис биллинга создаёт свою группу и реагирует только на нужные события:\n\n```\nXGROUP CREATE events:orders:stream billing-subscribers $ MKSTREAM\nXREADGROUP GROUP billing-subscribers billing-1 COUNT 10 STREAMS events:orders:stream >\n```\n\nСервис уведомлений делает то же самое, но обрабатывает события по-своему:\n\n```\nXGROUP CREATE events:orders:stream notify-subscribers $ MKSTREAM\nXREADGROUP GROUP notify-subscribers notify-1 COUNT 10 STREAMS events:orders:stream >\n```\n\nКаждая группа видит все события независимо от других и ведёт свой прогресс чтения. Это позволяет легко добавлять новые потребители, не меняя продюсера.\n\n## Ограничение скоростей и «умные» очереди\n\nStreams можно использовать как основу для rate limiting и более сложных схем обработки, когда важно не только выполнить задачи, но и соблюдать ограничения по скорости.\n\nНапример, у нас есть поток задач на внешнее API, где нельзя делать больше 100 запросов в минуту:\n\n```\nXGROUP CREATE external:api:tasks:stream api-workers $ MKSTREAM\n\nXADD external:api:tasks:stream * user_id 123 endpoint \"/profile\" priority \"normal\"\nXADD external:api:tasks:stream * user_id 456 endpoint \"/balance\" priority \"high\"\n```\n\nВоркеры:\n\n- читают задачи через **XREADGROUP**;\n- перед выполнением смотрят счётчик запросов в **rate:external:api**;\n- либо сразу выполняют и инкрементят счётчик, либо откладывают задачу на потом.\n\nКомбинация **Streams** и счётчиков в Redis позволяет строить гибкие схемы ограничения скорости без сложной инфраструктуры.\n\n## Итог\n\n**Redis Streams** хорошо подходят для задач, где есть последовательность событий или задач, которые нужно безопасно передавать между частями системы и обрабатывать асинхронно.\n\nНа их основе можно строить очереди фоновых работ, логи и шины событий для микросервисов, при этом оставаясь в рамках знакомого Redis и не вводя отдельную систему для каждого сценария."
    }
  ]
}