{
  "entries": [
    {
      "title": "Разница между образом и контейнером",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "basics",
      "sectionTitle": "Базовые команды и жизненный цикл",
      "sectionOrder": 3,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "basics",
        "slug": "01-image-vs-container",
        "lang": "ru"
      },
      "path": "/content/materials/docker/basics/01-image-vs-container.ru.md",
      "content": "\nВ программировании есть классическая аналогия: **Класс** и **Объект**.\nВ Docker есть похожая пара: **Образ (Image)** и **Контейнер (Container)**.\nПонимание их различий — фундамент всей работы с Docker.\n\n## Образ (Image)\n\nОбраз — это **шаблон**. Это упакованный файл (точнее, набор слоёв), который лежит у вас на диске. Он доступен только для чтения (read-only). Вы не можете «запустить» образ и что-то в нем изменить. Вы можете только создать из него контейнер.\n\nОбраз содержит:\n- Операционную систему (урезанную, например, Alpine или Debian).\n- Код вашего приложения.\n- Библиотеки и зависимости.\n- Переменные окружения по умолчанию.\n\n**Аналогии:**\n- Класс в ООП (`class User {}`).\n- Установочный диск Windows/игры.\n- Рецепт пирога.\n\nКоманда для просмотра скачанных образов:\n```bash\ndocker images\n```\n\n## Контейнер (Container)\n\nКонтейнер — это **запущенный процесс**. Это живая сущность, созданная из образа.\nКогда вы запускаете контейнер, Docker берет образ (шаблон) и добавляет к нему тонкий слой для записи данных (writable layer).\n\nВ одном контейнере вы можете создать файл `/tmp/test1`, в другом — удалить `/etc/hosts`, и эти изменения никак не коснутся ни самого образа, ни других контейнеров.\n\n**Аналогии:**\n- Объект в ООП (`new User()`).\n- Установленная и запущенная игра.\n- Испеченный пирог, который можно съесть.\n\nКоманда для просмотра запущенных контейнеров:\n```bash\ndocker ps\n```\nА для просмотра всех (в том числе остановленных):\n```bash\ndocker ps -a\n```\n\n## Главный принцип\n\n**Один образ — много контейнеров.**\nВы можете скачать один образ `nginx` и запустить из него 10 разных веб-серверов на разных портах. Каждый из них будет изолирован.\n\n## Итого\n\n- **Образ** — это файл на диске, шаблон. Он неизменен.\n- **Контейнер** — это процесс в памяти. Он живет, меняется и умирает.\n- Мы **строим** (build) или **скачиваем** (pull) образы.\n- Мы **запускаем** (run) контейнеры из образов.\n\n"
    },
    {
      "title": "Жизненный цикл: run, start, stop, rm",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "basics",
      "sectionTitle": "Базовые команды и жизненный цикл",
      "sectionOrder": 3,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "basics",
        "slug": "02-lifecycle",
        "lang": "ru"
      },
      "path": "/content/materials/docker/basics/02-lifecycle.ru.md",
      "content": "\nКонтейнер не живет вечно. У него есть четкий жизненный цикл, и для каждого этапа есть своя команда. Давайте пройдем этот путь на примере контейнера `nginx`.\n\n## 1. Создание и запуск (docker run)\n\nЭта команда делает всё сразу: скачивает образ (если нет), создает контейнер и запускает его.\n\n```bash\ndocker run -d --name my-web nginx\n```\n- `-d`: detached mode (в фоне).\n- `--name my-web`: даем контейнеру удобное имя (иначе Docker придумает смешное имя вроде `admiring_turing`).\n\nТеперь контейнер в статусе **Up** (работает). Проверьте:\n```bash\ndocker ps\n```\n\n## 2. Остановка (docker stop)\n\nЕсли сервис больше не нужен, мы его останавливаем. Это штатное выключение: Docker посылает сигнал завершения, и приложение корректно закрывается (сохраняет данные, закрывает соединения).\n\n```bash\ndocker stop my-web\n```\nТеперь контейнер в статусе **Exited**. Он не потребляет CPU и RAM, но всё еще занимает место на диске (логи, измененные файлы внутри).\nПроверьте:\n```bash\ndocker ps -a\n```\n\n## 3. Повторный запуск (docker start)\n\nОстановленный контейнер можно \"разбудить\". Все данные внутри него, которые были изменены до остановки, сохранятся.\n\n```bash\ndocker start my-web\n```\nОбратите внимание: `run` создает **новый** контейнер, а `start` запускает **существующий**.\n\n## 4. Удаление (docker rm)\n\nЕсли контейнер больше не нужен совсем (например, вы хотите создать новый с другими настройками), его нужно удалить.\n**Важно:** Нельзя удалить работающий контейнер. Сначала `stop`, потом `rm`.\n\n```bash\ndocker stop my-web\ndocker rm my-web\n```\n\nЕсли очень хочется удалить работающий контейнер сразу, можно использовать флаг `-f` (force), но это \"грубое\" убийство:\n```bash\ndocker rm -f my-web\n```\n\n## Итоговая схема\n\n1. `docker run` -> Создал + Запустил.\n2. `docker stop` -> Остановил (процесс умер, контейнер остался).\n3. `docker start` -> Снова запустил тот же контейнер.\n4. `docker rm` -> Удалил мусор (контейнер исчез навсегда).\n\n"
    },
    {
      "title": "Graceful Shutdown: сигналы SIGTERM/SIGKILL",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "basics",
      "sectionTitle": "Базовые команды и жизненный цикл",
      "sectionOrder": 3,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "basics",
        "slug": "03-graceful-shutdown",
        "lang": "ru"
      },
      "path": "/content/materials/docker/basics/03-graceful-shutdown.ru.md",
      "content": "\nКогда вы пишете `docker stop`, контейнер останавливается не мгновенно. Docker ведет себя вежливо: он просит приложение завершиться самостоятельно.\n\n## Как это работает\n\n1. **docker stop** отправляет главному процессу контейнера (PID 1) сигнал **SIGTERM**.\n2. У приложения есть время (по умолчанию 10 секунд), чтобы:\n   - Дообработать текущие запросы.\n   - Сохранить данные на диск.\n   - Закрыть соединения с базой данных.\n3. Если через 10 секунд приложение всё еще работает, Docker отправляет сигнал **SIGKILL**.\n4. **SIGKILL** — это выстрел в голову. Процесс убивается мгновенно операционной системой, без возможности что-либо сохранить.\n\n## Почему это важно знать?\n\nЕсли ваше приложение \"долго думает\" при выключении (например, сохраняет большой дамп базы), стандартных 10 секунд может не хватить. Данные могут побиться.\n\nВы можете увеличить время ожидания флагом `-t` (timeout):\n\n```bash\n# Дать контейнеру 30 секунд на корректное завершение\ndocker stop -t 30 my-app\n```\n\n## Команда docker kill\n\nЕсли вы не хотите ждать и вам нужно убить контейнер прямо сейчас (аналог выдергивания вилки из розетки):\n\n```bash\ndocker kill my-app\n```\nЭто сразу отправляет **SIGKILL**. Используйте только в крайних случаях, когда приложение зависло намертво.\n\n## Итого\n\n- Всегда используйте `docker stop` для штатной остановки.\n- Приложение должно уметь обрабатывать сигнал `SIGTERM` (большинство современных веб-серверов это умеют).\n- Если приложение закрывается дольше 10 секунд, увеличьте таймаут или оптимизируйте код.\n\n"
    },
    {
      "title": "Дебаг контейнера: logs, inspect, exec",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "basics",
      "sectionTitle": "Базовые команды и жизненный цикл",
      "sectionOrder": 3,
      "order": 4,
      "id": {
        "category": "docker",
        "section": "basics",
        "slug": "04-debug-commands",
        "lang": "ru"
      },
      "path": "/content/materials/docker/basics/04-debug-commands.ru.md",
      "content": "\nКонтейнер запущен, но сайт не открывается. Или база данных падает с ошибкой. Как понять, что происходит внутри \"черного ящика\"?\nУ Docker есть три главных инструмента для диагностики.\n\n## 1. Логи (docker logs)\n\nВ классических серверах логи пишутся в файлы (`/var/log/nginx/error.log`).\nВ Docker принято писать логи в **stdout** (стандартный вывод). Всё, что приложение пишет в консоль, Docker сохраняет.\n\nПосмотреть логи контейнера:\n```bash\ndocker logs my-web\n```\n\nСледить за логами в реальном времени (как `tail -f`):\n```bash\ndocker logs -f my-web\n```\n\nПоказать последние 100 строк:\n```bash\ndocker logs --tail 100 my-web\n```\n\n## 2. Инспекция (docker inspect)\n\nЭта команда показывает **всю подноготную** контейнера в формате JSON: IP-адрес, пути к файлам, переменные окружения, открытые порты и многое другое.\n\n```bash\ndocker inspect my-web\n```\n\nВывод будет огромным. Чтобы найти что-то конкретное (например, IP-адрес), можно использовать `grep`:\n```bash\ndocker inspect my-web | grep IPAddress\n```\n\n## 3. Вход внутрь (docker exec)\n\nИногда нужно зайти внутрь работающего контейнера, чтобы проверить, создался ли файл конфигурации или доступна ли база данных по сети.\n\nДля этого мы запускаем **новый процесс** (обычно оболочку `bash` или `sh`) внутри уже работающего контейнера.\n\n```bash\n# -it = интерактивный режим + tty (терминал)\ndocker exec -it my-web bash\n```\n\nЕсли в контейнере нет bash (например, в образах Alpine), пробуйте `sh`:\n```bash\ndocker exec -it my-web sh\n```\n\nВнутри вы можете использовать обычные команды Linux: `ls`, `cat`, `top`, `ping`.\nЧтобы выйти, нажмите `Ctrl+D` или наберите `exit`. Сам контейнер при этом **не остановится**, закроется только ваша сессия терминала.\n\n## Итого\n\n- Что-то сломалось? Сначала смотрите `docker logs`.\n- Нужно узнать IP или настройки? Смотрите `docker inspect`.\n- Нужно \"пощупать\" файлы руками? Заходите через `docker exec -it ... bash`.\n\n"
    },
    {
      "title": "Управление контейнерами: имена и очистка",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "basics",
      "sectionTitle": "Базовые команды и жизненный цикл",
      "sectionOrder": 3,
      "order": 5,
      "id": {
        "category": "docker",
        "section": "basics",
        "slug": "05-management-and-cleanup",
        "lang": "ru"
      },
      "path": "/content/materials/docker/basics/05-management-and-cleanup.ru.md",
      "content": "\nКогда вы экспериментируете с Docker, ваша система быстро засоряется десятками остановленных контейнеров и неиспользуемых образов. Разберем, как поддерживать порядок.\n\n## Имена контейнеров\n\nПо умолчанию Docker дает контейнерам случайные имена: `heuristic_perlman`, `focused_bose`. С ними неудобно работать.\nВсегда задавайте имя явно флагом `--name`:\n\n```bash\ndocker run -d --name redis-main redis\n```\nТеперь вы можете обращаться к нему по имени: `docker stop redis-main`.\n**Ограничение:** Имя должно быть уникальным. Вы не можете запустить два контейнера с именем `redis-main` одновременно.\n\n## Массовая очистка (Docker Prune)\n\nЭто самая приятная команда. Она удаляет **всё**, что не используется прямо сейчас:\n- Остановленные контейнеры.\n- Неиспользуемые сети.\n- \"Повисшие\" образы (dangling images — те, у которых нет имени, обычно остатки от сборки).\n\n```bash\ndocker system prune\n```\nDocker спросит подтверждение `Are you sure? [y/N]`.\nЕсли хотите удалить вообще всё, включая неиспользуемые образы (даже именованные), добавьте флаг `-a`:\n```bash\ndocker system prune -a\n```\n⚠️ **Будьте осторожны:** это удалит все образы, которые сейчас не запущены в контейнерах. При следующем запуске Docker придется качать их заново из интернета.\n\n## Удаление конкретных ресурсов\n\nЕсли `prune` для вас слишком радикален, можно удалять точечно:\n\nУдалить **все** остановленные контейнеры (одной командой):\n```bash\ndocker container prune\n```\n\nУдалить контейнер принудительно (даже если работает):\n```bash\ndocker rm -f my-container\n```\n\nУдалить образ:\n```bash\ndocker rmi nginx\n```\n\n## Итого\n\n- Давайте контейнерам понятные имена (`--name`).\n- Регулярно делайте `docker system prune`, чтобы освобождать место на диске.\n- Не бойтесь удалять контейнеры — в этом суть Docker. Если данные важны, они должны лежать в Volume, а не в контейнере.\n\n"
    },
    {
      "title": "Введение в Docker Compose",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "compose",
      "sectionTitle": "Docker Compose",
      "sectionOrder": 7,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "compose",
        "slug": "01-compose-intro",
        "lang": "ru"
      },
      "path": "/content/materials/docker/compose/01-compose-intro.ru.md",
      "content": "\nЗапускать контейнеры командами `docker run` с кучей флагов (`-v`, `-p`, `--network`, `-e`) — это неудобно, ненадежно и сложно воспроизводить. Если у вас 5 сервисов, запуск превращается в ад.\n\n**Docker Compose** решает эту проблему. Это инструмент для описания и запуска мульти-контейнерных приложений.\nВы описываете всю конфигурацию в одном YAML-файле (`docker-compose.yml`) и запускаете всё одной командой.\n\n## Структура docker-compose.yml\n\nДавайте перепишем пример с WordPress и MySQL из прошлого урока на язык Compose.\n\n```yaml\nversion: '3.8'  # Версия схемы (необязательно в новых версиях, но полезно)\n\nservices:       # Список наших контейнеров\n  db:           # Имя сервиса (оно же будет DNS-именем)\n    image: mysql:5.7\n    volumes:\n      - db_data:/var/lib/mysql  # Подключаем именованный том\n    restart: always\n    environment: # Переменные окружения\n      MYSQL_ROOT_PASSWORD: somewordpress\n      MYSQL_DATABASE: wordpress\n      MYSQL_USER: wordpress\n      MYSQL_PASSWORD: wordpress\n\n  wordpress:\n    depends_on:  # Указываем зависимость: не запускать WP, пока не стартанет db\n      - db\n    image: wordpress:latest\n    ports:\n      - \"8080:80\" # Проброс портов \"Внешний:Внутренний\"\n    restart: always\n    environment:\n      WORDPRESS_DB_HOST: db:3306 # Обращаемся к базе по имени сервиса \"db\"\n      WORDPRESS_DB_USER: wordpress\n      WORDPRESS_DB_PASSWORD: wordpress\n      WORDPRESS_DB_NAME: wordpress\n\nvolumes: # Объявляем тома, которые используем выше\n  db_data:\n```\n\n## Что изменилось?\n\n1. **Декларативность:** Мы не пишем команды, мы описываем *желаемое состояние*.\n2. **Сеть:** Docker Compose **автоматически** создает общую сеть для всех сервисов в файле. Нам не нужно делать `docker network create`.\n3. **DNS:** Имена сервисов (`db`, `wordpress`) автоматически становятся хостнеймами.\n\nТеперь, чтобы запустить весь этот зоопарк, нужна всего одна команда:\n```bash\ndocker compose up -d\n```\n(`-d` — detached mode, запустить в фоне).\n\n## Итого\n\nDocker Compose — это стандарт для локальной разработки.\nВместо того чтобы хранить `.txt` файл с длинными командами `docker run`, вы храните аккуратный `docker-compose.yml` в репозитории проекта.\n\n"
    },
    {
      "title": "Управление стеком: up, down, logs, ps",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "compose",
      "sectionTitle": "Docker Compose",
      "sectionOrder": 7,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "compose",
        "slug": "02-commands",
        "lang": "ru"
      },
      "path": "/content/materials/docker/compose/02-commands.ru.md",
      "content": "\nDocker Compose имеет свой набор команд, зеркально отражающий обычный Docker CLI, но работающий сразу со всем стеком сервисов.\n\n## Запуск (up)\n\n```bash\ndocker compose up -d\n```\nЭта команда делает магию:\n1. Создает сеть (если нет).\n2. Создает тома (если нет).\n3. Скачивает образы (pull).\n4. Запускает контейнеры.\n\nЕсли вы изменили конфиг `docker-compose.yml` (например, поменяли порт), просто выполните `up` еще раз. Compose увидит изменения и пересоздаст только измененные контейнеры.\n\n## Остановка и удаление (down)\n\n```bash\ndocker compose down\n```\nЭто обратная операция:\n1. Останавливает контейнеры.\n2. Удаляет контейнеры.\n3. Удаляет созданную сеть.\n\n**Важно:** Тома (Volumes) с данными **не удаляются** по умолчанию (чтобы вы случайно не стерли базу).\nЕсли хотите удалить всё-всё, включая тома:\n```bash\ndocker compose down -v\n```\n\n## Логи (logs)\n\nСмотреть логи сразу всех сервисов в одном потоке (очень удобно для дебага взаимодействия):\n```bash\ndocker compose logs -f\n```\nИли конкретного сервиса:\n```bash\ndocker compose logs -f wordpress\n```\n\n## Статус (ps)\n\nПосмотреть список контейнеров, запущенных *именно этим* docker-compose файлом:\n```bash\ndocker compose ps\n```\n\n## Пересборка (build)\n\nЕсли вы используете `build: .` в файле (собираете образ из кода), и код изменился:\n```bash\ndocker compose up -d --build\n```\nФлаг `--build` принуждает Compose пересобрать образы перед запуском.\n\n## Итого\n\n- `up -d` — поднять всё.\n- `down` — всё убрать.\n- `logs -f` — смотреть, что происходит.\n- `ps` — проверить статус.\n\n"
    },
    {
      "title": "Зависимости сервисов (depends_on)",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "compose",
      "sectionTitle": "Docker Compose",
      "sectionOrder": 7,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "compose",
        "slug": "03-depends-on",
        "lang": "ru"
      },
      "path": "/content/materials/docker/compose/03-depends-on.ru.md",
      "content": "\nЧастая проблема: ваше приложение (`web`) стартует быстрее, чем база данных (`db`).\nПриложение пытается подключиться, базы еще нет, приложение падает с ошибкой `Connection refused`.\n\n## depends_on\n\nБазовое решение — инструкция `depends_on`.\n\n```yaml\nservices:\n  web:\n    build: .\n    depends_on:\n      - db\n  db:\n    image: postgres\n```\n\nЧто это дает?\n1. `docker compose up` гарантированно запустит `db` **перед** тем, как запускать `web`.\n2. `docker compose up web` автоматически запустит и `db` тоже.\n\n## Проблема «Готовности»\n\n`depends_on` ждет только того момента, когда контейнер с базой запустится (статус `Running`).\nНо база данных может запускаться еще 10-30 секунд **внутри** контейнера (инициализация файлов, создание таблиц).\nDocker не знает, что происходит внутри процесса. Поэтому `web` запустится, а база всё еще не готова принимать соединения.\n\n## Решение: Healthcheck (Проверка здоровья)\n\nМы можем научить Docker проверять, жива ли база по-настоящему.\n\n```yaml\nservices:\n  db:\n    image: postgres\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"] # Команда проверки\n      interval: 10s\n      timeout: 5s\n      retries: 5\n  \n  web:\n    build: .\n    depends_on:\n      db:\n        condition: service_healthy # Ждать не просто запуска, а \"здоровья\"\n```\n\nТеперь `web` не запустится до тех пор, пока утилита `pg_isready` внутри контейнера `db` не вернет успех. Это самый надежный способ синхронизации запуска.\n\n## Итого\n\nПросто `depends_on` контролирует только порядок старта контейнеров.\n`depends_on` + `condition: service_healthy` контролирует **готовность** сервиса к работе.\n\n"
    },
    {
      "title": "Политики перезапуска (restart policies)",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "compose",
      "sectionTitle": "Docker Compose",
      "sectionOrder": 7,
      "order": 4,
      "id": {
        "category": "docker",
        "section": "compose",
        "slug": "04-restart-policies",
        "lang": "ru"
      },
      "path": "/content/materials/docker/compose/04-restart-policies.ru.md",
      "content": "\nЧто должно произойти, если ваше приложение упало с ошибкой? Или если сервер перезагрузился?\nЗа это отвечает параметр `restart`.\n\n## Варианты политик\n\n```yaml\nservices:\n  my-app:\n    image: my-image\n    restart: always # <-- Вот здесь\n```\n\n### 1. `no` (по умолчанию)\nНикогда не перезапускать. Если упало — пусть лежит.\nПолезно для \"одноразовых\" задач (скрипты миграций, бэкапы).\n\n### 2. `always`\nВсегда перезапускать.\n- Если процесс упал с ошибкой -> перезапуск.\n- Если вы остановили Docker -> при старте Docker контейнер запустится сам.\n- **Нюанс:** Если вы явно сделали `docker stop`, он не перезапустится, пока вы не сделаете `docker start`.\n\n### 3. `on-failure`\nПерезапускать, только если приложение упало с ошибкой (exit code != 0).\nЕсли приложение завершилось штатно (exit code 0), перезапуска не будет.\nПолезно, если падение — это баг, который надо лечить рестартом, а штатное завершение — это норма.\n\n### 4. `unless-stopped`\nПохоже на `always`, но с отличием: если контейнер был остановлен (вручную или по ошибке) **перед** перезагрузкой демона Docker, то после перезагрузки он **не** запустится автоматически.\nЭто самый частый выбор для долгоживущих сервисов в продакшене.\n\n## Итого\n\nДля веб-серверов и баз данных ставьте `restart: always` или `restart: unless-stopped`.\nЭто обеспечит их автоматическое поднятие после перезагрузки сервера.\n\n"
    },
    {
      "title": "Использование переменных окружения (.env)",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "compose",
      "sectionTitle": "Docker Compose",
      "sectionOrder": 7,
      "order": 5,
      "id": {
        "category": "docker",
        "section": "compose",
        "slug": "05-env-files",
        "lang": "ru"
      },
      "path": "/content/materials/docker/compose/05-env-files.ru.md",
      "content": "\nХардкодить пароли в `docker-compose.yml` — плохая идея. Файл попадет в git, и пароли утекут.\nDocker Compose нативно поддерживает файлы `.env`.\n\n## Как это работает\n\n1. Создайте файл `.env` рядом с `docker-compose.yml`:\n\n```env\nDB_USER=admin\nDB_PASS=super_secret_password_123\nDB_PORT=5432\n```\n\n2. Используйте переменные в `docker-compose.yml`:\n\n```yaml\nservices:\n  db:\n    image: postgres\n    environment:\n      POSTGRES_USER: ${DB_USER}       # Подставится admin\n      POSTGRES_PASSWORD: ${DB_PASS}   # Подставится пароль\n    ports:\n      - \"${DB_PORT}:5432\"             # Можно даже в портах\n```\n\nТеперь вы можете коммитить `docker-compose.yml` в репозиторий, а `.env` добавить в `.gitignore`.\nУ каждого разработчика будет свой `.env` со своими настройками.\n\n## Значения по умолчанию\n\nМожно задавать дефолтные значения прямо в YAML, если переменная не найдена:\n\n```yaml\nports:\n  - \"${PORT:-8080}:80\" # Если PORT не задан, используем 8080\n```\n\n## Итого\n\nНикогда не храните секреты в чистом виде в `docker-compose.yml`. Используйте `.env` файл — это стандарт индустрии для конфигурации 12-factor приложений.\n\n"
    },
    {
      "title": "Выбор базового образа: Alpine, Debian, Distroless",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "images",
      "sectionTitle": "Dockerfile и сборка образов",
      "sectionOrder": 4,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "images",
        "slug": "01-base-images",
        "lang": "ru"
      },
      "path": "/content/materials/docker/images/01-base-images.ru.md",
      "content": "\nЛюбой Docker-образ начинается с инструкции `FROM`. Это фундамент.\nВы выбираете \"родителя\", на основе которого будете строить своё приложение.\nВыбор базового образа критически влияет на **размер**, **безопасность** и **удобство отладки**.\n\n## 1. Debian / Ubuntu (Full OS)\n\nЭто полноценные дистрибутивы Linux, упакованные в контейнер.\nВ них есть всё привычное: `apt`, `bash`, `curl`, `git`.\n\nПример: `FROM node:18` (часто основан на Debian).\n\n**Плюсы:**\n- Максимальная совместимость (glibc).\n- Легко дебажить (есть все утилиты).\n- Привычное окружение.\n\n**Минусы:**\n- Большой размер (сотни мегабайт).\n- Много лишнего софта = больше потенциальных уязвимостей (CVE).\n\n## 2. Alpine Linux\n\nСверхлегкий дистрибутив Linux (около 5 МБ). Использует библиотеку `musl` вместо `glibc`.\nСтандарт де-факто для тех, кто гонится за минимальным размером.\n\nПример: `FROM node:18-alpine`.\n\n**Плюсы:**\n- Очень маленький размер образа.\n- Меньше поверхность атаки.\n\n**Минусы:**\n- Использует `apk` вместо `apt`.\n- Нет `glibc` (некоторые бинарные файлы могут не запуститься или работать медленно).\n- Сложнее дебажить из-за урезанного набора утилит.\n\n## 3. Distroless (Google)\n\nРадикальный подход: в образе нет **ничего**, кроме вашего приложения и минимальных рантайм-зависимостей.\nТам нет даже оболочки (`bash`, `sh`) и пакетного менеджера!\n\nПример: `gcr.io/distroless/nodejs:18`.\n\n**Плюсы:**\n- Идеальная безопасность (злоумышленник не сможет запустить shell, потому что его нет).\n- Минимальный размер.\n\n**Минусы:**\n- Невозможно зайти внутрь через `docker exec` (нет шелла).\n- Дебаг только через логи.\n\n## Что выбрать?\n\n1. **Для разработки:** Обычные образы (`node:18`, `python:3.9`) или Alpine. Вам нужны инструменты внутри.\n2. **Для продакшена:**\n   - Если важен размер и безопасность: **Alpine**.\n   - Если паранойя безопасности максимальна: **Distroless**.\n   - Если нужны специфичные C++ библиотеки: **Debian-slim**.\n\n## Итого\n\n- Всегда указывайте конкретные теги (`node:18-alpine`), а не `latest`.\n- Начинайте с `alpine` версий. Если что-то не работает — переходите на `slim` (урезанный Debian).\n- Используйте полные образы только если это действительно необходимо.\n\n"
    },
    {
      "title": "Основы Dockerfile: FROM, COPY, RUN, CMD",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "images",
      "sectionTitle": "Dockerfile и сборка образов",
      "sectionOrder": 4,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "images",
        "slug": "02-dockerfile-basics",
        "lang": "ru"
      },
      "path": "/content/materials/docker/images/02-dockerfile-basics.ru.md",
      "content": "\nЧтобы создать свой образ, нам нужна инструкция. Эта инструкция пишется в файле с названием `Dockerfile` (без расширения).\n\nДавайте напишем Dockerfile для простого Node.js приложения.\n\n## Пример Dockerfile\n\n```dockerfile\n# 1. Базовый образ\nFROM node:18-alpine\n\n# 2. Рабочая директория внутри контейнера\nWORKDIR /app\n\n# 3. Копируем файлы зависимостей\nCOPY package.json package-lock.json ./\n\n# 4. Устанавливаем зависимости\nRUN npm ci\n\n# 5. Копируем исходный код\nCOPY . .\n\n# 6. Объявляем порт (информативно)\nEXPOSE 3000\n\n# 7. Команда запуска\nCMD [\"node\", \"index.js\"]\n```\n\n## Разбор команд\n\n### FROM\nС чего начинаем. Всегда первая команда.\n`FROM ubuntu:22.04` или `FROM python:3.9-slim`.\n\n### WORKDIR\nЗадает текущую папку внутри контейнера.\nВсе последующие команды (`COPY`, `RUN`, `CMD`) будут выполняться в ней.\nЕсли папки нет, она создастся.\n**Совет:** Всегда используйте `WORKDIR`, не работайте в корне `/`.\n\n### COPY\nКопирует файлы **с вашего компьютера** (хоста) **в контейнер**.\nСинтаксис: `COPY <откуда> <куда>`.\n`COPY . .` означает \"скопировать всё из текущей папки проекта в текущую папку контейнера (`WORKDIR`)\".\n\n### RUN\nВыполняет команду **во время сборки** образа.\nРезультат выполнения сохраняется в слое образа.\nИспользуется для установки пакетов (`npm install`, `pip install`, `apt-get update`).\n\n### CMD\nКоманда, которая выполнится **при запуске контейнера** (`docker run`).\nВ Dockerfile может быть только одна инструкция `CMD` (точнее, сработает только последняя).\n\n## Как собрать образ\n\nКогда Dockerfile готов, мы запускаем сборку командой `build`:\n\n```bash\n# -t my-app: ставим тег (имя) образу\n# . : путь к папке с Dockerfile (текущая папка)\ndocker build -t my-app .\n```\n\nDocker прочитает файл сверху вниз, выполнит каждую инструкцию и создаст итоговый образ `my-app`.\n\n## Итого\n\n1. `FROM` — база.\n2. `WORKDIR` — перешли в папку.\n3. `COPY` — закинули файлы.\n4. `RUN` — установили библиотеки.\n5. `CMD` — сказали, как запускать.\n\n"
    },
    {
      "title": "Кеш слоёв и оптимизация порядка команд",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "images",
      "sectionTitle": "Dockerfile и сборка образов",
      "sectionOrder": 4,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "images",
        "slug": "03-layer-caching",
        "lang": "ru"
      },
      "path": "/content/materials/docker/images/03-layer-caching.ru.md",
      "content": "\nСборка Docker-образа работает послойно. Каждая инструкция в Dockerfile (`RUN`, `COPY`) создает новый слой.\nDocker очень умен: он **кеширует** каждый слой. Если вы ничего не меняли в инструкции и файлах, которые она трогает, Docker мгновенно возьмет готовый слой из кеша, вместо того чтобы выполнять команду заново.\n\nЭто критически важно для скорости сборки (CI/CD).\n\n## Правильный порядок: от редкого к частому\n\nПосмотрите на этот \"плохой\" Dockerfile:\n\n```dockerfile\nFROM node:18\nWORKDIR /app\n\n# ПЛОХО: Мы копируем ВЕСЬ код сразу\nCOPY . .\n\n# А потом ставим зависимости\nRUN npm install\n\nCMD [\"node\", \"index.js\"]\n```\n\nПочему это плохо?\nЕсли вы измените хоть одну запятую в коде (`index.js`), инструкция `COPY . .` изменится (так как изменилась чексумма файлов).\nЗначит, Docker сбросит кеш для этого слоя и **всех последующих**.\nСледовательно, `RUN npm install` будет выполняться заново при каждом изменении кода!\n\n## Оптимизированный вариант\n\nМы разделяем копирование зависимостей и кода:\n\n```dockerfile\nFROM node:18\nWORKDIR /app\n\n# 1. Сначала копируем ТОЛЬКО файлы описания зависимостей\nCOPY package.json package-lock.json ./\n\n# 2. Ставим зависимости\n# Этот слой закешируется и не будет пересобираться, \n# пока вы не добавите новую библиотеку в package.json\nRUN npm install\n\n# 3. И только потом копируем исходный код\nCOPY . .\n\nCMD [\"node\", \"index.js\"]\n```\n\n**Результат:**\nВы меняете код приложения 100 раз в день. Docker использует кеш для `npm install` (тяжелая операция) и просто быстро перекопирует легкие исходники. Сборка занимает 1 секунду вместо 2 минут.\n\n## Правило\n\nРасполагайте инструкции в порядке **от наименее часто изменяемых к наиболее часто изменяемым**.\n\n1. Установка системных пакетов (`apt install`).\n2. Установка зависимостей проекта (`npm install`, `pip install`).\n3. Копирование исходного кода.\n4. Команда запуска.\n\n## Итого\n\nИспользуйте механизм слоев себе на пользу. Правильный порядок команд в Dockerfile может ускорить сборку в десятки раз.\n\n"
    },
    {
      "title": ".dockerignore и контекст сборки",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "images",
      "sectionTitle": "Dockerfile и сборка образов",
      "sectionOrder": 4,
      "order": 4,
      "id": {
        "category": "docker",
        "section": "images",
        "slug": "04-dockerignore",
        "lang": "ru"
      },
      "path": "/content/materials/docker/images/04-dockerignore.ru.md",
      "content": "\nКогда вы пишете `docker build .`, первое, что делает Docker CLI — это отправляет **весь контекст** (все файлы из текущей папки) демону Docker.\n\nЕсли у вас в папке проекта лежит папка `node_modules` (300 МБ) или `.git` (100 МБ), Docker сначала \"засосет\" эти 400 МБ демону, и только потом начнет сборку. Это долго и тратит ресурсы.\n\nКроме того, если вы сделаете `COPY . .`, весь этот мусор попадет внутрь образа, раздувая его размер.\n\n## Файл .dockerignore\n\nЧтобы этого избежать, создайте в корне проекта файл `.dockerignore`. Он работает точно так же, как `.gitignore`.\n\nПример `.dockerignore` для JS проекта:\n```text\nnode_modules\n.git\n.vscode\ndist\nbuild\n*.md\ndocker-compose.yml\nDockerfile\n.env\n```\n\n## Что это дает?\n\n1. **Скорость:** `docker build` начинается мгновенно, так как контекст маленький.\n2. **Безопасность:** Вы случайно не скопируете внутрь образа файл `.env` с паролями или папку `.git` с историей изменений.\n3. **Размер:** Образ остается чистым, в нем только то, что нужно для запуска.\n\n## Частая ошибка\n\nНе путайте `.gitignore` и `.dockerignore`.\n`.gitignore` говорит git-у не отслеживать файлы.\n`.dockerignore` говорит docker-у не видеть файлы при сборке.\n\nОбычно они похожи, но `.dockerignore` часто строже (например, мы игнорируем `Dockerfile` и `README.md`, которые в git-е нужны, а внутри контейнера — нет).\n\n## Итого\n\nВсегда создавайте `.dockerignore` в начале проекта. Это признак хорошего тона и профессионализма.\n\n"
    },
    {
      "title": "Multi-stage сборка",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "images",
      "sectionTitle": "Dockerfile и сборка образов",
      "sectionOrder": 4,
      "order": 6,
      "id": {
        "category": "docker",
        "section": "images",
        "slug": "05-multistage",
        "lang": "ru"
      },
      "path": "/content/materials/docker/images/05-multistage.ru.md",
      "content": "\nПредставьте, что вы пишете на Go, Java или TypeScript.\nВам нужны компиляторы (`go build`, `tsc`, `maven`) для сборки приложения. Но для **запуска** готового бинарника или JS-файлов эти инструменты не нужны!\n\nЕсли оставить их в финальном образе, он будет весить 500 МБ вместо 20 МБ.\nРешение: **Multi-stage builds** (многоэтапная сборка).\n\n## Как это работает\n\nМы используем несколько инструкций `FROM` в одном Dockerfile. Каждый `FROM` начинает новый этап. Мы можем копировать файлы (артефакты) из предыдущего этапа в текущий.\n\n## Пример (для статического сайта на Nginx)\n\nДопустим, у нас React-приложение. Его нужно собрать (`npm run build`), а потом просто раздавать статику через Nginx. Node.js в продакшене нам не нужен.\n\n```dockerfile\n# --- Этап 1: Сборка (Builder) ---\nFROM node:18-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build\n# Теперь в папке /app/dist лежит готовый сайт\n\n# --- Этап 2: Продакшен (Production) ---\nFROM nginx:alpine\n# Копируем ТОЛЬКО папку dist из этапа builder\nCOPY --from=builder /app/dist /usr/share/nginx/html\n\n# Нам не нужен Node.js, npm и исходники. \n# В итоговом образе только Nginx и HTML/JS файлы.\nEXPOSE 80\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n```\n\n## Преимущества\n\n1. **Минимальный размер:** Итоговый образ содержит только то, что нужно для работы (Runtime). Все инструменты сборки (Build tools) отбрасываются.\n2. **Безопасность:** В продакшен не едут исходные коды, компиляторы и dev-зависимости.\n3. **Удобство:** Единый Dockerfile описывает весь процесс: и сборку, и упаковку. Не нужны внешние CI-скрипты.\n\n## Итого\n\nMulti-stage — это стандарт для компилируемых языков (Go, Java, C++) и фронтенда (React, Vue).\nИспользуйте конструкцию `COPY --from=...` чтобы переносить только готовые артефакты.\n\n"
    },
    {
      "title": "Введение в контейнеризацию",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Введение",
      "sectionOrder": 1,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "01-introduction-to-containerization",
        "lang": "ru"
      },
      "path": "/content/materials/docker/intro/01-introduction-to-containerization.ru.md",
      "content": "\nКонтейнеризация — это способ запуска приложений в изолированных пространствах, называемых контейнерами. Представьте себе грузовой корабль. Раньше грузы перевозили как попало: мешки с зерном, бочки с маслом, ящики с инструментами — всё это было сложно грузить, сложно закреплять и сложно переносить с корабля на поезд.\n\nЗатем появились **стандартные контейнеры**. Теперь неважно, что внутри: автомобили, техника или еда. Контейнер всегда имеет стандартный размер и крепления. Портовый кран просто берет контейнер и ставит его, не задумываясь о содержимом.\n\nВ мире IT **Docker** сделал то же самое. Раньше, чтобы запустить приложение, нужно было настраивать сервер, устанавливать библиотеки, следить за версиями языков программирования и конфликтами. Теперь приложение и все его зависимости (библиотеки, конфиги, среда исполнения) упаковываются в один «контейнер».\n\n## Проблема «работает на моей машине»\n\nКлассическая ситуация: разработчик написал код, протестировал у себя — всё работает. Отдает код сисадмину или тестировщику — у них всё падает.\n\nПочему так происходит?\n- У разработчика Python 3.9, а на сервере 3.8.\n- У разработчика macOS, а сервер на Linux.\n- У разработчика установлена библиотека версии 1.2, а на сервере 1.0.\n\nКонтейнеризация решает эту проблему радикально. В контейнере лежит не только код, но и **вся среда запуска**. Если контейнер запустился у разработчика, он гарантированно запустится и на сервере, и у тестировщика, и в облаке.\n\n## Изоляция\n\nКаждый контейнер думает, что он — единственный жилец на сервере. У него своя (виртуальная) файловая система, свои процессы, свой сетевой интерфейс (обычно).\n\nЭто позволяет:\n- Запускать разные версии одного и того же ПО на одной машине (например, Node.js 14 и Node.js 18).\n- Если одно приложение зависнет или сломается, оно не утянет за собой соседние контейнеры и саму операционную систему.\n- Можно смело экспериментировать, зная, что основной системе ничего не угрожает.\n\n## Итого\n\nКонтейнеризация — это стандарт упаковки ПО. Она превращает ваше приложение в «чёрный ящик», который **гарантированно работает одинаково** везде, где установлен Docker. Это избавляет от боли с настройкой окружения и конфликтами зависимостей.\n\n"
    },
    {
      "title": "Задачи, которые решает Docker",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Введение",
      "sectionOrder": 1,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "02-docker-tasks",
        "lang": "ru"
      },
      "path": "/content/materials/docker/intro/02-docker-tasks.ru.md",
      "content": "\nDocker стал стандартом индустрии не просто так. Он закрывает целый пласт проблем, которые раньше отнимали у разработчиков и администраторов часы и дни. Разберем основные задачи, которые он берет на себя.\n\n## 1. Избавление от Dependency Hell (Ад зависимостей)\n\nБез Docker вам приходится устанавливать все зависимости прямо в операционную систему.\n- Проект А требует Java 8.\n- Проект Б требует Java 11.\n- Проект В требует Python 3.\n\nПопытка заставить всё это жить дружно на одном сервере превращается в кошмар. С Docker каждый проект живет в своем контейнере со своими версиями библиотек. Они друг друга не видят и не мешают.\n\n## 2. Быстрое развертывание (Deployment)\n\nРаньше деплой выглядел как длинная инструкция: «зайди на сервер, обнови apt, скачай код, поправь конфиг, перезапусти сервис...». Если на каком-то шаге ошибка — продакшн лежит.\n\nС Docker процесс выглядит так:\n1. Собрали образ (упаковали приложение).\n2. Одной командой запустили его на сервере.\n\nЕсли нужно обновиться — просто выбрасываем старый контейнер и запускаем новый из свежего образа. Это занимает секунды.\n\n## 3. Идентичность окружений (Dev / Test / Prod)\n\nЧастая проблема: на тестовом сервере настройки одни, а на боевом — немного другие. В итоге баги вылезают только в продакшене.\n\nDocker гарантирует, что образ, который вы собрали и проверили локально — это **бит-в-бит** тот же самый образ, который поедет в продакшн. Окружение \"зашито\" внутрь образа.\n\n## 4. Масштабируемость\n\nПредставьте, что на ваш сайт пришло много пользователей, и один сервер не справляется.\nБез Docker: нужно настраивать второй сервер с нуля.\nС Docker: вы просто запускаете еще 5 копий того же самого контейнера. Это можно делать вручную или автоматически (с помощью оркестраторов, таких как Kubernetes или Docker Swarm).\n\n## 5. Быстрый онбординг новых сотрудников\n\nНовый разработчик приходит в команду. Раньше он тратил первый день (или два) на настройку своего ноутбука: установка баз данных, компиляторов, серверов очередей.\n\nС Docker он делает:\n```bash\ngit clone project-repo\ndocker compose up\n```\nИ через 5 минут у него развернут весь проект: с базой данных, кэшем, бэкендом и фронтендом.\n\n## Итого\n\nDocker решает проблему **доставки и запуска** приложений. Он делает этот процесс предсказуемым, быстрым и надежным. Вместо ручной настройки серверов мы оперируем готовыми кирпичиками-контейнерами.\n\n"
    },
    {
      "title": "Виртуальные машины vs контейнеры",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Введение",
      "sectionOrder": 1,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "03-vm-vs-containers",
        "lang": "ru"
      },
      "path": "/content/materials/docker/intro/03-vm-vs-containers.ru.md",
      "content": "\nЧасто новички путают Docker и виртуальные машины (Virtual Machines, VM), так как и те, и другие позволяют запускать изолированные приложения. Но работают они принципиально по-разному. Главное отличие — в том, **что именно** изолируется и виртуализируется.\n\n## Виртуальные машины (VM)\n\nВиртуальная машина (например, в VirtualBox или VMware) — это, по сути, **полный компьютер внутри компьютера**.\n\nУ неё есть:\n- Свое виртуальное «железо» (диск, сетевая карта, CPU).\n- Своя полноценная операционная система (Guest OS).\n\nЕсли вы хотите запустить 3 приложения в разных VM, вам придется запустить 3 отдельных операционных системы. Каждая из них будет съедать ресурсы: занимать 1-2 ГБ оперативной памяти просто на работу самой ОС, грузить процессор системными службами.\n\n**Минусы:**\n- **Тяжелые:** образ весит гигабайты.\n- **Медленные:** загрузка занимает минуты (как включение обычного ПК).\n- **Ресурсоемкие:** большие накладные расходы на эмуляцию железа и работу ядра ОС.\n\n## Контейнеры (Docker)\n\nКонтейнеры используют **ядро основной операционной системы (Host OS)**. Они не эмулируют железо и не загружают отдельную ОС.\n\nВнутри контейнера лежат только само приложение и библиотеки, необходимые для его работы. Всё остальное берется у хост-системы.\n\nЕсли вы запускаете 3 контейнера на Linux, у вас работает **одно общее ядро Linux**, которое просто разделяет процессы по изолированным «комнатам».\n\n**Плюсы:**\n- **Легкие:** образ может весить 5-100 МБ.\n- **Быстрые:** запуск занимает миллисекунды (как запуск обычной программы).\n- **Эффективные:** почти нет накладных расходов, процессор и память тратятся только на полезную работу приложения.\n\n## Сравнительная таблица\n\n| Характеристика | Виртуальные машины (VM) | Контейнеры (Docker) |\n| :--- | :--- | :--- |\n| **Изоляция** | Полная (железо + ОС) | На уровне процессов (общее ядро) |\n| **Размер образа** | Гигабайты | Мегабайты |\n| **Скорость запуска** | Минуты | Секунды / миллисекунды |\n| **Потребление ресурсов** | Высокое (дублирование ОС) | Низкое (нативная производительность) |\n| **Переносимость** | Зависит от гипервизора | Работает везде, где есть Docker |\n\n## Итого\n\nВиртуализация (VM) — это про создание **виртуальных компьютеров**. Контейнеризация — это про создание **изолированных пространств для процессов**. Docker выбирают, когда нужно быстро и экономно запускать много приложений на одном сервере, не тратя ресурсы на лишние операционные системы.\n\n"
    },
    {
      "title": "Архитектура Docker",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "intro",
      "sectionTitle": "Введение",
      "sectionOrder": 1,
      "order": 4,
      "id": {
        "category": "docker",
        "section": "intro",
        "slug": "04-docker-architecture",
        "lang": "ru"
      },
      "path": "/content/materials/docker/intro/04-docker-architecture.ru.md",
      "content": "\nDocker — это клиент-серверное приложение. Когда вы набираете команды в терминале, происходит больше, чем кажется на первый взгляд. Разберем основные компоненты системы.\n\n## Основные компоненты\n\n### 1. Docker Client (Клиент)\nЭто то, с чем вы взаимодействуете. Утилита командной строки `docker`.\nКогда вы пишете `docker build` или `docker run`, клиент отправляет эти команды демону Docker. Клиент может работать на той же машине, что и демон, или подключаться к удаленному серверу.\n\n### 2. Docker Daemon (Демон, `dockerd`)\nЭто «мозг» и «руки» Docker. Он работает в фоне на хост-машине.\nИменно демон выполняет всю тяжелую работу:\n- Создает и удаляет контейнеры.\n- Скачивает и собирает образы.\n- Управляет сетями и хранилищами данных.\n\n### 3. Docker Registry (Реестр)\nЭто хранилище образов. Самый известный публичный реестр — **Docker Hub**.\nКогда вы просите запустить программу, которой у вас нет локально, демон идет в реестр, скачивает нужный образ и запускает его. Компании часто поднимают свои приватные реестры (например, GitLab Registry) для хранения закрытого кода.\n\n## Ключевые объекты\n\nВ работе с Docker вы постоянно оперируете тремя сущностями:\n\n### Image (Образ)\nЭто **шаблон**, чертеж. Образ доступен только для чтения (read-only). В нем запаковано приложение, код, библиотеки, переменные среды — всё, что нужно для запуска.\nАналогия: Образ — это **класс** в программировании.\n\n### Container (Контейнер)\nЭто **запущенный экземпляр** образа. У него появляется свой слой для записи данных. Контейнеры можно создавать, запускать, останавливать и удалять.\nАналогия: Контейнер — это **объект** (экземпляр класса). Из одного образа можно запустить хоть 100 контейнеров.\n\n### Volume (Том)\nТак как контейнеры эфемерны (при удалении контейнера все данные внутри него пропадают), для хранения важных данных (базы данных, логи, файлы пользователей) используются **Volumes**. Это специальные папки, которые хранятся на хост-машине и «пробрасываются» внутрь контейнера.\n\n## Как это работает вместе\n\nПример команды:\n```bash\ndocker run -d nginx\n```\n\nЧто происходит \"под капотом\":\n1. **Client** получает команду `run` и передает её демону.\n2. **Daemon** проверяет, есть ли у вас локально образ `nginx`.\n3. Если нет — он идет в **Registry** (Docker Hub), скачивает образ `nginx` себе в кэш.\n4. Из этого **Image** демон создает новый **Container**.\n5. Демон запускает контейнер и выделяет ему ресурсы.\n\n## Итого\n\nВы управляете Docker через **Client**, который отдает приказы **Daemon**. Демон скачивает **Images** из **Registry** и превращает их в живые **Containers**. Понимание этой цепочки помогает быстрее находить проблемы, когда что-то идет не так.\n\n"
    },
    {
      "title": "Публикация портов (-p) и доступность",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "networking",
      "sectionTitle": "Сети",
      "sectionOrder": 6,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "networking",
        "slug": "01-ports",
        "lang": "ru"
      },
      "path": "/content/materials/docker/networking/01-ports.ru.md",
      "content": "\nКонтейнеры по умолчанию живут в своей закрытой сети. Если вы запустите веб-сервер внутри контейнера, снаружи (из вашего браузера) он будет недоступен.\nЧтобы «пробить дыру» в этой изоляции, мы используем публикацию портов (Port Publishing).\n\n## Флаг -p (publish)\n\nСинтаксис: `-p <ПОРТ_НА_ХОСТЕ>:<ПОРТ_В_КОНТЕЙНЕРЕ>`\n\n```bash\ndocker run -d -p 8080:80 nginx\n```\nЗдесь мы говорим: \"Всё, что придет на порт `8080` моего ноутбука, перенаправь на порт `80` внутри контейнера Nginx\".\n\nТеперь сайт доступен по адресу `http://localhost:8080`.\n\n## Важные нюансы\n\n1. **Конфликт портов:**\n   Если вы запустите два контейнера с `-p 8080:80`, второй упадет с ошибкой `Bind for 0.0.0.0:8080 failed: port is already allocated`.\n   Один порт на хосте может слушать только один процесс.\n   **Решение:** Поменяйте внешний порт для второго контейнера: `-p 8081:80`.\n\n2. **UDP протокол:**\n   По умолчанию пробрасывается TCP. Если нужен UDP (например, для DNS или игровых серверов), укажите это явно:\n   ```bash\n   docker run -d -p 53:53/udp my-dns-server\n   ```\n\n3. **Случайный порт (-P):**\n   Если вам лень выбирать свободный порт, можно использовать флаг `-P` (заглавная). Docker сам найдет свободный порт на хосте и привяжет его ко всем `EXPOSE` портам контейнера.\n   Узнать, какой порт он выбрал, можно через `docker port <container_name>`.\n\n## Доступность (0.0.0.0 vs 127.0.0.1)\n\nПо умолчанию `-p 8080:80` открывает порт на адресе `0.0.0.0`. Это значит, что сервис будет доступен **всему интернету** (если у вас \"белый\" IP).\n\nЕсли вы хотите, чтобы сервис был доступен **только с вашего компьютера** (для безопасности), указывайте IP явно:\n\n```bash\n# Доступен только локально\ndocker run -p 127.0.0.1:8080:80 nginx\n```\n\n## Итого\n\nБез флага `-p` ваш контейнер — как подводная лодка: внутри всё работает, но снаружи к нему не подключиться. Всегда проверяйте маппинг портов командой `docker ps`.\n\n"
    },
    {
      "title": "Docker network: bridge, host и DNS",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "networking",
      "sectionTitle": "Сети",
      "sectionOrder": 6,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "networking",
        "slug": "02-network-types",
        "lang": "ru"
      },
      "path": "/content/materials/docker/networking/02-network-types.ru.md",
      "content": "\nDocker умеет создавать виртуальные сети, чтобы контейнеры могли общаться друг с другом.\nЕсть три основных типа драйверов сети.\n\n## 1. Bridge (Мост) — По умолчанию\n\nКогда вы просто запускаете контейнер, он попадает в стандартную сеть `bridge`.\nНо лучше создавать свои пользовательские сети.\n\n```bash\n# Создать сеть\ndocker network create my-net\n\n# Запустить контейнеры в этой сети\ndocker run -d --name db --network my-net mongo\ndocker run -d --name app --network my-net my-web-app\n```\n\n### Магия DNS\nВ пользовательской сети (`my-net`) работает **автоматический Service Discovery**.\nКонтейнеры могут обращаться друг к другу **по именам**!\n\nВнутри контейнера `app` вы можете написать:\n```bash\nping db\n```\nИ Docker сам подставит правильный IP-адрес контейнера `db`. Не нужно хардкодить IP-адреса.\n\n## 2. Host (Хост)\n\nРежим полной открытости. Контейнер не получает свой IP, а использует сетевой стек хост-машины.\n\n```bash\ndocker run -d --network host nginx\n```\nВ этом режиме флаг `-p` не нужен. Если Nginx слушает порт 80, он сразу откроется на 80-м порту вашего компьютера.\n\n**Плюсы:** Максимальная скорость сети (нет накладных расходов на NAT).\n**Минусы:** Порты могут конфликтовать. Работает только на Linux (на Mac/Windows есть особенности реализации).\n\n## 3. None (Нет сети)\n\nПолная изоляция. У контейнера есть только loopback интерфейс (localhost). Выхода в интернет нет.\n\n```bash\ndocker run -d --network none alpine\n```\nИспользуется для задач с повышенной безопасностью, где не нужна сеть (например, генерация ключей, обработка файлов).\n\n## Итого\n\n- Всегда создавайте свою сеть (`docker network create app-net`) для связки сервисов.\n- Обращайтесь к сервисам по именам контейнеров (`mysql`, `redis`), а не по IP.\n- Используйте `bridge` для 99% задач. `host` — только для специфичных кейсов производительности.\n\n"
    },
    {
      "title": "Взаимодействие контейнеров (app + db)",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "networking",
      "sectionTitle": "Сети",
      "sectionOrder": 6,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "networking",
        "slug": "03-container-communication",
        "lang": "ru"
      },
      "path": "/content/materials/docker/networking/03-container-communication.ru.md",
      "content": "\nДавайте закрепим знания на реальном примере.\nМы запустим классическую связку: **Веб-приложение (WordPress)** + **База данных (MySQL)**.\n\n## Шаг 1. Создаем сеть\n\nЧтобы они видели друг друга, им нужна общая комната.\n\n```bash\ndocker network create wp-net\n```\n\n## Шаг 2. Запускаем Базу Данных\n\nОбратите внимание на `--name mysql`. Это имя станет DNS-адресом для вордпресса.\n\n```bash\ndocker run -d \\\n  --name mysql \\\n  --network wp-net \\\n  -e MYSQL_ROOT_PASSWORD=somewordpress \\\n  -e MYSQL_DATABASE=wordpress \\\n  -e MYSQL_USER=wordpress \\\n  -e MYSQL_PASSWORD=wordpress \\\n  mysql:5.7\n```\nМы не публикуем порты (`-p`), потому что базе не нужно быть доступной из интернета. Ей нужно быть доступной только внутри сети `wp-net`.\n\n## Шаг 3. Запускаем WordPress\n\n```bash\ndocker run -d \\\n  --name wordpress \\\n  --network wp-net \\\n  -e WORDPRESS_DB_HOST=mysql \\\n  -e WORDPRESS_DB_USER=wordpress \\\n  -e WORDPRESS_DB_PASSWORD=wordpress \\\n  -e WORDPRESS_DB_NAME=wordpress \\\n  -p 8080:80 \\\n  wordpress:latest\n```\n\nОбратите внимание на `-e WORDPRESS_DB_HOST=mysql`. Мы говорим WordPress-у: \"Ищи базу данных по адресу `mysql`\". Docker направит этот запрос в контейнер с именем `mysql`.\n\n## Результат\n\nОткройте `http://localhost:8080`. Вы увидите установщик WordPress.\nДва контейнера общаются друг с другом по внутренней защищенной сети, а наружу торчит только веб-сайт.\n\n## Итого\n\nЭто и есть суть микросервисной архитектуры в Docker:\n1. Создали сеть.\n2. Запустили базу (скрыта от мира).\n3. Запустили бэкенд (подключился к базе по имени).\n4. Опубликовали порт бэкенда наружу.\n\n"
    },
    {
      "title": "Работа с реестрами: login, push, pull",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "registry",
      "sectionTitle": "Реестры и доставка",
      "sectionOrder": 8,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "registry",
        "slug": "01-push-pull",
        "lang": "ru"
      },
      "path": "/content/materials/docker/registry/01-push-pull.ru.md",
      "content": "\nВы создали образ на своем ноутбуке. Как передать его коллеге или на продакшн-сервер?\nОтвет: через **Реестр (Registry)**.\n\nРеестр — это как GitHub, только для Docker-образов.\nСамый известный — **Docker Hub** (публичный). Также популярны **GitLab Container Registry**, **AWS ECR**, **Google GCR**.\n\n## 1. Авторизация (Login)\n\nПрежде чем что-то загружать, нужно представиться.\n\n```bash\n# Логин в Docker Hub (потребует ввести username и password)\ndocker login\n\n# Логин в приватный реестр (например, GitLab)\ndocker login registry.gitlab.com\n```\n\n## 2. Тегирование (Tag)\n\nDocker не знает, куда отправлять образ `my-app`, потому что в имени нет адреса.\nЧтобы отправить образ в реестр, его имя должно соответствовать формату:\n`<адрес-реестра>/<пользователь>/<имя-образа>:<версия>`\n\nДопустим, ваш логин на Docker Hub — `ivan`.\nУ вас есть локальный образ `my-app:latest`. Создадим для него \"сетевой\" псевдоним:\n\n```bash\ndocker tag my-app:latest ivan/my-app:v1\n```\n\n## 3. Отправка (Push)\n\nТеперь Docker знает, куда это слать (по умолчанию в Docker Hub, так как адрес реестра не указан явно).\n\n```bash\ndocker push ivan/my-app:v1\n```\n\n## 4. Скачивание (Pull)\n\nНа сервере или компьютере коллеги:\n\n```bash\ndocker pull ivan/my-app:v1\n```\n\nИ запуск:\n```bash\ndocker run -d ivan/my-app:v1\n```\n\n## Приватные реестры\n\nЕсли вы работаете с GitLab:\n1. `docker tag my-app registry.gitlab.com/ivan/project/app:v1`\n2. `docker push registry.gitlab.com/ivan/project/app:v1`\n\nDocker смотрит на первую часть имени (до первого слеша) и понимает, на какой сервер стучаться.\n\n## Итого\n\n1. Собрали (`build`).\n2. Присвоили правильное имя с адресом реестра (`tag`).\n3. Залогинились (`login`).\n4. Отправили (`push`).\nЭто стандартный путь доставки кода в современном мире.\n\n"
    },
    {
      "title": "Стратегия тегирования: semver, sha",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "registry",
      "sectionTitle": "Реестры и доставка",
      "sectionOrder": 8,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "registry",
        "slug": "02-tagging-strategies",
        "lang": "ru"
      },
      "path": "/content/materials/docker/registry/02-tagging-strategies.ru.md",
      "content": "\nКак правильно называть версии образов?\nЕсли вы всегда используете `latest`, вы стреляете себе в ногу.\n\n## Проблема тега `latest`\n\n`latest` — это просто тег по умолчанию. Это **НЕ** \"самая свежая версия\". Это просто строка \"latest\".\nЕсли вы обновили код, собрали образ, но забыли перевесить тег `latest`, то `docker pull my-app:latest` скачает старый код.\n\nКроме того, если в продакшене вы используете `image: my-app:latest`, вы не знаете, какая именно версия кода там сейчас работает. Откатиться на предыдущую невозможно (ведь она тоже была `latest`, вы просто перезаписали её).\n\n## Стратегия 1: Semantic Versioning (SemVer)\n\nВыпускаете релизы, как в npm или git tag: `v1.0.0`, `v1.0.1`, `v1.1.0`.\n\n```bash\ndocker build -t my-app:v1.0.1 .\n```\n\n**Плюсы:** Понятно людям. Легко откатиться (`v1.0.1` сломалась -> запустили `v1.0.0`).\n**Минусы:** Нужно вручную следить за версиями.\n\n## Стратегия 2: Git Commit SHA\n\nАвтоматическая генерация тега на основе хеша коммита.\n\n```bash\n# В CI/CD пайплайне\ndocker build -t my-app:$(git rev-parse --short HEAD) .\n# Создаст образ my-app:a1b2c3d\n```\n\n**Плюсы:** Железобетонная связка \"Код в Git\" <-> \"Образ в Docker\". Вы точно знаете, из какого коммита собран этот образ. Идеально для CI/CD.\n**Минусы:** Теги выглядят как набор букв (`a1b2c3d`), сложно понять, какой новее, без просмотра истории git.\n\n## Лучшая практика (Комбинированный подход)\n\nПри релизе вешать сразу несколько тегов на один и тот же образ:\n\n1. Точный хеш: `my-app:a1b2c3d` (для роботов и точного отката).\n2. Версия: `my-app:v1.2` (для людей).\n3. Плавающий тег: `my-app:latest` (для удобства локального запуска).\n\nВ Docker один и тот же Image ID может иметь сколько угодно тегов. Это бесплатно (место на диске не дублируется).\n\n## Итого\n\nВ продакшене **никогда** не используйте `latest`. Всегда фиксируйте версию (`v1.2.3`) или хеш коммита. Это единственный способ обеспечить предсказуемость и возможность отката (Rollback).\n\n"
    },
    {
      "title": "Базовый сценарий CI/CD",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "registry",
      "sectionTitle": "Реестры и доставка",
      "sectionOrder": 8,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "registry",
        "slug": "03-ci-cd-basics",
        "lang": "ru"
      },
      "path": "/content/materials/docker/registry/03-ci-cd-basics.ru.md",
      "content": "\nКак автоматизировать доставку кода?\nDocker идеально вписывается в пайплайны CI/CD (GitHub Actions, GitLab CI).\n\nРассмотрим типичный процесс **Build -> Push -> Deploy**.\n\n## 1. Build (Сборка)\n\nНа сервере сборки (CI Runner):\n1. Клонируем код из Git.\n2. Логинимся в реестр:\n   ```bash\n   echo $REGISTRY_PASSWORD | docker login -u $REGISTRY_USER --password-stdin\n   ```\n3. Собираем образ с тегом (хеш коммита):\n   ```bash\n   COMMIT_SHA=$(git rev-parse --short HEAD)\n   docker build -t myorg/myapp:$COMMIT_SHA .\n   ```\n\n## 2. Push (Отправка)\n\nЗагружаем собранный образ в реестр:\n```bash\ndocker push myorg/myapp:$COMMIT_SHA\n```\n\n## 3. Deploy (Развертывание)\n\nЗдесь есть два пути.\n\n### Путь А: SSH (простой)\nCI подключается к боевому серверу по SSH и выполняет команды:\n```bash\nssh user@production-server \"\n  docker pull myorg/myapp:$COMMIT_SHA && \\\n  docker stop myapp || true && \\\n  docker rm myapp || true && \\\n  docker run -d --name myapp -p 80:3000 myorg/myapp:$COMMIT_SHA\n\"\n```\n*Примечание: Если используете docker-compose, просто обновляете версию в файле .env и делаете `docker compose up -d`.*\n\n### Путь Б: Watchtower (автоматический)\nНа сервере запущен специальный контейнер **Watchtower**. Он раз в минуту проверяет, не обновился ли образ в реестре. Если обновился — он сам скачивает новый, гасит старый и запускает новый с теми же параметрами.\n\n## Итого\n\nDocker превращает деплой в простую замену одного кирпичика на другой. Вам не нужно настраивать сервер, ставить зависимости и копировать файлы. Вы просто говорите серверу: \"Запусти вот этот новый образ\".\n\n"
    },
    {
      "title": "Запуск от непривилегированного пользователя",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "security",
        "slug": "01-rootless",
        "lang": "ru"
      },
      "path": "/content/materials/docker/security/01-rootless.ru.md",
      "content": "\nПо умолчанию процессы в контейнере работают от имени **root**.\nЭто значит, что если злоумышленник взломает ваше Node.js приложение (например, через уязвимость в npm-пакете) и сможет выбраться из контейнера (container breakout), он окажется на вашем сервере с правами root. Это катастрофа.\n\n## Решение: USER в Dockerfile\n\nВсегда создавайте и используйте обычного пользователя внутри Dockerfile.\n\n```dockerfile\nFROM node:18-alpine\n\nWORKDIR /app\n\n# Копируем файлы (владельцем пока будет root)\nCOPY . .\n\n# Меняем владельца файлов на node (этот юзер уже есть в node-образах)\n# Или создаем своего: RUN addgroup -S appgroup && adduser -S appuser -G appgroup\nRUN chown -R node:node /app\n\n# Переключаемся на пользователя node\nUSER node\n\n# Теперь все дальнейшие команды (CMD, RUN) будут выполняться от user: node\nCMD [\"node\", \"index.js\"]\n```\n\n## Проверка\n\nЗапустите контейнер и проверьте, кто вы:\n\n```bash\ndocker exec my-app whoami\n# Должно вернуть: node\n# Если вернуло: root — у вас проблемы\n```\n\n## Ограничение портов\n\nОбычный пользователь (не root) не может слушать порты ниже 1024 (например, 80 или 443).\nПоэтому внутри контейнера ваше приложение должно слушать порт 3000 или 8080.\nА уже снаружи через Docker вы можете пробросить его на 80-й порт: `-p 80:3000`.\n\n## Итого\n\nНикогда не запускайте продакшен-сервисы от root. Добавьте инструкцию `USER` в свой Dockerfile. Это одна строчка, которая закрывает огромную дыру в безопасности.\n\n"
    },
    {
      "title": "Лимиты ресурсов (CPU, Memory)",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "security",
        "slug": "02-resource-limits",
        "lang": "ru"
      },
      "path": "/content/materials/docker/security/02-resource-limits.ru.md",
      "content": "\nЧто будет, если в вашем приложении утечка памяти? Оно съест всю оперативку сервера.\nLinux начнет убивать процессы (OOM Killer), и под раздачу может попасть не виновник, а база данных или SSH-демон. Сервер \"умрет\".\n\nDocker позволяет жестко ограничить аппетиты контейнеров.\n\n## Ограничение памяти\n\n```bash\n# Жесткий лимит: 512 МБ\ndocker run -d --memory=\"512m\" nginx\n```\nЕсли Nginx попытается потребить 513 МБ, ядро Linux мгновенно убьет этот контейнер (OOM Killed), но остальная система не пострадает.\n\n## Ограничение CPU\n\n```bash\n# Дать контейнеру не более 50% от одного ядра\ndocker run -d --cpus=\"0.5\" nginx\n```\n\n## Настройка в Docker Compose\n\nВ `docker-compose.yml` (версия 3+) это делается в секции `deploy`:\n\n```yaml\nservices:\n  web:\n    image: nginx\n    deploy:\n      resources:\n        limits:\n          cpus: '0.50'\n          memory: 512M\n        reservations: # Гарантированный минимум\n          cpus: '0.25'\n          memory: 128M\n```\n\n*Примечание: для применения секции `deploy` в обычном `docker-compose` (не Swarm) может потребоваться флаг `--compatibility`, хотя в современных версиях V2 это часто работает из коробки.*\n\n## Итого\n\nВсегда ставьте лимиты памяти (`memory`) для Java и Node.js приложений. Они любят потреблять всё доступное пространство. Лимиты спасут ваш сервер от полного зависания.\n\n"
    },
    {
      "title": "Управление секретами и переменными окружения",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "security",
        "slug": "03-secrets",
        "lang": "ru"
      },
      "path": "/content/materials/docker/security/03-secrets.ru.md",
      "content": "\nКак мы выяснили, хранить пароли в коде или Dockerfile — нельзя.\nМы используем переменные окружения (`-e DB_PASS=...`). Но есть нюанс.\n\n## Проблема переменных окружения\n\nЛюбой, кто имеет доступ к серверу и может сделать `docker inspect my-container`, увидит все ваши пароли в открытом виде в секции `Env`.\nКроме того, переменные окружения часто попадают в логи ошибок.\n\n## Docker Secrets (для Docker Swarm / Kubernetes)\n\nЕсли вы используете оркестраторы, там есть механизм **Secrets**. Секрет монтируется как файл в оперативную память (`/run/secrets/my_db_pass`). Это безопасно.\n\n## Безопасность в обычном Docker (локально / один сервер)\n\nЕсли вы просто запускаете контейнеры на VPS:\n1. Используйте `.env` файл, который добавлен в `.gitignore` (чтобы не утек в репозиторий).\n2. Ограничьте доступ к серверу (SSH только по ключам).\n3. Ограничьте доступ к докер-сокету (чтобы никто лишний не мог сделать `docker inspect`).\n\n## Не запекайте секреты в образ!\n\n**Плохой Dockerfile:**\n```dockerfile\nENV DB_PASSWORD=secret123  <-- ПЛОХО! Останется в истории слоев навсегда.\n```\n\nЕсли вам нужен секрет **во время сборки** (например, токен для скачивания приватных npm-пакетов), используйте **Docker Build Secrets** (BuildKit).\n\n```dockerfile\n# В Dockerfile\nRUN --mount=type=secret,id=npmrc \\\n    cp /run/secrets/npmrc .npmrc && npm install\n```\n\nЗапуск сборки:\n```bash\ndocker build --secret id=npmrc,src=./.npmrc .\n```\nВ этом случае секрет «подмонтируется» только на время выполнения команды `RUN` и не сохранится в итоговом образе.\n\n## Итого\n\n- Пароли в `.env` (не в Dockerfile!).\n- Если собираете образ с приватными ключами — используйте `--mount=type=secret`.\n\n"
    },
    {
      "title": "Минимизация поверхности атаки",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 4,
      "id": {
        "category": "docker",
        "section": "security",
        "slug": "04-attack-surface",
        "lang": "ru"
      },
      "path": "/content/materials/docker/security/04-attack-surface.ru.md",
      "content": "\nБезопасность — это не только пароли. Это уменьшение возможностей для взлома.\nЧем меньше утилит в контейнере, тем сложнее хакеру.\n\n## 1. Минимальные образы (Alpine / Distroless)\n\nЕсли в контейнере есть `curl`, `wget`, `gcc`, хакер может скачать эксплойт, скомпилировать его и запустить.\nЕсли в контейнере нет даже `sh` (как в Distroless), хакер не сможет выполнить произвольный код (Shell Injection не сработает).\n\n**Совет:** Используйте `alpine` образы в продакшене. Удаляйте лишнее.\n\n## 2. Read-only файловая система\n\nЕсли приложению не нужно ничего писать на диск (кроме временных файлов в `/tmp`), запретите запись во всю файловую систему.\n\n```bash\ndocker run --read-only --tmpfs /tmp my-app\n```\nТеперь, даже если хакер найдет уязвимость, он не сможет изменить код вашего приложения или загрузить бэкдор.\n\n## 3. Сканирование образов\n\nРегулярно проверяйте свои образы на известные уязвимости (CVE).\n\nКоманда `docker scout` (встроена в новые версии Docker):\n```bash\ndocker scout quickview nginx:latest\n```\nОна покажет, сколько критических уязвимостей найдено в этом образе.\n\n## Итоговый чек-лист безопасности\n\n1. [ ] Запуск от обычного **USER** (не root).\n2. [ ] Лимиты ресурсов (**memory**, **cpus**).\n3. [ ] Минимальный базовый образ (**alpine**).\n4. [ ] Секреты не вшиты в образ.\n5. [ ] Регулярное обновление базовых образов.\n\n"
    },
    {
      "title": "Установка Docker и проверка работоспособности",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "setup",
      "sectionTitle": "Установка и первый запуск",
      "sectionOrder": 2,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "setup",
        "slug": "01-installation",
        "lang": "ru"
      },
      "path": "/content/materials/docker/setup/01-installation.ru.md",
      "content": "\nПеред тем как начать, нам нужно установить Docker. Процесс установки зависит от вашей операционной системы, но суть везде одна: мы ставим Docker Engine (сам движок) и Docker CLI (клиент).\n\n## Установка\n\nМы не будем дублировать официальную документацию, так как она обновляется чаще, чем этот курс. Перейдите по ссылке для вашей ОС и выполните инструкции:\n\n- **Windows / macOS**: Установите **Docker Desktop**. Это самый простой способ, который включает в себя всё необходимое + удобный графический интерфейс.\n  - [Скачать для Windows](https://docs.docker.com/desktop/install/windows-install/)\n  - [Скачать для Mac](https://docs.docker.com/desktop/install/mac-install/)\n- **Linux**: Рекомендуется устанавливать **Docker Engine** через репозиторий.\n  - [Инструкция для Ubuntu](https://docs.docker.com/engine/install/ubuntu/)\n  - [Инструкция для CentOS](https://docs.docker.com/engine/install/centos/)\n\n> **Важно для Linux**: После установки не забудьте добавить своего пользователя в группу docker, чтобы не писать `sudo` перед каждой командой:\n> ```bash\n> sudo usermod -aG docker $USER\n> ```\n\n## Проверка установки\n\nОткройте терминал (PowerShell, Terminal, iTerm) и введите команду:\n\n```bash\ndocker version\n```\n\nЕсли вы видите вывод с информацией о **Client** и **Server** — поздравляем, Docker работает!\nЕсли вы видите ошибку `Cannot connect to the Docker daemon`, значит сам движок Docker не запущен. На Windows/Mac запустите приложение Docker Desktop.\n\n## Hello World\n\nПо традиции запустим самый простой контейнер, чтобы убедиться, что всё действительно работает (сеть, скачивание образов, запуск).\n\nВыполните команду:\n\n```bash\ndocker run hello-world\n```\n\nЧто должно произойти:\n1. Docker скажет: `Unable to find image 'hello-world:latest' locally` (Не нашел образ локально).\n2. `Pulling from library/hello-world` (Скачивает из интернета).\n3. Выведет приветственное сообщение: `Hello from Docker!`.\n\nЕсли вы видите этот текст — ваша среда полностью готова к работе.\n\n## Итого\n\nМы установили Docker и проверили его работоспособность тестовым образом. Теперь мы готовы запускать настоящие приложения.\n\n"
    },
    {
      "title": "Запуск первого контейнера и публикация порта",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "setup",
      "sectionTitle": "Установка и первый запуск",
      "sectionOrder": 2,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "setup",
        "slug": "02-first-container",
        "lang": "ru"
      },
      "path": "/content/materials/docker/setup/02-first-container.ru.md",
      "content": "\nЗапускать `hello-world` скучно. Давайте запустим что-то полезное, например, веб-сервер **Nginx**.\n\nНаша задача: запустить веб-сервер в контейнере и открыть его в браузере на нашей машине.\n\n## Запуск в фоновом режиме\n\nЕсли просто написать `docker run nginx`, сервер запустится, но захватит ваш терминал. Вы будете видеть логи, но не сможете вводить команды. Обычно сервисы запускают в фоновом режиме (detached mode).\n\nДля этого используется флаг `-d`:\n\n```bash\ndocker run -d nginx\n```\n\nDocker вернет длинный хеш (ID контейнера) и вернет управление терминалом. Сервер работает где-то в фоне. Но как к нему подключиться?\n\n## Публикация портов (Port Mapping)\n\nПо умолчанию контейнер закрыт от внешнего мира. У Nginx внутри контейнера открыт порт 80, но снаружи (на вашем компьютере) к нему доступа нет. Нам нужно «пробросить» порт из контейнера наружу.\n\nИспользуем флаг `-p <порт_хоста>:<порт_контейнера>`.\n\nОстановим предыдущий контейнер (если запустили) и запустим правильно:\n\n```bash\n# -d: запуск в фоне\n# -p 8080:80: перенаправить порт 8080 вашего ПК на порт 80 контейнера\ndocker run -d -p 8080:80 nginx\n```\n\nТеперь откройте браузер и перейдите по адресу: [http://localhost:8080](http://localhost:8080).\nВы увидите стартовую страницу \"Welcome to nginx!\".\n\n### Что произошло?\n1. Браузер отправил запрос на ваш компьютер на порт `8080`.\n2. Docker перехватил этот запрос и перенаправил его внутрь контейнера на порт `80`.\n3. Nginx внутри контейнера ответил.\n\nВы можете изменить внешний порт на любой свободный, например `-p 3000:80`, тогда сайт будет доступен на `localhost:3000`. Внутренний порт (80) менять нельзя, так как Nginx настроен слушать именно его.\n\n## Итого\n\nКоманда `docker run` — основная команда для запуска.\n- Флаг `-d` запускает контейнер в фоне, чтобы не блокировать терминал.\n- Флаг `-p` пробрасывает порты, чтобы мы могли достучаться до приложения внутри контейнера.\n\n"
    },
    {
      "title": "Где Docker хранит данные и почему контейнеры эфемерны",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "setup",
      "sectionTitle": "Установка и первый запуск",
      "sectionOrder": 2,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "setup",
        "slug": "03-data-storage-and-ephemerality",
        "lang": "ru"
      },
      "path": "/content/materials/docker/setup/03-data-storage-and-ephemerality.ru.md",
      "content": "\nНовички часто совершают фатальную ошибку: они сохраняют важные данные прямо внутри контейнера.\nДавайте разберемся, почему так делать нельзя и что такое «эфемерность».\n\n## Эксперимент\n\n1. Запустим Ubuntu в интерактивном режиме (флаг `-it` позволяет «войти» внутрь контейнера):\n   ```bash\n   docker run -it ubuntu\n   ```\n2. Теперь мы внутри контейнера. Создадим файл с важными данными:\n   ```bash\n   echo \"My secret data\" > /important.txt\n   cat /important.txt\n   # Вывод: My secret data\n   ```\n3. Выйдем из контейнера командой `exit`. Контейнер остановился.\n\nТеперь попробуем запустить Ubuntu снова:\n```bash\ndocker run -it ubuntu\ncat /important.txt\n```\n**Результат:** `cat: /important.txt: No such file or directory`. Файла нет!\n\n## Почему данные пропали?\n\nКаждый раз, когда вы пишете `docker run`, Docker создает **совершенно новый** контейнер из чистого образа. Это как распаковать новый ноутбук из коробки: на нем нет ваших файлов, только заводские настройки.\n\nДаже если вы запустите тот же самый остановленный контейнер (командой `docker start`), данные сохранятся. Но в мире Docker принято считать контейнеры **эфемерными** (временными).\nКонтейнеры легко удаляются, пересоздаются, переезжают на другие серверы.\n\n**Золотое правило:** Всё, что записано внутри файловой системы контейнера, может исчезнуть в любой момент (при обновлении версии, при сбое, при удалении контейнера).\n\n## Как хранить данные надежно?\n\nДля хранения данных, которые должны пережить перезапуск или удаление контейнера (базы данных, логи, загруженные файлы), используются **Volumes (Тома)** или **Bind Mounts**.\n\nЭто механизм, который говорит Docker: «Храни эту папку не внутри контейнера, а на моем реальном жестком диске».\n\nПример (пока просто для ознакомления):\n```bash\ndocker run -d -v my-db-data:/var/lib/mysql mysql\n```\nВ этом случае, даже если вы удалите контейнер с MySQL, данные останутся в томе `my-db-data`, и новый контейнер сможет их подхватить.\n\n## Итого\n\n- Контейнеры по своей природе **эфемерны**.\n- `docker run` создает новый чистый контейнер.\n- Не храните важные данные внутри контейнера без использования томов (Volumes). Мы подробно разберем работу с данными в отдельном модуле.\n\n"
    },
    {
      "title": "Типы хранилищ: volumes vs bind mounts",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "storage",
      "sectionTitle": "Хранение данных",
      "sectionOrder": 5,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "storage",
        "slug": "01-volumes-vs-bind-mounts",
        "lang": "ru"
      },
      "path": "/content/materials/docker/storage/01-volumes-vs-bind-mounts.ru.md",
      "content": "\nКонтейнеры эфемерны. Удалил контейнер — потерял данные.\nЧтобы данные жили вечно (или хотя бы дольше контейнера), Docker предлагает два основных механизма: **Volumes** и **Bind Mounts**.\n\n## 1. Bind Mounts (Привязка папок)\n\nЭто самый простой и понятный способ для разработки.\nВы берете реальную папку на вашем компьютере и \"монтируете\" (пробрасываете) её внутрь контейнера.\nИзменения видны сразу: поменяли файл в IDE — он изменился внутри контейнера.\n\n```bash\n# Монтируем текущую папку $(pwd) в папку /app внутри контейнера\ndocker run -v $(pwd):/app node:18\n```\n\n**Плюсы:**\n- Идеально для разработки (hot reload работает).\n- Вы полностью контролируете файлы.\n\n**Минусы:**\n- Зависит от структуры папок хоста (путь `/Users/vasya/project` не сработает на сервере Linux).\n- Проблемы с правами доступа (Permissions) между хостом и контейнером.\n- Работает медленнее на Mac/Windows (из-за прослойки виртуализации файловой системы).\n\n## 2. Volumes (Тома)\n\nЭто \"родной\" способ хранения данных в Docker.\nВы не говорите, ГДЕ хранить данные на диске. Вы говорите Docker-у: \"Создай мне хранилище с именем `my-db-data` и следи за ним сам\".\nDocker хранит эти данные где-то в своих недрах (`/var/lib/docker/volumes/...`).\n\n```bash\n# Создаем том\ndocker volume create my-db-data\n\n# Подключаем его к базе данных\ndocker run -v my-db-data:/var/lib/mysql mysql\n```\n\n**Плюсы:**\n- Работает быстрее, чем bind mounts (особенно на Mac/Win).\n- Не зависит от структуры папок хоста.\n- Безопаснее: другие процессы не лезут в эти файлы.\n- Легко переносить и бекапить средствами Docker.\n\n**Минусы:**\n- Неудобно лезть в эти файлы руками (они спрятаны глубоко в системных папках).\n\n## Когда что использовать?\n\n| Сценарий | Выбор | Почему |\n| :--- | :--- | :--- |\n| **Разработка кода** | **Bind Mount** | Чтобы изменения кода сразу попадали в контейнер без пересборки. |\n| **Базы данных** | **Volume** | Скорость, надежность, изоляция. Вам не нужно смотреть файлы БД руками. |\n| **Конфиги** | **Bind Mount** | Удобно править конфиг (`nginx.conf`) и перезапускать контейнер. |\n| **Логи** | **Volume** | Чтобы не засорять папку проекта, но сохранять историю. |\n\n## Итого\n\n- **Bind Mount (`-v /path:/path`)**: Проброс конкретной папки. Для кода и конфигов.\n- **Volume (`-v name:/path`)**: Управляемое хранилище. Для баз данных и важных данных приложения.\n\n"
    },
    {
      "title": "Подключение томов к базе данных",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "storage",
      "sectionTitle": "Хранение данных",
      "sectionOrder": 5,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "storage",
        "slug": "02-database-volumes",
        "lang": "ru"
      },
      "path": "/content/materials/docker/storage/02-database-volumes.ru.md",
      "content": "\nСамый частый кейс использования Volumes — это базы данных.\nДавайте запустим Postgres так, чтобы данные не пропали после удаления контейнера.\n\n## 1. Запуск без тома (ОШИБКА)\n\n```bash\ndocker run -d --name pg-test -e POSTGRES_PASSWORD=secret postgres\n```\nЕсли вы сейчас создадите таблицу, а потом сделаете `docker rm -f pg-test`, данные исчезнут навсегда. Потому что Postgres хранит данные в папке `/var/lib/postgresql/data` **внутри** контейнера.\n\n## 2. Запуск с именованным томом (ПРАВИЛЬНО)\n\nСоздадим том:\n```bash\ndocker volume create pg-data\n```\n\nЗапустим контейнер, подключив этот том:\n```bash\ndocker run -d \\\n  --name pg-prod \\\n  -e POSTGRES_PASSWORD=secret \\\n  -v pg-data:/var/lib/postgresql/data \\\n  postgres\n```\n\nТеперь:\n1. Зайдите в контейнер, создайте таблицу.\n2. Удалите контейнер: `docker rm -f pg-prod`.\n3. Запустите новый контейнер с **тем же томом** (`-v pg-data:...`).\n4. Вуаля! Ваши данные на месте.\n\n## Как посмотреть список томов\n\n```bash\ndocker volume ls\n```\n\n## Как очистить неиспользуемые тома\n\nТома не удаляются автоматически, когда вы удаляете контейнер (чтобы вы случайно не потеряли данные).\nСо временем они накапливаются.\n\nУдалить конкретный том:\n```bash\ndocker volume rm pg-data\n```\n⚠️ **Внимание:** Это необратимо удалит все данные базы!\n\nОчистить все \"повисшие\" тома (которые не подключены ни к одному контейнеру):\n```bash\ndocker volume prune\n```\n\n## Итого\n\nДля любой базы данных (Postgres, MySQL, Mongo, Redis) **всегда** создавайте отдельный Volume. Это ваша страховка от потери данных.\n\n"
    },
    {
      "title": "Бэкап, восстановление и перенос данных volumes",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "storage",
      "sectionTitle": "Хранение данных",
      "sectionOrder": 5,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "storage",
        "slug": "03-backup-restore",
        "lang": "ru"
      },
      "path": "/content/materials/docker/storage/03-backup-restore.ru.md",
      "content": "\nВы используете Volumes. Это круто. Но как сделать бэкап?\nВедь том — это не просто папка, в которую можно зайти проводником (особенно на Mac/Windows).\n\nDocker-way решение: использовать временный контейнер-утилиту.\n\n## Создание бэкапа\n\nЗадача: Заархивировать содержимое тома `my-data` в файл `backup.tar.gz` в текущей папке.\n\n```bash\ndocker run --rm \\\n  -v my-data:/source \\\n  -v $(pwd):/backup \\\n  alpine \\\n  tar czf /backup/backup.tar.gz -C /source .\n```\n\nРазберем эту магию:\n1. `docker run --rm`: Запустить и сразу удалить контейнер после завершения.\n2. `-v my-data:/source`: Подключили наш том c данными в папку `/source` внутри контейнера.\n3. `-v $(pwd):/backup`: Подключили текущую папку хоста в папку `/backup` внутри контейнера.\n4. `alpine`: Используем самый легкий образ.\n5. `tar ...`: Команда архивации. Берет файлы из `/source` и кладет архив в `/backup`.\n\nВ итоге у вас на компьютере появляется файл `backup.tar.gz`.\n\n## Восстановление из бэкапа\n\nЗадача: Распаковать `backup.tar.gz` в новый том `restored-data`.\n\n1. Создаем пустой том:\n```bash\ndocker volume create restored-data\n```\n\n2. Запускаем распаковку:\n```bash\ndocker run --rm \\\n  -v restored-data:/dest \\\n  -v $(pwd):/backup \\\n  alpine \\\n  tar xzf /backup/backup.tar.gz -C /dest\n```\n\nЛогика та же: монтируем том и папку с бэкапом, но теперь выполняем команду распаковки (`tar x...`).\n\n## Зачем это нужно?\n\n- Перенос данных с локальной машины на сервер (сделали tar -> scp на сервер -> распаковали).\n- Регулярные бэкапы перед обновлением базы данных.\n- Переезд на другую машину.\n\n## Итого\n\nНе бойтесь того, что данные \"спрятаны\" в Volume. С помощью маленького контейнера Alpine вы всегда можете добраться до них, заархивировать и перенести куда угодно.\n\n"
    },
    {
      "title": "Алгоритм поиска неисправностей",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "troubleshooting",
      "sectionTitle": "Типичные проблемы и решения",
      "sectionOrder": 10,
      "order": 1,
      "id": {
        "category": "docker",
        "section": "troubleshooting",
        "slug": "01-troubleshooting-flow",
        "lang": "ru"
      },
      "path": "/content/materials/docker/troubleshooting/01-troubleshooting-flow.ru.md",
      "content": "\nКонтейнер не запускается или работает неправильно? Без паники.\nСледуйте этому алгоритму, чтобы найти причину за 5 минут.\n\n## 1. Проверьте статус (docker ps -a)\n\n```bash\ndocker ps -a\n```\nСмотрите на колонку **STATUS**:\n- `Up 2 minutes` — работает.\n- `Exited (1) 5 seconds ago` — упал с ошибкой.\n- `Exited (0)` — завершился успешно (штатно).\n- `Restarting (1)` — падает, перезапускается, падает снова (Cyclic Restart).\n\n## 2. Читайте логи (docker logs)\n\nЕсли контейнер упал или перезапускается — причина в 99% случаев написана в логах.\n\n```bash\ndocker logs <container_name>\n```\nИщите ключевые слова: `Error`, `Exception`, `Fatal`, `Address already in use`.\n\n**Частая ошибка:** Приложение падает молча.\nЗначит, оно пишет логи не в stdout, а в файл внутри контейнера.\nРешение: Зайдите внутрь (`docker exec`) и найдите лог-файл, или настройте приложение писать в консоль.\n\n## 3. Проверьте настройки (docker inspect)\n\nЕсли приложение работает, но ведет себя странно (не видит базу, не тот порт), проверьте, как оно запущено.\n\n```bash\ndocker inspect <container_name>\n```\nЧто проверять:\n- **Mounts**: Правильно ли примонтированы папки? Тот ли путь?\n- **Env**: Те ли переменные окружения (пароли, хосты)?\n- **NetworkSettings**: Тот ли IP? Открыты ли порты?\n\n## 4. Зайдите внутрь (docker exec)\n\nЕсли снаружи ничего не понятно, лезьте внутрь.\n\n```bash\ndocker exec -it <container_name> sh\n```\nВнутри проверьте:\n- Виден ли соседний сервис? `ping db` или `nc -zv db 5432`.\n- Есть ли файлы конфигурации? `cat /app/config.json`.\n- Какие процессы запущены? `top` или `ps aux`.\n\n## 5. Проверьте ресурсы (docker stats)\n\nМожет, контейнеру просто не хватает памяти, и он \"тупит\"?\n\n```bash\ndocker stats\n```\nВы увидите живое потребление CPU и RAM. Если RAM уперлась в лимит — это кандидат на вылет (OOM Kill).\n\n## Итого\n\nЛоги (`logs`) -> Конфиг (`inspect`) -> Проверка изнутри (`exec`).\nЭтот треугольник решает любую проблему.\n\n"
    },
    {
      "title": "Проблемы с сетью: connection refused, DNS",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "troubleshooting",
      "sectionTitle": "Типичные проблемы и решения",
      "sectionOrder": 10,
      "order": 2,
      "id": {
        "category": "docker",
        "section": "troubleshooting",
        "slug": "02-network-issues",
        "lang": "ru"
      },
      "path": "/content/materials/docker/troubleshooting/02-network-issues.ru.md",
      "content": "\n\"Приложение не может подключиться к базе данных\". Это самая частая боль новичков.\n\n## Ошибка 1: Connection Refused (127.0.0.1)\n\n**Ситуация:**\nУ вас в конфиге приложения написано: `DB_HOST=localhost`.\nПриложение внутри контейнера пытается подключиться к `localhost`... и не находит там базы.\n\n**Причина:**\nВнутри контейнера `localhost` — это **сам контейнер**. База данных находится в **другом** контейнере.\n\n**Решение:**\nИспользуйте имя сервиса базы данных как хост: `DB_HOST=postgres` (или как вы назвали сервис в docker-compose).\n\n## Ошибка 2: Host not found (DNS)\n\n**Ситуация:**\nВы пишете `DB_HOST=postgres`, но получаете ошибку `getaddrinfo EAI_AGAIN postgres`.\n\n**Причина:**\nКонтейнеры не находятся в одной пользовательской сети.\nЕсли вы запускали их через `docker run` без флага `--network`, они попали в дефолтный `bridge`, где DNS по именам **не работает**.\n\n**Решение:**\nСоздайте сеть и поместите оба контейнера туда:\n```bash\ndocker network create my-net\ndocker run --network my-net ... db\ndocker run --network my-net ... app\n```\n(Docker Compose делает это автоматически).\n\n## Ошибка 3: Connection refused (Wrong Port)\n\n**Ситуация:**\n`DB_HOST=postgres`, сеть есть, но соединения нет.\n\n**Причина:**\n1. База еще не успела запуститься (Race Condition). См. урок про `depends_on`.\n2. Вы стучитесь не в тот порт. Postgres — 5432, MySQL — 3306, Redis — 6379.\n3. База настроена слушать только `127.0.0.1` (внутри своего конфига `listen_addresses`). Ей нужно разрешить слушать `0.0.0.0`.\n\n## Диагностика сети из контейнера\n\nУстановите `curl` или `nc` (netcat) внутри контейнера для проверки:\n\n```bash\n# Проверка DNS: видит ли он IP?\ngetent hosts postgres\n\n# Проверка порта: открыт ли он?\nnc -zv postgres 5432\n```\nЕсли `nc` пишет `Open`, значит сеть работает, и проблема в логике приложения (неверный пароль, имя базы).\n\n## Итого\n\nЗабудьте слово `localhost` внутри контейнеров (если только вы не обращаетесь к процессу в *этом же* контейнере). Используйте имена сервисов.\n\n"
    },
    {
      "title": "Проблемы со сборкой: build context, cache miss",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "troubleshooting",
      "sectionTitle": "Типичные проблемы и решения",
      "sectionOrder": 10,
      "order": 3,
      "id": {
        "category": "docker",
        "section": "troubleshooting",
        "slug": "03-build-issues",
        "lang": "ru"
      },
      "path": "/content/materials/docker/troubleshooting/03-build-issues.ru.md",
      "content": "\nКогда `docker build` идет не по плану.\n\n## 1. Сборка идет очень долго (Sending build context)\n\n**Симптом:**\nВы запускаете билд, и видите:\n```\nSending build context to Docker daemon  500MB\n```\nИ только через минуту начинается реальная работа.\n\n**Причина:**\nВы не добавили `.dockerignore`. Docker копирует вашу папку `node_modules`, `.git`, видео с котиками и всё остальное демону перед началом сборки.\n\n**Решение:**\nСоздайте `.dockerignore` и исключите всё лишнее.\n\n## 2. npm install выполняется каждый раз\n\n**Симптом:**\nВы поменяли одну строчку в коде, а Docker заново качает весь интернет (`npm install`), тратя 5 минут.\n\n**Причина:**\nНеправильный порядок слоев. Вы скопировали `COPY . .` **до** `RUN npm install`. Любое изменение кода сбрасывает кеш для установки пакетов.\n\n**Решение:**\nСначала `COPY package.json`, потом `RUN npm install`, потом `COPY . .`.\n\n## 3. \"Файл не найден\" при COPY\n\n**Симптом:**\n`COPY ./config/app.conf /app/` падает с ошибкой `file not found`.\n\n**Причина:**\nВы думаете, что путь относительный от Dockerfile, но на самом деле он от **контекста сборки**.\nОбычно контекст — это точка в конце команды: `docker build .`.\n\nЕсли вы запускаете билд из другой папки: `docker build -f ./backend/Dockerfile .`, то контекст — текущая папка, а Dockerfile ищет файлы внутри `backend`.\n\n**Решение:**\nВсегда запускайте билд из корня проекта, или внимательно следите за путями.\n\n## 4. Windows Line Endings (CRLF)\n\n**Симптом:**\nБаш-скрипт внутри контейнера падает с ошибкой: `/bin/sh^M: bad interpreter`.\n\n**Причина:**\nВы редактировали файл `entrypoint.sh` в Windows (Notepad), и он сохранился с окончаниями строк `CRLF` (Carriage Return + Line Feed). Linux понимает только `LF`.\n\n**Решение:**\nПересохраните файл с LF (в VS Code: справа снизу кнопка \"CRLF\" -> переключить на \"LF\"). Или настройте git `core.autocrlf`.\n\n## Итого\n\nСледите за контекстом, кешем и окончаниями строк. И не забывайте про `.dockerignore`.\n\n"
    },
    {
      "title": "Docker на Windows/Mac: нюансы производительности",
      "category": "docker",
      "categoryTitle": "Docker",
      "section": "troubleshooting",
      "sectionTitle": "Типичные проблемы и решения",
      "sectionOrder": 10,
      "order": 4,
      "id": {
        "category": "docker",
        "section": "troubleshooting",
        "slug": "04-platform-specifics",
        "lang": "ru"
      },
      "path": "/content/materials/docker/troubleshooting/04-platform-specifics.ru.md",
      "content": "\nDocker — это технология Linux.\nНа Windows и macOS Docker не может работать нативно. Он запускает скрытую **виртуальную машину (Linux VM)** и работает в ней.\n\nЭто порождает ряд особенностей.\n\n## 1. Медленная файловая система (Bind Mounts)\n\n**Проблема:**\nВы разрабатываете Symfony/Laravel/Magento проект с тысячами файлов. На Linux страницы грузятся за 200мс. На Mac с Docker Desktop — за 5 секунд.\n\n**Причина:**\nПроброс файлов с хоста (macOS/Win) в Linux VM через `Bind Mounts` (`-v $(pwd):/app`) — это очень дорогая операция. Каждое чтение файла проходит через прослойку виртуализации (gRPC/FUSE).\n\n**Решение:**\n1. **VirtioFS (для Mac):** В настройках Docker Desktop включите `Use VirtioFS`. Это ускоряет работу в разы.\n2. **WSL 2 (для Windows):** Используйте WSL 2 бэкенд. Храните код проекта **внутри** файловой системы Linux (`\\\\wsl$\\Ubuntu\\home\\user\\project`), а не на диске `C:\\`. Скорость будет нативной.\n3. **Не монтируйте лишнего:** Исключайте `node_modules` или `vendor` из bind mount (используйте volume trick), чтобы Docker не синхронизировал эти папки с хостом.\n\n## 2. Потребление памяти\n\n**Проблема:**\nDocker Desktop жрет 4-8 ГБ RAM, даже если контейнеры ничего не делают.\n\n**Причина:**\nВиртуальная машина резервирует память заранее.\n\n**Решение:**\nВ настройках Docker Desktop (Resources) ограничьте Memory Limit (например, 4 ГБ). Больше этого значения VM не возьмет.\n\n## 3. Host Networking\n\nРежим `--network host` работает **только на Linux**.\nНа Mac/Win вы не можете обратиться к контейнеру по IP-адресу контейнера. Только через `localhost` и проброшенные порты (`-p`).\n\n## Итого\n\nЕсли нужен максимальный перформанс — используйте Linux.\nЕсли сидите на Mac/Win:\n- Mac: Включите VirtioFS.\n- Windows: Используйте WSL 2 и храните код там.\n\n"
    },
    {
      "title": "Что такое Go",
      "category": "golang",
      "categoryTitle": "Go",
      "section": "intro",
      "sectionTitle": "Введение",
      "sectionOrder": 1,
      "order": 1,
      "id": {
        "category": "golang",
        "section": "intro",
        "slug": "01-what-is-go",
        "lang": "ru"
      },
      "path": "/content/materials/golang/intro/01-what-is-go.ru.md",
      "content": "\nGo (часто называют Golang) — это компилируемый язык программирования, разработанный в Google. Его создали, чтобы объединить простоту разработки (как в Python) с производительностью и безопасностью (как в C++). Go специально спроектирован для создания эффективных серверных приложений, микросервисов и инструментов командной строки.\n\nГлавная фишка языка — он не пытается быть самым умным или сложным. Наоборот, Go намеренно ограничивает количество концепций, чтобы код оставался читаемым и понятным даже в огромных проектах. Здесь нет сложного наследования, перегрузки операторов или магии, скрытой под капотом. Всё максимально явно и просто.\n\n## Простота и читаемость\n\nКод на Go читается почти как обычный текст. Синтаксис минималистичен: нет лишних скобок там, где они не нужны, и строгие правила форматирования. В Go встроен инструмент `gofmt`, который автоматически форматирует код по единому стандарту. Это значит, что код любого разработчика выглядит одинаково, и не нужно спорить о расстановке пробелов.\n\n## Высокая производительность\n\nGo — компилируемый язык со строгой статической типизацией. Программа преобразуется сразу в машинный код (один бинарный файл), который запускается на сервере без установки дополнительных виртуальных машин или интерпретаторов.\n\nЭто даёт скорость, сравнимую с C или C++, но при этом Go берёт на себя управление памятью (есть Garbage Collector), избавляя программиста от ручной работы с выделением и очисткой ресурсов.\n\n## Конкурентность из коробки\n\nОдна из самых сильных сторон Go — работа с многопоточностью. Вместо тяжёлых потоков операционной системы здесь используются **горутины** (goroutines). Это лёгкие потоки, которых можно запустить тысячи или даже миллионы на одной машине.\n\nОбщение между ними происходит через **каналы** (channels) — безопасный способ передачи данных без использования сложных блокировок.\n\n```go\nfunc main() {\n    // Запуск функции в отдельной горутине\n    go processData()\n    \n    // Основная программа продолжает работу\n    fmt.Println(\"Start processing...\")\n}\n```\n\n## Где используют Go\n\nGo стал стандартом индустрии для облачной инфраструктуры и высоконагруженных систем. На нём написаны:\n- **Docker** и **Kubernetes** — инструменты контейнеризации;\n- **Prometheus** и **Grafana** (бэкенд) — системы мониторинга;\n- **Terraform** — управление инфраструктурой;\n- Огромная часть микросервисов в компаниях вроде Uber, Twitch, Dropbox и Google.\n\nЕсли нужно написать быстрый веб-сервер, API или консольную утилиту, которая будет работать быстро и стабильно, Go — отличный выбор.\n\n## Итог\n\nGo — это язык для инженерии, а не для академических изысканий. Он простой, быстрый и надёжный. Если ваша цель — создавать масштабируемые серверные системы, которые легко поддерживать и развивать, Go даст вам всё необходимое без лишней сложности.\n"
    },
    {
      "title": "Установка Go и настройка окружения",
      "category": "golang",
      "categoryTitle": "Go",
      "section": "intro",
      "sectionTitle": "Введение",
      "sectionOrder": 1,
      "order": 2,
      "id": {
        "category": "golang",
        "section": "intro",
        "slug": "02-installation-and-setup",
        "lang": "ru"
      },
      "path": "/content/materials/golang/intro/02-installation-and-setup.ru.md",
      "content": "\nЧтобы начать писать на Go, нужно установить компилятор и настроить рабочее место. Процесс установки максимально упрощён: Go поставляется как один пакет, который содержит всё необходимое — от компилятора и форматтера до инструментов тестирования и документации.\n\nВ отличие от многих других языков, здесь не нужно ставить отдельные менеджеры пакетов или сложные среды выполнения. Всё работает «из коробки».\n\n## Установка Go\n\nСамый надёжный способ — скачать официальный установщик с сайта [go.dev](https://go.dev/dl/).\n\n1. Перейдите на страницу загрузки.\n2. Выберите версию для вашей ОС (Windows, macOS или Linux).\n3. Запустите установщик и следуйте инструкциям.\n\nПосле установки откройте терминал (или командную строку) и проверьте, что всё прошло успешно:\n\n```bash\ngo version\n```\n\nЕсли вы видите что-то вроде `go version go1.22.0 darwin/arm64`, значит, Go установлен и готов к работе.\n\n## Настройка окружения\n\nРаньше в Go была обязательна сложная структура папок (`GOPATH`), где весь код должен был лежать в строго определённом месте. Сейчас это в прошлом.\n\nСовременный Go использует **Go Modules**. Это значит, что вы можете создавать проекты в любой удобной папке на диске. Вам не нужно настраивать системные переменные, если вы используете свежую версию языка.\n\n## Выбор редактора кода\n\nGo отлично поддерживается большинством редакторов, но стандартом де-факто сейчас являются:\n\n### VS Code\n\nБесплатный и лёгкий редактор. Для работы с Go нужно установить официальное расширение **Go** (от Go Team at Google).\nОно автоматически предложит установить дополнительные утилиты (`gopls`, `dlv` и другие) при первом открытии `.go` файла. Соглашайтесь — это даст автодополнение, подсветку ошибок и возможность отладки.\n\n### GoLand\n\nМощная IDE от JetBrains. Платная, но с невероятно глубоким анализом кода и удобным рефакторингом. Если вы привыкли к продуктам JetBrains (IntelliJ IDEA, PyCharm), здесь вы будете чувствовать себя как дома.\n\n## Полезные команды\n\nУтилита `go` — это ваш швейцарский нож. Вот основные команды, которые пригодятся сразу:\n\n```bash\n# Проверить версию\ngo version\n\n# Посмотреть документацию по конкретному пакету (например, fmt)\ngo doc fmt\n\n# Узнать, где установлен Go и какие переменные окружения используются\ngo env\n```\n\n## Итог\n\nУстановка Go сводится к скачиванию одного файла и нажатию кнопки «Далее». Вам не нужно возиться с конфигурациями путей или сложными зависимостями. Главное — убедитесь, что команда `go version` работает в терминале, и установите плагин для вашего любимого редактора. Теперь вы готовы написать первую программу.\n"
    },
    {
      "title": "Первый проект и запуск",
      "category": "golang",
      "categoryTitle": "Go",
      "section": "intro",
      "sectionTitle": "Введение",
      "sectionOrder": 1,
      "order": 3,
      "id": {
        "category": "golang",
        "section": "intro",
        "slug": "03-first-program",
        "lang": "ru"
      },
      "path": "/content/materials/golang/intro/03-first-program.ru.md",
      "content": "\nВ Go любая программа — это проект (модуль). Даже если вы пишете простой скрипт, хорошей практикой считается оформить его как модуль. Это позволяет фиксировать версии библиотек и делает проект переносимым.\n\nНапишем классическую программу «Hello, World!», разберём структуру файла и научимся запускать и собирать код.\n\n## Создание модуля\n\nСоздайте новую папку для проекта и перейдите в неё:\n\n```bash\nmkdir hello-go\ncd hello-go\n```\n\nТеперь инициализируем модуль. Имя модуля обычно совпадает с путём к репозиторию (например, `github.com/user/project`), но для локальных тестов можно назвать его просто `example/hello`.\n\n```bash\ngo mod init example/hello\n```\n\nЭта команда создаст файл `go.mod`. В нём Go будет хранить информацию о названии вашего модуля и версии языка.\n\n## Написание кода\n\nСоздайте файл `main.go` и добавьте в него следующий код:\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    fmt.Println(\"Hello, Go!\")\n}\n```\n\nРазберём, что здесь происходит:\n- `package main`: Первая строка любого файла указывает, к какому пакету он относится. Пакет `main` — особенный. Именно он говорит компилятору, что это исполняемая программа, а не библиотека.\n- `import \"fmt\"`: Подключаем встроенный пакет `fmt` (format) для вывода текста.\n- `func main()`: Главная функция. Выполнение программы всегда начинается с неё.\n\n## Запуск программы\n\nЧтобы быстро проверить работу кода без создания бинарного файла, используйте команду `run`:\n\n```bash\ngo run main.go\n```\n\nВы увидите вывод:\n```\nHello, Go!\n```\n\nКоманда `go run` компилирует программу во временную папку, запускает её и сразу очищает следы. Это идеально для разработки.\n\n## Компиляция (Сборка)\n\nЕсли вы хотите получить готовый исполнимый файл (бинарник), который можно запустить на другом компьютере (даже там, где нет Go), используйте команду `build`:\n\n```bash\ngo build\n```\n\nВ папке появится файл `hello` (или `hello.exe` на Windows). Теперь его можно запустить напрямую:\n\n```bash\n./hello\n```\n\nЭтот файл полностью самодостаточен. В него «вшиты» все необходимые библиотеки.\n\n## Итог\n\nМы прошли полный цикл создания простой программы:\n1. `go mod init` — создали основу проекта.\n2. `package main` — написали код точки входа.\n3. `go run` — быстро запустили для проверки.\n4. `go build` — собрали готовое приложение.\n\nТеперь у вас есть рабочий фундамент для изучения синтаксиса и более сложных конструкций языка.\n"
    },
    {
      "title": "Lua-скрипты",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "advanced",
      "sectionTitle": "Продвинутые темы",
      "sectionOrder": 12,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "advanced",
        "slug": "01-lua-scripts",
        "lang": "ru"
      },
      "path": "/content/materials/redis/advanced/01-lua-scripts.ru.md",
      "content": "\nИногда одной команды Redis недостаточно: нужно сделать несколько проверок, обновить пару ключей и при этом сохранить атомарность. В таких случаях выручает встроенная поддержка **Lua-скриптов**: небольшой скрипт выполняется целиком как одна команда, без гонок между конкурентными клиентами.\n\nГлавная идея: сложная логика с несколькими шагами переносится в Redis и выполняется там, где лежат данные.\n\n## Запуск простого Lua-скрипта\n\nБазовая команда — **EVAL**. Внутри скрипта доступны массивы **KEYS** и **ARGV**: первые используются для имён ключей, вторые — для произвольных аргументов.\n\nПример: атомарно увеличить счётчик только если он меньше порога.\n\n```\nEVAL \"\n  local current = tonumber(redis.call('GET', KEYS[1]) or '0')\n  if current >= tonumber(ARGV[1]) then\n    return current\n  end\n  current = current + 1\n  redis.call('SET', KEYS[1], current)\n  return current\n\" 1 metrics:actions 100\n```\n\nЧто происходит:\n\n- скрипт читает значение **metrics:actions**;\n- если значение достигло порога **100**, просто возвращает его;\n- иначе увеличивает и сохраняет обратно;\n- вся логика выполняется как одна атомарная операция.\n\n## Использование SHA и кэширование скриптов\n\nКаждый скрипт можно загрузить в Redis и вызывать по SHA‑хэшу. Это уменьшает накладные расходы при частом запуске.\n\nЗагрузка:\n\n```\nSCRIPT LOAD \"\n  return redis.call('INCRBY', KEYS[1], tonumber(ARGV[1]))\n\"\n```\n\nRedis вернёт SHA скрипта, например:\n\n```\n\"f2b3c0...\"\n```\n\nВызов по SHA:\n\n```\nEVALSHA f2b3c0... 1 metrics:views 10\n```\n\nЕсли скрипт уже загружен, Redis сразу выполнит его, минуя повторный разбор текста.\n\n## Ограничения и практические рекомендации\n\nВажно помнить:\n\n- скрипты выполняются в одном потоке и блокируют выполнение других команд до завершения;\n- нельзя вызывать команды, которые требуют пользовательского ввода или делают блокировки;\n- скрипты должны быть быстрыми и предусказуемыми по времени выполнения.\n\nПрактичные советы:\n\n- выносить в Lua только логику, где критична атомарность и несколько шагов;\n- не загонять в скрипт огромные циклы по тысячам ключей;\n- держать код скриптов в репозитории, а не писать случайный текст прямо в консоли.\n\n## Итог\n\n**Lua-скрипты** позволяют реализовывать сложные атомарные операции прямо в Redis, без гонок и дополнительных сетевых запросов.\n\nЕсли использовать их точечно — для проверки и обновления нескольких ключей за один шаг — можно заметно упростить код приложения и повысить надёжность критичных операций.\n\n\n"
    },
    {
      "title": "Транзакции и мультикоманды",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "advanced",
      "sectionTitle": "Продвинутые темы",
      "sectionOrder": 12,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "advanced",
        "slug": "02-transactions",
        "lang": "ru"
      },
      "path": "/content/materials/redis/advanced/02-transactions.ru.md",
      "content": "\nВ **Redis** нет привычных транзакций с изоляцией и откатом, как в классических СУБД, но есть механизм **MULTI/EXEC** и оптимистичные блокировки через **WATCH**. Вместе они позволяют группировать несколько команд в одну «мультикоманду» и атомарно применять изменения, если никто не успел вмешаться.\n\nВажно понимать, что транзакции в Redis — это скорее последовательное выполнение команд без прерывания, чем полноценная ACID‑модель.\n\n## MULTI/EXEC — группировка команд\n\nБазовый паттерн:\n\n1. Открываем транзакцию командой **MULTI**.\n2. Отправляем несколько команд — они не выполняются сразу, а попадают в очередь.\n3. Фиксируем изменения через **EXEC**.\n\nПример: инкремент двух счётчиков как одной операции.\n\n```\nMULTI\nINCR metrics:views\nINCR metrics:clicks\nEXEC\n```\n\nЗдесь:\n\n- обе команды попадут в очередь;\n- при EXEC Redis выполнит их последовательно, без вмешательства других клиентов между ними;\n- отката при ошибке одной команды нет — ответственность на приложении.\n\n## WATCH — оптимистичная блокировка\n\nЕсли важно убедиться, что данные не менялись между чтением и записью, используют **WATCH**. Он помечает один или несколько ключей как наблюдаемые; если какой‑то из них изменится до EXEC, транзакция не выполнится.\n\nПример: безопасное списание баланса.\n\n```\nWATCH user:42:balance\nGET user:42:balance\nMULTI\nDECRBY user:42:balance 100\nEXEC\n```\n\nСценарий:\n\n- после WATCH и GET приложение решает, достаточно ли средств;\n- если в это время другой клиент изменит **user:42:balance**, EXEC вернёт nil — транзакция не применится;\n- приложение может повторить попытку или сообщить об ошибке.\n\nТакой подход называют оптимистичной блокировкой: нет тяжёлых лочков, но есть проверка на конкурентные изменения.\n\n## Пайплайны против транзакций\n\nВажно не путать:\n\n- транзакции (**MULTI/EXEC**) — про атомарность группы команд;\n- пайплайны — про уменьшение сетевых задержек за счёт отправки нескольких команд одним пакетом.\n\nМногие клиентские библиотеки позволяют отправлять пачку команд без ожидания ответов по очереди. Это ускоряет работу, но не даёт никаких гарантий атомарности.\n\nКомбинировать подходы можно: внутри пайплайна использовать MULTI/EXEC, если нужна и скорость, и атомарность.\n\n## Итог\n\nТранзакции в **Redis** через **MULTI/EXEC** и **WATCH** помогают группировать команды и защищаться от гонок при конкурентных изменениях.\n\nЕсли правильно использовать оптимистичные блокировки и помнить об отсутствии автоматического отката, можно реализовать надёжные сценарии обновления нескольких ключей без излишнего усложнения архитектуры.\n\n\n"
    },
    {
      "title": "Модули Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "advanced",
      "sectionTitle": "Продвинутые темы",
      "sectionOrder": 12,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "advanced",
        "slug": "03-redis-modules",
        "lang": "ru"
      },
      "path": "/content/materials/redis/advanced/03-redis-modules.ru.md",
      "content": "\nБазовый **Redis** уже даёт много возможностей, но иногда хочется добавить свои типы данных, команды или встроить внешнюю логику ближе к памяти. Для этого существуют **модули Redis** — динамические расширения, которые сервер может загружать при старте или во время работы.\n\nМодули позволяют превратить Redis во что‑то большее, чем «ключ–значение»: поисковый движок, графовую базу, JSON‑хранилище и многое другое.\n\n## Как подключаются модули\n\nМодуль — это скомпилированная библиотека (обычно .so), которую Redis загружает командой **MODULE LOAD** или через конфиг.\n\nЧерез конфиг:\n\n```\nloadmodule /etc/redis/modules/my_module.so\n```\n\nЧерез команду:\n\n```\nMODULE LOAD /etc/redis/modules/my_module.so\n```\n\nПосмотреть загруженные модули:\n\n```\nMODULE LIST\n```\n\nРазгрузить модуль (если разрешено конфигурацией):\n\n```\nMODULE UNLOAD my_module\n```\n\nКак правило, в продакшене модули подключают через конфиг при старте, чтобы при перезапуске Redis всегда поднимался в одном и том же составе.\n\n## Что дают модули на практике\n\nПопулярные официальные и сторонние модули добавляют:\n\n- новые структуры данных (JSON‑объекты, графы, временные ряды);\n- продвинутый поиск и индексацию;\n- готовые высокоуровневые функции (например, для анализа данных).\n\nИдея в том, что тяжёлую по логике часть можно реализовать один раз как модуль, а приложение будет работать с ней через привычный протокол Redis.\n\n## Ограничения и осторожность\n\nВажно помнить:\n\n- модули работают внутри процесса Redis, любые ошибки или утечки в них могут уронить весь сервер;\n- обновление модулей требует аккуратного тестирования и контроля версии Redis;\n- не все хостинги и облачные сервисы позволяют загружать кастомные модули.\n\nПрактические рекомендации:\n\n- использовать только зрелые и поддерживаемые модули в продакшене;\n- проверять совместимость версии Redis и модуля;\n- отделять инстансы с модулями от тех, где нужен «чистый» Redis под кэш и быстрые ключи.\n\n## Итог\n\n**Модули Redis** позволяют расширять сервер новыми типами данных и командами, не меняя сам Redis и не переписывая приложение на низком уровне.\n\nЕсли аккуратно выбирать модули и отделять экспериментальные вещи от критичных инстансов, можно сильно обогатить возможности Redis, сохраняя при этом его скорость и простоту работы.\n\n\n"
    },
    {
      "title": "RedisJSON, RedisSearch, RedisGraph",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "advanced",
      "sectionTitle": "Продвинутые темы",
      "sectionOrder": 12,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "advanced",
        "slug": "04-redisjson-search-graph",
        "lang": "ru"
      },
      "path": "/content/materials/redis/advanced/04-redisjson-search-graph.ru.md",
      "content": "\nОтдельные модули **RedisJSON**, **RedisSearch** и **RedisGraph** превращают Redis в гораздо более универсальный инструмент: можно хранить и индексировать JSON‑документы, делать полнотекстовый поиск и строить графовые модели прямо поверх Redis.\n\nИх объединяет общий принцип: сложные структуры и запросы живут ближе к памяти, а приложение общается с ними через знакомый протокол Redis.\n\n## RedisJSON — работа с JSON-объектами\n\n**RedisJSON** добавляет полноценное хранение JSON‑документов с возможностью изменять отдельные поля без перезаписи всей строки.\n\nПример записи профиля пользователя:\n\n```\nJSON.SET user:42 $ '{\"name\":\"Alice\",\"age\":30,\"tags\":[\"dev\",\"redis\"]}'\n```\n\nЧтение всего объекта:\n\n```\nJSON.GET user:42\n```\n\nИзменение одного поля:\n\n```\nJSON.SET user:42 $.age 31\n```\n\nПолучение только нужного фрагмента:\n\n```\nJSON.GET user:42 $.tags\n```\n\nТакой подход удобен, когда:\n\n- данные естественно выглядят как JSON;\n- часто нужно менять отдельные поля;\n- важно не гонять лишние байты между приложением и Redis.\n\n## RedisSearch — индексы и поиск\n\n**RedisSearch** (часто под именем RediSearch) добавляет полнотекстовый поиск, индексы и сложные запросы по данным в Redis.\n\nПример создания индекса по JSON‑документам профилей:\n\n```\nFT.CREATE idx:users ON JSON PREFIX 1 user: SCHEMA $.name AS name TEXT $.age AS age NUMERIC\n```\n\nДобавление данных уже рассмотрено в RedisJSON. Теперь можно искать:\n\n```\nFT.SEARCH idx:users \"@name:Alice\"\nFT.SEARCH idx:users \"@age:[25 35]\"\n```\n\nRedisSearch сам ведёт индекс и позволяет:\n\n- делать фильтрацию по полям;\n- добавлять сортировку и пагинацию;\n- строить сложные запросы над данными, уже лежащими в Redis.\n\nЭто удобно, когда нужно быстрый поиск по профилям, товарам или логам без отдельной поисковой системы.\n\n## RedisGraph — графовые данные\n\n**RedisGraph** добавляет графовую модель: вершины, рёбра и запросы в стиле Cypher.\n\nПример создания простого графа:\n\n```\nGRAPH.QUERY social \"\n  CREATE (:User {id: 1, name: 'Alice'})-[:FOLLOWS]->(:User {id: 2, name: 'Bob'})\n\"\n```\n\nЗапрос друзей:\n\n```\nGRAPH.QUERY social \"\n  MATCH (u:User {id: 1})-[:FOLLOWS]->(f:User)\n  RETURN f.name\n\"\n```\n\nТакой подход подходит для:\n\n- социальных графов;\n- рекомендательных систем;\n- задач, где важны связи и пути между сущностями.\n\n## Итог\n\nМодули **RedisJSON**, **RedisSearch** и **RedisGraph** расширяют Redis за пределы классического «ключ–значение»: позволяют работать с JSON‑документами, делать быстрый поиск и строить графовые запросы прямо в памяти.\n\nЕсли проекту нужны такие возможности, а Redis уже используется как базовая инфраструктура, эти модули позволяют обойтись без отдельных специализированных систем, сохранив при этом высокую скорость.\n\n\n"
    },
    {
      "title": "Базовые паттерны работы клиента с Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "clients",
      "sectionTitle": "Клиенты и работа из приложений",
      "sectionOrder": 13,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "clients",
        "slug": "01-client-patterns",
        "lang": "ru"
      },
      "path": "/content/materials/redis/clients/01-client-patterns.ru.md",
      "content": "\nRedis сам по себе всего лишь сервер, который принимает команды. В реальных приложениях к нему всегда ходит клиентская библиотека: для Node.js, Python, Go, Java и так далее. От того, как выстроена эта обвязка, часто зависит не меньше, чем от конфигурации самого Redis.\n\nРазберём базовые паттерны, которые полезно закладывать в любой код, работающий с Redis.\n\n## Долгоживущие подключения вместо «подключиться–сделать–закрыть»\n\nRedis хорошо работает с постоянными TCP‑соединениями. Открывать и закрывать сокет на каждый запрос — лишняя нагрузка и лишние задержки.\n\nТипичная ошибка:\n\n1. Подключиться к Redis.\n2. Выполнить одну команду.\n3. Закрыть подключение.\n\nЛучше:\n\n- создать клиент один раз при старте приложения;\n- переиспользовать подключение для всех запросов;\n- закрывать соединение только при остановке сервиса.\n\nВ большинстве библиотек это выглядит как создание одного экземпляра клиента и его шаринг по всему приложению.\n\n## Локальный слой обёрток над Redis\n\nВместо того чтобы разбрасывать по коду сырые команды, полезно завести тонкий сервис, который:\n\n- знает схему ключей;\n- инкапсулирует логику кэша и TTL;\n- прячет детали клиента.\n\nПримеры логических методов:\n\n- сохранить сессию пользователя;\n- получить кэш страницы;\n- увеличить счётчик метрики.\n\nТакая обёртка помогает:\n\n- менять схему ключей без переписывания всего приложения;\n- централизованно настраивать время жизни, сериализацию и обработку ошибок;\n- упростить тестирование, подменяя реализацию на фейковую.\n\n## Явная схема ключей в одном месте\n\nСхема ключей Redis часто растёт стихийно. Лучше сразу описать её явно в одном модуле.\n\nПримеры шаблонов:\n\n- **user:ID** для данных пользователя;\n- **session:token:...** для сессий;\n- **cache:...** для кэша;\n- **metrics:...** для метрик.\n\nВ коде приложения удобно иметь функции‑генераторы:\n\n```\nuserKey(42)          -> \"user:42\"\nsessionTokenKey(t)   -> \"session:token:abcd\"\ncacheArticleKey(10)  -> \"cache:article:10\"\n```\n\nТак меньше риск опечаток, а миграция схемы ключей сводится к изменению этих функций.\n\n## Баланс ответственности между Redis и БД\n\nRedis часто используется вместе с основной базой данных. Важно чётко понимать, за что отвечает каждый слой.\n\nТипичный паттерн:\n\n- основная БД — источник правды (постоянные данные, транзакции, сложные запросы);\n- Redis — быстрый кэш, счётчики, очереди, временные структуры.\n\nПоследствия:\n\n- при ошибке Redis приложение по возможности должно уметь обратиться к БД напрямую;\n- логика согласованности данных должна быть в приложении, а не в надежде «Redis сам разберётся».\n\n## Итог\n\nБазовый уровень работы с Redis в приложении — это один или несколько долгоживущих клиентов, тонкий слой обёртки вокруг команд и явная схема ключей в одном месте.\n\nЕсли сразу разделить ответственность между Redis и основной БД и не пускать сырые команды по всему коду, дальнейшая эволюция и отладка приложения становятся намного проще.\n\n\n"
    },
    {
      "title": "Подключения, пулы и таймауты",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "clients",
      "sectionTitle": "Клиенты и работа из приложений",
      "sectionOrder": 13,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "clients",
        "slug": "02-connections-pools-timeouts",
        "lang": "ru"
      },
      "path": "/content/materials/redis/clients/02-connections-pools-timeouts.ru.md",
      "content": "\nПодключение к Redis — дешёвая операция по сравнению с классическими базами, но даже его можно использовать неправильно. Чрезмерное количество соединений, отсутствие таймаутов и большие очереди запросов легко превращают быстрый Redis в узкое место.\n\nРазберём практичные настройки подключений, пулов и таймаутов, которые стоит закладывать по умолчанию.\n\n## Сколько соединений нужно приложению\n\nВ простом сервисе часто достаточно одного подключения на процесс или на инстанс приложения. При высокой конкуренции и блокирующих командах может понадобиться несколько соединений или пул.\n\nОриентиры:\n\n- небольшое веб‑приложение — один клиент на процесс;\n- высоконагруженный сервис — пул из нескольких соединений;\n- фоновые воркеры — отдельное подключение для каждого воркера или батча задач.\n\nВажно не плодить тысячи соединений без нужды: Redis хорошо работает с сотнями клиентов, но чрезмерное количество TCP‑сессий увеличивает накладные расходы и сложнее диагностируется.\n\n## Пулы соединений\n\nПул — это набор заранее открытых соединений, которые приложение переиспользует между запросами.\n\nПреимущества:\n\n- нет задержек на установку TCP‑сессии;\n- можно ограничить максимальное число параллельных запросов;\n- проще контролировать нагрузку на Redis.\n\nПрактические рекомендации:\n\n- задавать разумный минимум и максимум соединений в пуле;\n- следить за метриками: сколько времени запрос ждёт свободное соединение;\n- не забывать корректно закрывать пул при остановке приложения.\n\nЕсли библиотека по умолчанию открывает новые подключения без ограничений, лучше явно включить режим пула.\n\n## Таймауты подключений и команд\n\nРабота без таймаутов — прямой путь к «висящим» запросам и забитым потокам приложения.\n\nНужны два вида таймаутов:\n\n- на установку соединения;\n- на выполнение команды.\n\nОриентировочные значения:\n\n- connect timeout — десятки или сотни миллисекунд для внутренней сети;\n- command timeout — от нескольких миллисекунд до пары секунд, в зависимости от операции.\n\nПри превышении таймаута:\n\n- запрос должен завершаться ошибкой;\n- приложение должно уметь решить, повторять ли его или деградировать.\n\n## Ограничение очередей и защита от перегрузки\n\nЕсли приложение генерирует запросы быстрее, чем Redis успевает их обрабатывать, соединения и пулы начинают накапливать очереди команд.\n\nПризнаки:\n\n- растущее время ответа при неизменной нагрузке;\n- длинные очереди в клиентской библиотеке;\n- повышенный instantaneous_ops_per_sec и задержки.\n\nПрактичные меры:\n\n- ограничить размер очереди запросов на клиента;\n- при переполнении — возвращать ошибку вверх по стеку;\n- включить backpressure: замедлять источники нагрузки или временно отказывать.\n\nЛучше честно вернуть пользователю ошибку, чем позволить сервису повиснуть из‑за бесконтрольной очереди к Redis.\n\n## Итог\n\nГрамотная работа с подключениями к **Redis** — это небольшое число долгоживущих соединений, аккуратный пул, чёткие таймауты и ограничения на очереди запросов.\n\nЕсли настроить это один раз в клиентской обёртке, большинство проблем с «зависшими» запросами и неожиданными перегрузками Redis исчезнут ещё до того, как попадут в продакшен.\n\n\n"
    },
    {
      "title": "Ошибки, ретраи и деградация при сбоях Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "clients",
      "sectionTitle": "Клиенты и работа из приложений",
      "sectionOrder": 13,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "clients",
        "slug": "03-errors-retries-degradation",
        "lang": "ru"
      },
      "path": "/content/materials/redis/clients/03-errors-retries-degradation.ru.md",
      "content": "\nRedis обычно работает стабильно, но сеть, диски и люди иногда ломаются. Важно заранее решить, что делает приложение, если Redis внезапно недоступен: бесконечно ретраит, сразу падает с ошибкой или аккуратно деградирует.\n\nГрамотная обработка ошибок часто важнее, чем сама конфигурация Redis.\n\n## Какие ошибки бывают на стороне клиента\n\nЧаще всего встречаются:\n\n- ошибка подключения (сервер недоступен, таймаут при connect);\n- таймаут команды (сервер не ответил за отведённое время);\n- протокольные ошибки (редко, обычно при баге в клиенте или модуле);\n- логические ошибки Redis (например, операция над неправильным типом ключа).\n\nПриложение должно:\n\n- различать сетевые/инфраструктурные проблемы и ошибки логики;\n- логировать и метриковать оба типа по‑разному;\n- не глушить исключения молча.\n\n## Когда стоит делать ретраи\n\nРетраи уместны для кратковременных сбоев сети и перегрузки, но легко превратить их в «шторм», когда каждый сервис ещё сильнее давит на Redis.\n\nПрактичные правила:\n\n- ретраить только операции, которые безопасны при повторе (идемпотентные);\n- ставить ограничение по числу попыток (2–3, а не бесконечно);\n- использовать экспоненциальную паузу между попытками.\n\nНапример, для чтения кэша:\n\n- одна повторная попытка через короткую задержку;\n- при повторной неудаче — пропускаем кэш и идём в основное хранилище либо возвращаем упрощённый ответ.\n\nДля записи логов и метрик иногда проще не ретраить вовсе, чтобы не создавать дополнительную нагрузку.\n\n## Деградация: когда Redis не критичен\n\nВо многих системах Redis используется как кэш или вспомогательное хранилище. В таких случаях важнее, чтобы пользователь получил хоть какой‑то ответ, чем чтобы кэш отработал идеально.\n\nПримеры деградации:\n\n- при ошибке чтения кэша страницы — собрать ответ без кэша, пусть медленнее;\n- при недоступности Redis для логов — временно писать меньше метрик;\n- при падении кэша рекомендаций — показать дефолтный список или ничего не показывать.\n\nХорошо, когда в коде есть явное разделение:\n\n- операции, без которых сервис не может работать;\n- операции, которые можно пропустить или упростить при сбое Redis.\n\n## Когда лучше сразу падать с ошибкой\n\nЕсли Redis — часть критичной бизнес‑логики (например, хранит заказы или сессии авторизации в единственном экземпляре), попытка «как‑нибудь продолжить» может только усугубить ситуацию.\n\nВ таких случаях:\n\n- лучше быстро и явно вернуть пользователю ошибку;\n- сработает алертинг, команда поймёт масштаб проблемы;\n- не появится скрытых несогласованных состояний.\n\nВажно заранее задокументировать, какие операции относятся к этой категории, и не пытаться чинить их ретраями без изменения архитектуры.\n\n## Итог\n\nОбработка ошибок при работе с **Redis** — это выбор между ретраями, деградацией и явным отказом, в зависимости от того, насколько критична операция.\n\nЕсли отделить сетевые сбои от логических ошибок, ретраить только безопасные вызовы и честно признавать фатальные ситуации, приложение станет предсказуемым и устойчивым даже при временных проблемах с Redis.\n\n\n"
    },
    {
      "title": "Идемпотентность и безопасные операции при повторах",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "clients",
      "sectionTitle": "Клиенты и работа из приложений",
      "sectionOrder": 13,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "clients",
        "slug": "04-idempotency-and-safety",
        "lang": "ru"
      },
      "path": "/content/materials/redis/clients/04-idempotency-and-safety.ru.md",
      "content": "\nКогда появляются ретраи, сетевые сбои и сложная логика, легко дважды выполнить одну и ту же операцию. Если команда не идемпотентна, это приводит к удвоенным списаниям, дубликатам задач или странным состояниям в очередях.\n\nИдемпотентность — это свойство операции давать тот же результат при повторном выполнении. В связке с Redis это можно и нужно использовать осознанно.\n\n## Простейшие идемпотентные операции\n\nМногие команды Redis по сути уже идемпотентны:\n\n- SET с одним и тем же значением для ключа;\n- EXPIRE и PEXPIRE с одинаковым временем;\n- записи, где значение полностью определено содержимым команды.\n\nПример:\n\n```\nSET user:42:name \"Alice\"\nSET user:42:name \"Alice\"\n```\n\nПовтор второй команды не меняет состояние. Если операция реализована именно как установка значения, а не как сложная последовательность шагов, ретраи становятся безопаснее.\n\n## Использование SETNX и атомарных операций\n\nДля сценариев «сделать что‑то один раз» помогают команды **SETNX** и атомарные инкременты.\n\nПример: один раз выполнить инициализацию для пользователя.\n\n```\nSETNX user:42:initialized 1\n```\n\nЕсли ключ уже существует, команда вернёт 0, и повторный вызов не изменит состояние. Аналогично, атомарные операции вроде INCR и HINCRBY гарантируют корректный результат даже при параллельных вызовах.\n\n## Идемпотентность на уровне бизнес‑идентификаторов\n\nЧасто удобнее считать идемпотентной не отдельную команду Redis, а всю бизнес‑операцию с собственным идентификатором.\n\nПример: обработка платежа с идентификатором операции.\n\nШаги:\n\n1. До начала логики проверить, обрабатывался ли уже этот **payment_id**.\n2. Если да — просто вернуть сохранённый результат.\n3. Если нет — выполнить бизнес‑логику и пометить операцию как завершённую.\n\nХранение статуса:\n\n```\nSETNX payment:op:12345 \"processed\"\n```\n\nЕсли SETNX вернул 1, мы считаем, что именно этот инстанс сервиса «выиграл гонку» и будет обрабатывать операцию. Остальные при повторе увидят, что статус уже есть.\n\n## Lua-скрипты для сложных идемпотентных операций\n\nКогда нужно сделать несколько шагов атомарно и при этом сохранить идемпотентность, выручает Lua.\n\nИдея:\n\n- перед выполнением основной логики проверить специальный ключ с идентификатором операции;\n- если ключ уже существует — вернуть сохранённый результат или код;\n- если нет — выполнить логику и записать маркер выполнения.\n\nПростейший шаблон:\n\n```\nEVAL \"\n  local status = redis.call('GET', KEYS[1])\n  if status then\n    return status\n  end\n  redis.call('SET', KEYS[1], ARGV[1])\n  return ARGV[1]\n\" 1 op:12345 \"done\"\n```\n\nОдин и тот же скрипт можно безопасно вызывать несколько раз — результат будет предсказуемым.\n\n## Итог\n\nИдемпотентность в связке с **Redis** достигается за счёт простых и атомарных команд, аккуратного использования SETNX и INCR, а при необходимости — Lua‑скриптов, которые проверяют и помечают выполнение операций.\n\nЕсли проектировать ключи и операции так, чтобы повторный вызов не ломал данные, можно смело использовать ретраи и не бояться случайных дубликатов и двойных списаний.\n\n\n"
    },
    {
      "title": "Структуры данных в Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "data",
      "sectionTitle": "Структуры данных",
      "sectionOrder": 2,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "data",
        "slug": "01-data-structures",
        "lang": "ru"
      },
      "path": "/content/materials/redis/data/01-data-structures.ru.md",
      "content": "\n**Redis** — это не просто хранилище строк. Его особенность в том, что данные могут быть представлены разными структурами, и каждая из них подходит под определённые задачи. В отличие от обычной базы данных, где обычно работают с таблицами и строками, здесь используются более простые и быстрые модели: списки, наборы, хеши, упорядоченные коллекции и потоки. Благодаря этому многие задачи решаются естественно и без сложных запросов.\n\n![Структуры данных Redis](images/structures.jpg)\n\n## Строки\n\n**Строка** — самая базовая форма данных. Это просто значение, связанное с ключом. Внутри строки может лежать что угодно: текст, число, JSON в виде текста. Такой тип чаще всего используют там, где нужно хранить простые значения — например, токен, число, небольшую структуру или результат вычисления.\n\n**Пример данных:**  \n\"hello world\"\n\n**Пример команды:**  \n```\nSET message \"hello world\"\n```\n\n**Когда использовать:**  \nКогда нужно хранить простое значение: текст, число, флаг, токен, JSON в виде строки.\n\n## Хеши\n\n**Хеш** похож на маленький объект или словарь. У одного ключа Redis может быть несколько полей, у каждого — своё значение. Это удобный вариант, когда нужно хранить сущность с несколькими свойствами: профиль пользователя, настройки, краткую информацию о товаре. Хеши позволяют получать или менять отдельные поля без перезаписи всей структуры.\n\n**Пример данных:**  \n{a: \"hello\", b: \"world\"}\n\n**Пример команды:**  \n```\nHSET user name \"Alice\" age 25\n```\n\n**Когда использовать:**  \nКогда требуется небольшая сущность с несколькими полями, обновляемыми отдельно.\n\n## Списки\n\n**Списки** ведут себя как обычная очередь или стек. В начало и конец можно быстро добавлять элементы, извлекать их, просматривать нужные участки. Это хорошее решение для задач, где важен порядок: хранение последних действий пользователя, формирование очередей задач, временные журналы событий.\n\n**Пример данных:**  \n[A > B > C]\n\n**Пример команды:**  \n```\nLPUSH logs \"event1\"\n```\n\n**Когда использовать:**  \nКогда важен порядок: очереди задач, последние записи, журналы действий.\n\n## Множества\n\n**Множество** — коллекция уникальных значений. Здесь нельзя хранить дубликаты, и порядок элементов не важен. Такой тип помогает решать задачи вроде хранения уникальных ID, отслеживания пользователей, которые выполнили действие, или быстрого определения, находится ли элемент в наборе.\n\n**Пример данных:**  \n{A, B, C}\n\n**Пример команды:**  \n```\nSADD online_users \"user1\"\n```\n\n**Когда использовать:**  \nКогда нужен набор уникальных значений без повторов.\n\n## Упорядоченные множества\n\n**Упорядоченные множества** отличаются от обычных тем, что каждый элемент имеет числовой «вес», по которому Redis сортирует коллекцию. Этот тип хорошо подходит для рейтингов, лидбордов, статистики, где важно быстро узнать позиции элементов или взять часть списка по определённому диапазону.\n\n**Пример данных:**  \n{A:1, B:2, C:3}\n\n**Пример команды:**  \n```\nZADD rating 100 \"player1\"\n```\n\n**Когда использовать:**  \nКогда нужен рейтинг, сортировка или выборка по диапазону числовых значений.\n\n## Bitmaps\n\n**Bitmaps** позволяют хранить и изменять данные на уровне отдельных битов. Это даёт возможность создавать компактные структуры для отметок присутствия/отсутствия. Часто используется в аналитике, когда нужно отслеживать активность пользователей по дням или отмечать события в большом массиве данных без большого расхода памяти.\n\n**Пример данных:**  \n01101101 01101111 01101101\n\n**Пример команды:**  \n```\nSETBIT days 5 1\n```\n\n**Когда использовать:**  \nКогда нужно отмечать состояния по битам: активности по дням, флаги, быстрые отметки.\n\n## HyperLogLog\n\n**HyperLogLog** — структура для приближённого подсчёта количества уникальных значений. Она не хранит сами элементы, зато позволяет оценить, сколько уникальных записей прошло через систему. Подходит для огромных массивов данных, где точность важна меньше, чем компактность и скорость (например, количество уникальных посетителей).\n\n**Пример данных:**  \n010110101 011011111 01101101\n\n**Пример команды:**  \n```\nPFADD visitors \"user123\"\n```\n\n**Когда использовать:**  \nКогда требуется приблизительно посчитать количество уникальных значений в большом потоке данных.\n\n## Streams\n\n**Streams** — структура для обработки последовательных событий. Каждый элемент имеет автоинкрементный идентификатор и набор полей. Это природный способ создавать очереди событий, собирать логи, обмениваться сообщениями между сервисами. В отличие от списков, потоки умеют работать с группами потребителей и гарантируют доставку данных тем, кто их обрабатывает.\n\n**Пример данных:**  \n{id1 = time.seq { a: \"foo\", b: \"bar\" }}\n\n**Пример команды:**  \n```\nXADD mystream * message \"hello\"\n```\n\n**Когда использовать:**  \nКогда нужно работать с последовательными событиями, логами или очередями с группами потребителей.\n\n## Зачем столько типов?\n\n**Каждая структура** существует не ради разнообразия, а чтобы решать конкретные задачи максимально быстро. Где-то важен порядок, где-то уникальность, где-то возможность работать с огромными потоками данных без потери производительности. Понимание различий помогает выбирать правильный инструмент и строить более эффективные решения.\n\n**Redis выигрывает именно за счёт того, что позволяет использовать разные структуры там, где они логичнее и быстрее всего.**\n"
    },
    {
      "title": "Основные операции",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "data",
      "sectionTitle": "Структуры данных",
      "sectionOrder": 2,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "data",
        "slug": "02-basic-operations",
        "lang": "ru"
      },
      "path": "/content/materials/redis/data/02-basic-operations.ru.md",
      "content": "\n**Основные операции** в Redis сводятся к простым и быстрым действиям над ключами и значениями. Большинство команд работает мгновенно, потому что сервер обрабатывает данные в оперативной памяти. Ниже — самые важные операции, которые используются практически в любом проекте.\n\n## Установка и получение значений\n\n```\nSET message \"hello\"\nGET message\n```\n\nКоманда **SET** создаёт или обновляет значение по ключу, а **GET** возвращает его. Это самый распространённый способ работы со строками.\n\n## Проверка существования ключа\n\n```\nEXISTS message\n```\n\nКоманда **EXISTS** возвращает 1, если ключ существует, и 0, если нет.\n\n## Удаление данных\n\n```\nDEL message\n```\n\nКоманда **DEL** удаляет ключ и его значение.\n\n## Инкремент и декремент\n\nЕсли значение является числом, его можно увеличивать и уменьшать:\n\n```\nINCR counter\nDECR counter\n```\n\nКоманды **INCR** и **DECR** особенно удобны для счётчиков кликов, лайков и просмотров.\n\n## Работа со списками\n\n```\nLPUSH logs \"event1\"\nRPUSH logs \"event2\"\nLPOP logs\nRPOP logs\n```\n\nДобавление через **LPUSH** и **RPUSH** происходит слева или справа, и извлечение через **LPOP** и **RPOP** — тоже. Со списками часто строят очереди.\n\n## Работа с множествами\n\n```\nSADD users \"alice\"\nSADD users \"bob\"\nSMEMBERS users\n```\n\nМножество хранит только уникальные значения, и команда **SMEMBERS** возвращает весь набор.\n\n## Работа с хешами\n\n```\nHSET user name \"Alice\"\nHSET user age 25\nHGET user name\n```\n\nХеши удобно использовать для сущностей с несколькими полями, которые удобно заполнять через **HSET** и читать через **HGET**.\n\n## Упорядоченные множества\n\n```\nZADD rating 100 \"player1\"\nZADD rating 150 \"player2\"\nZRANGE rating 0 -1 WITHSCORES\n```\n\nКоманда **ZADD** добавляет элементы с «весом», а **ZRANGE** помогает их читать в нужном порядке. Подходит для рейтингов и систем, где важна сортировка по числовому значению.\n\n## Работа с потоками\n\n```\nXADD mystream * message \"hello\"\nXREAD COUNT 1 STREAMS mystream 0\n```\n\nПотоки через **XADD** и **XREAD** используются для событий, логов и очередей с высокой нагрузкой.\n\n**Эти команды — фундамент работы с Redis.** Освоив их, можно уверенно двигаться дальше и использовать более сложные механизмы и структуры.\n"
    },
    {
      "title": "TTL и управление временем жизни ключей",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "data",
      "sectionTitle": "Структуры данных",
      "sectionOrder": 2,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "data",
        "slug": "03-ttl-and-key-expiration",
        "lang": "ru"
      },
      "path": "/content/materials/redis/data/03-ttl-and-key-expiration.ru.md",
      "content": "\n**TTL** позволяет сделать ключи «временными». По умолчанию данные в Redis живут вечно, пока их явно не удалить. Время жизни ключа задаётся отдельно и измеряется в секундах или миллисекундах.\n\n## Основная идея\n\nМожно записать значение, дать ему срок жизни и не думать о ручной очистке. После истечения срока Redis удалит ключ сам. Это удобно для кэша, сессий, одноразовых кодов и временных флагов.\n\n**Простейший пример:**\n\n```\nSET session:123 \"user data\"\nEXPIRE session:123 60\n```\n\nКлюч session:123 будет жить 60 секунд, потом исчезнет.\n\n**Проверка оставшегося времени:**\n\n```\nTTL session:123\n```\n\nЕсли ключ ещё жив, возвращается число секунд. Возможны специальные значения:\n- **-1** — у ключа нет срока жизни;\n- **-2** — ключ уже не существует.\n\n## Запись сразу с временем жизни\n\nМожно не вызывать EXPIRE отдельно, а задать срок прямо при записи.\n\n**SETEX — запись сразу с временем жизни (в секундах):**\n\n```\nSETEX cache:user:1 300 \"{\\\"name\\\":\\\"Alice\\\"}\"\n```\n\nКлюч cache:user:1 будет автоматически удалён через 300 секунд.\n\n**PSETEX — вариант с миллисекундами:**\n\n```\nPSETEX cache:page:1 1500 \"html...\"\n```\n\n## Снятие срока жизни\n\n**PERSIST — сделать ключ снова постоянным:**\n\n```\nPERSIST session:123\n```\n\nПосле этого у ключа больше нет таймера удаления.\n\nВажно помнить: если перезаписать значение, TTL сбрасывается. Новое значение будет без срока жизни, пока его не задать заново.\n\n## Поведение при истечении\n\nRedis не удаляет ключи строго в ту же миллисекунду, когда истечёт время. Он периодически проверяет истекающие ключи и дополнительно удаляет их при обращении. Для приложения это выглядит так, будто ключ просто перестал существовать:\n\n```\nGET session:123     # до истечения\n# \"user data\"\n\n# проходит время\n\nGET session:123     # после истечения\n# (nil)\n```\n\n## Практические случаи\n\n**Кэш.** Хранить результат тяжёлого запроса несколько секунд или минут.\n\n```\nSETEX cache:popular:posts 60 \"...\"\n```\n\n**Сессии.** Хранить данные пользователя, пока он активен.\n\n```\nSET session:456 \"data\"\nEXPIRE session:456 1800\n```\n\n**Одноразовые коды и токены.** Срок действия задаётся сразу и не требует ручной очистки.\n\nГрамотная работа с TTL помогает не захламлять память Redis и автоматически удалять ненужные данные.\n\n## Итого по TTL и командам\n\nTTL делает ключи временными и позволяет не заниматься ручной очисткой. У каждого ключа может быть свой срок жизни: его можно задать при записи, изменить, снять или проверить.\n\nКоманды, которые важно знать:\n\n- **EXPIRE key seconds** — установить время жизни в секундах.\n- **PEXPIRE key milliseconds** — то же самое, но в миллисекундах.\n- **EXPIREAT key timestamp** — истечение по Unix-времени в секундах.\n- **PEXPIREAT key milliseconds-timestamp** — истечение по Unix-времени в миллисекундах.\n- **TTL key** — показать оставшееся время жизни в секундах.\n- **PTTL key** — показать оставшееся время жизни в миллисекундах.\n- **SETEX key seconds value** — записать значение и сразу задать срок жизни.\n- **PSETEX key milliseconds value** — вариант с миллисекундами.\n- **PERSIST key** — убрать время жизни и сделать ключ постоянным.\n\nПонимая, как работают эти команды, можно строить кэш, сессии, временные токены и любые другие механизмы, которые должны исчезать сами через заданный промежуток времени.\n"
    },
    {
      "title": "Работа с ключами и пространством имен",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "data",
      "sectionTitle": "Структуры данных",
      "sectionOrder": 2,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "data",
        "slug": "04-keys-and-namespaces",
        "lang": "ru"
      },
      "path": "/content/materials/redis/data/04-keys-and-namespaces.ru.md",
      "content": "\nРабота с ключами в Redis важна не меньше, чем выбор структуры данных. От того, как называются ключи, зависит удобство отладки, простота поиска и риск случайно удалить или перезаписать чужие данные.\n\n## Что такое ключ в Redis\n\nКлюч в Redis — это строка, по которой сервер находит значение. В одном экземпляре Redis все ключи лежат в общем пространстве. Никаких таблиц или схем, как в классических базах, здесь нет.\n\nПростейший пример записи значения по ключу:\n\n```\nSET user:1 \"Alice\"\nGET user:1\n```\n\nКлючи могут быть любыми строками, но на практике используют понятные имена, которые отражают назначение данных.\n\n## Пространства имён через разделитель\n\nТак как формальных схем нет, пространство имён организуют самим названием ключа. Часто используют двоеточие как разделитель.\n\nПример ключей для пользователей:\n\n```\nSET user:1:name \"Alice\"\nSET user:1:email \"alice@example.com\"\nSET user:2:name \"Bob\"\n```\n\nЗдесь user — логическая группа, число после двоеточия — идентификатор, а последнее слово — поле или тип данных.\n\nЕщё один пример для сессий и кэша:\n\n```\nSET session:token:abc123 \"user:1\"\nSET cache:article:42 \"html...\"\n```\n\nТакой подход помогает:\n\n**Визуально группировать данные.** По ключу сразу видно, к чему относится запись.\n\n**Избегать конфликтов.** Ключи разных подсистем не пересекаются: session:..., cache:..., user:....\n\n**Удобно искать и чистить.** Можно выбрать группу ключей по шаблону.\n\n## Поиск и обход ключей\n\nДля поиска ключей по шаблону есть несколько команд. В учебных примерах часто используют KEYS, но в реальных проектах её лучше избегать: она может блокировать сервер, если ключей много.\n\nПример KEYS для понимания работы шаблонов:\n\n```\nKEYS user:*\n```\n\nБолее безопасный вариант для продакшена — команда SCAN. Она обходит ключи постепенно и не блокирует сервер.\n\nПример выборки сессий по шаблону:\n\n```\nSCAN 0 MATCH session:* COUNT 100\n```\n\nКлиент вызывает SCAN несколько раз, пока не обойдёт все подходящие ключи.\n\n## Тип ключа и удаление\n\nИногда важно понять, какое значение лежит по ключу. Для этого есть команда TYPE.\n\n```\nTYPE user:1\n```\n\nОтвет покажет тип: string, hash, list, set и так далее.\n\nУдалить ключ можно простой командой:\n\n```\nDEL user:1\n```\n\nЕсли ключ крупный и его много, иногда используют UNLINK. Эта команда помечает данные на удаление и возвращается быстрее, чем DEL.\n\n```\nUNLINK big:list\n```\n\nКакую бы команду ни использовать, важно аккуратно выбирать ключи. Ошибка в шаблоне или названии может удалить лишние данные.\n\n## Практические схемы именования\n\nНесколько типичных вариантов, которые хорошо приживаются в проектах.\n\nПользователи:\n\n```\nuser:42\nuser:42:name\nuser:42:settings\n```\n\nСессии и авторизация:\n\n```\nsession:token:abc123\nsession:user:42\n```\n\nКэш:\n\n```\ncache:article:10\ncache:profile:42\n```\n\nСчётчики и метрики:\n\n```\nmetrics:views:article:10\nmetrics:logins:2025-11-20\n```\n\nГлавная идея простая: один логический блок — один префикс. Так ключи остаются читаемыми, их легко искать и удалять по шаблону, а риск конфликтов между разными частями системы заметно снижается.\n"
    },
    {
      "title": "Геопространственные данные",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "data",
      "sectionTitle": "Структуры данных",
      "sectionOrder": 2,
      "order": 5,
      "id": {
        "category": "redis",
        "section": "data",
        "slug": "05-geospatial-data",
        "lang": "ru"
      },
      "path": "/content/materials/redis/data/05-geospatial-data.ru.md",
      "content": "\n**Redis** умеет работать с географическими координатами и быстро находить объекты в радиусе от заданной точки, вычислять расстояния между точками и строить простые гео‑запросы. Внутри это реализовано через упорядоченные множества, но команды **GEO*** упрощают работу с координатами.\n\nГеопространственные данные полезны для поиска ближайших ресторанов, расчёта расстояний доставки, отображения объектов на карте и других задач, где важны координаты.\n\n## Добавление точек на карту\n\nКоманда **GEOADD** добавляет точку с координатами в структуру. Координаты задаются как долгота и широта.\n\nПример добавления нескольких точек:\n\n```\nGEOADD restaurants 37.6173 55.7558 \"Cafe Pushkin\"\nGEOADD restaurants 37.6231 55.7520 \"Teremok\"\nGEOADD restaurants 37.6098 55.7525 \"Starbucks\"\n```\n\nЗдесь:\n\n- **restaurants** — имя ключа, где хранятся точки;\n- первое число — долгота (longitude);\n- второе число — широта (latitude);\n- последний аргумент — название или идентификатор точки.\n\nМожно добавить несколько точек за один вызов:\n\n```\nGEOADD restaurants 37.6173 55.7558 \"Cafe Pushkin\" 37.6231 55.7520 \"Teremok\"\n```\n\n## Поиск точек в радиусе\n\nКоманда **GEORADIUS** находит все точки в заданном радиусе от центральной координаты.\n\nПример поиска ресторанов в радиусе 1 километра:\n\n```\nGEORADIUS restaurants 37.6200 55.7550 1 km\n```\n\nЗдесь:\n\n- **37.6200 55.7550** — координаты центра;\n- **1 km** — радиус поиска (можно указать в метрах: **1000 m**).\n\nКоманда вернёт список названий точек, которые попадают в радиус.\n\nЧтобы получить не только названия, но и расстояния до них:\n\n```\nGEORADIUS restaurants 37.6200 55.7550 1 km WITHDIST\n```\n\nОпция **WITHCOORD** вернёт координаты найденных точек:\n\n```\nGEORADIUS restaurants 37.6200 55.7550 1 km WITHCOORD\n```\n\nМожно комбинировать опции:\n\n```\nGEORADIUS restaurants 37.6200 55.7550 1 km WITHDIST WITHCOORD\n```\n\n## Поиск по расстоянию от существующей точки\n\nЕсли нужно найти точки в радиусе от уже известной точки, используют **GEORADIUSBYMEMBER**.\n\nПример: найти все рестораны в радиусе 500 метров от **Cafe Pushkin**:\n\n```\nGEORADIUSBYMEMBER restaurants \"Cafe Pushkin\" 500 m\n```\n\nЭто удобно, когда центральная точка уже есть в структуре и не нужно указывать координаты вручную.\n\n## Вычисление расстояния между точками\n\nКоманда **GEODIST** вычисляет расстояние между двумя точками.\n\nПример:\n\n```\nGEODIST restaurants \"Cafe Pushkin\" \"Teremok\" km\n```\n\nКоманда вернёт расстояние в километрах. Можно указать другие единицы: **m** (метры), **mi** (мили), **ft** (футы).\n\nЕсли одна из точек не найдена, команда вернёт пустое значение.\n\n## Получение координат точки\n\nЧтобы узнать координаты уже добавленной точки, используют **GEOPOS**.\n\nПример:\n\n```\nGEOPOS restaurants \"Cafe Pushkin\"\n```\n\nКоманда вернёт массив координат: сначала долготу, потом широту.\n\n## Хеш для хранения координат\n\nПо умолчанию **GEOADD** хранит координаты в виде геохеша (geohash), который оптимизирован для быстрого поиска. Но можно явно указать, что координаты нужно хранить как обычные значения.\n\nДля большинства задач это не нужно, но если требуется максимальная точность или специфичные запросы, можно работать с координатами напрямую через **ZADD** и геохеши.\n\n## Практические сценарии\n\n**Поиск ближайших объектов.** Приложение для доставки еды находит ближайшие рестораны к адресу клиента.\n\n```\nGEORADIUS restaurants 37.6200 55.7550 2 km WITHDIST\n```\n\n**Расчёт стоимости доставки.** По расстоянию между рестораном и клиентом вычисляется цена доставки.\n\n```\nGEODIST restaurants \"Cafe Pushkin\" \"Client Address\" km\n```\n\n**Отображение на карте.** Все точки в видимой области карты выбираются через **GEORADIUS** с нужным радиусом.\n\n**Поиск по шаблону.** Комбинируя **GEORADIUS** с фильтрацией по другим полям (например, через отдельные ключи), можно строить сложные запросы: «ближайшие рестораны с рейтингом выше 4.5».\n\n## Ограничения и особенности\n\nГеопространственные команды Redis хорошо работают для задач в пределах одного города или региона. Для глобальных запросов (поиск по всей планете) точность может снижаться из‑за особенностей проекции координат.\n\nВажно помнить:\n\n- координаты должны быть в формате WGS84 (стандартный формат GPS);\n- долгота указывается первой, широта — второй (не наоборот);\n- радиус поиска лучше ограничивать разумными значениями (не больше нескольких десятков километров для точных результатов).\n\n## Итого\n\n**Геопространственные команды Redis** позволяют быстро находить объекты по координатам, вычислять расстояния и строить простые гео‑запросы без сложных вычислений на стороне приложения.\n\nДля задач вроде поиска ближайших точек, расчёта расстояний доставки и отображения объектов на карте **GEO*** команды дают удобный и быстрый способ работы с координатами прямо в Redis.\n\n"
    },
    {
      "title": "Работа с Bitmaps",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "data",
      "sectionTitle": "Структуры данных",
      "sectionOrder": 2,
      "order": 6,
      "id": {
        "category": "redis",
        "section": "data",
        "slug": "06-bitmaps",
        "lang": "ru"
      },
      "path": "/content/materials/redis/data/06-bitmaps.ru.md",
      "content": "\n**Bitmaps** в Redis — это способ хранить и обрабатывать данные на уровне отдельных битов. Внутри это обычные строки, но команды **BIT*** позволяют работать с ними как с массивами битов. Это даёт очень компактное хранение для задач, где нужно отмечать наличие или отсутствие чего‑то: активность пользователя по дням, флаги, бинарные состояния.\n\nГлавное преимущество — экономия памяти: один бит вместо целого числа или строки. Для больших массивов данных это может дать существенную экономию.\n\n## Установка и чтение битов\n\nКоманда **SETBIT** устанавливает бит в позицию 0 или 1, а **GETBIT** читает значение бита.\n\nПример отметки активности пользователя по дням:\n\n```\nSETBIT user:42:activity 0 1\nSETBIT user:42:activity 1 1\nSETBIT user:42:activity 2 0\nSETBIT user:42:activity 3 1\n```\n\nЗдесь:\n\n- **user:42:activity** — ключ для хранения битов;\n- первое число — позиция бита (например, день недели или день месяца);\n- последнее число — значение: **1** (активен) или **0** (неактивен).\n\nПроверка активности в конкретный день:\n\n```\nGETBIT user:42:activity 3\n```\n\nКоманда вернёт **1**, если пользователь был активен, и **0**, если нет.\n\n## Подсчёт установленных битов\n\nКоманда **BITCOUNT** считает, сколько битов установлено в 1.\n\nПример:\n\n```\nBITCOUNT user:42:activity\n```\n\nЭто полезно для быстрого подсчёта: сколько дней пользователь был активен, сколько флагов установлено, сколько событий произошло.\n\nМожно считать биты в определённом диапазоне:\n\n```\nBITCOUNT user:42:activity 0 6\n```\n\nЗдесь считаются биты с позиции 0 по 6 (например, активность за неделю).\n\n## Битовая операция AND\n\nКоманда **BITOP AND** выполняет побитовое И между несколькими bitmap и сохраняет результат в новый ключ.\n\nПример поиска пользователей, активных в оба дня:\n\n```\nSETBIT user:42:activity 0 1\nSETBIT user:42:activity 1 1\nSETBIT user:100:activity 0 1\nSETBIT user:100:activity 1 0\n\nBITOP AND result user:42:activity user:100:activity\nGETBIT result 0\n```\n\nРезультат будет содержать **1** только в тех позициях, где оба исходных bitmap имели **1**.\n\nЭто удобно для поиска пересечений: какие пользователи были активны и в понедельник, и во вторник.\n\n## Битовая операция OR\n\nКоманда **BITOP OR** выполняет побитовое ИЛИ — результат содержит **1**, если хотя бы в одном из bitmap бит установлен.\n\nПример:\n\n```\nBITOP OR result user:42:activity user:100:activity\n```\n\nЭто полезно для объединения данных: активность хотя бы одного из пользователей, события из разных источников.\n\n## Битовая операция XOR\n\nКоманда **BITOP XOR** возвращает **1** только там, где биты различаются между bitmap.\n\nПример:\n\n```\nBITOP XOR result user:42:activity user:100:activity\n```\n\nЭто можно использовать для поиска различий: какие дни отличаются между двумя пользователями.\n\n## Битовая операция NOT\n\nКоманда **BITOP NOT** инвертирует все биты в bitmap.\n\nПример:\n\n```\nBITOP NOT inverted user:42:activity\n```\n\nТеперь **inverted** содержит обращённые значения: где было **1**, стало **0**, и наоборот.\n\n## Поиск первого установленного бита\n\nКоманда **BITPOS** находит позицию первого бита с заданным значением.\n\nПример поиска первого дня активности:\n\n```\nBITPOS user:42:activity 1\n```\n\nКоманда вернёт номер позиции первого установленного бита. Если нужно найти первый **0**, указывают:\n\n```\nBITPOS user:42:activity 0\n```\n\nМожно искать в определённом диапазоне:\n\n```\nBITPOS user:42:activity 1 0 6\n```\n\n## Практические сценарии\n\n**Отслеживание активности по дням.** Каждый день месяца — один бит. Если пользователь был активен, бит устанавливается в **1**.\n\n```\nSETBIT user:42:activity:2025-11 20 1\nBITCOUNT user:42:activity:2025-11\n```\n\n**Флаги и настройки.** Разные биты хранят разные флаги: уведомления включены, подписка активна, верификация пройдена.\n\n```\nSETBIT user:42:flags 0 1\nSETBIT user:42:flags 1 0\nSETBIT user:42:flags 2 1\n```\n\n**Аналитика пересечений.** Какие пользователи были активны и в понедельник, и во вторник, и в среду.\n\n```\nBITOP AND weekdays monday tuesday wednesday\nBITCOUNT weekdays\n```\n\n**Отслеживание уникальных событий.** Каждое событие — один бит. Если событие произошло, бит устанавливается. **BITCOUNT** показывает, сколько уникальных событий было.\n\n## Ограничения и особенности\n\nBitmaps эффективны, когда данных много, а значения бинарные (есть/нет). Если нужно хранить сложные структуры или частые обновления затрагивают большие диапазоны, лучше использовать другие структуры.\n\nВажно помнить:\n\n- позиции битов должны быть неотрицательными целыми числами;\n- для очень больших позиций (миллионы) память всё равно будет заниматься, даже если установлено мало битов;\n- операции **BITOP** создают новый ключ, что требует дополнительной памяти.\n\n## Итого\n\n**Bitmaps в Redis** дают компактный способ хранить бинарные данные и выполнять быстрые операции над ними: подсчёт установленных битов, поиск пересечений, объединение данных.\n\nДля задач вроде отслеживания активности, хранения флагов и анализа больших массивов бинарных данных **BIT*** команды предоставляют эффективный инструмент с минимальным расходом памяти.\n\n"
    },
    {
      "title": "Работа с HyperLogLog",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "data",
      "sectionTitle": "Структуры данных",
      "sectionOrder": 2,
      "order": 7,
      "id": {
        "category": "redis",
        "section": "data",
        "slug": "07-hyperloglog",
        "lang": "ru"
      },
      "path": "/content/materials/redis/data/07-hyperloglog.ru.md",
      "content": "\n**HyperLogLog** — это структура данных для приблизительного подсчёта количества уникальных элементов. Она не хранит сами элементы, а только оценивает, сколько их было. За счёт этого **HyperLogLog** занимает очень мало памяти — всего около 12 килобайт на структуру — и может обрабатывать миллиарды уникальных значений.\n\nТочность оценки обычно составляет около 0.81% стандартной ошибки, что для большинства аналитических задач вполне достаточно. Если нужен точный подсчёт уникальных элементов, лучше использовать обычные множества, но они занимают намного больше памяти.\n\n## Добавление элементов\n\nКоманда **PFADD** добавляет один или несколько элементов в структуру.\n\nПример подсчёта уникальных посетителей сайта:\n\n```\nPFADD visitors:2025-11-21 user_42\nPFADD visitors:2025-11-21 user_100\nPFADD visitors:2025-11-21 user_42\n```\n\nЗдесь:\n\n- **visitors:2025-11-21** — ключ для хранения структуры за конкретный день;\n- **user_42**, **user_100** — идентификаторы посетителей.\n\nЕсли один и тот же элемент добавляется несколько раз (как **user_42** в примере), структура учитывает его только один раз.\n\nМожно добавить несколько элементов за один вызов:\n\n```\nPFADD visitors:2025-11-21 user_42 user_100 user_789\n```\n\n## Получение оценки количества уникальных элементов\n\nКоманда **PFCOUNT** возвращает приблизительное количество уникальных элементов.\n\nПример:\n\n```\nPFCOUNT visitors:2025-11-21\n```\n\nКоманда вернёт число, например **1523**, которое означает, что примерно столько уникальных посетителей было за день.\n\nВажно понимать, что это оценка, а не точное значение. Для большинства аналитических задач такая точность достаточна, особенно когда речь идёт о миллионах или миллиардах элементов.\n\n## Объединение нескольких HyperLogLog\n\nКоманда **PFMERGE** объединяет несколько структур в одну. Это полезно, когда нужно посчитать уникальные элементы за период: например, за неделю или месяц.\n\nПример объединения данных за несколько дней:\n\n```\nPFADD visitors:2025-11-21 user_42 user_100\nPFADD visitors:2025-11-22 user_42 user_200\nPFADD visitors:2025-11-23 user_100 user_200\n\nPFMERGE visitors:week visitors:2025-11-21 visitors:2025-11-22 visitors:2025-11-23\nPFCOUNT visitors:week\n```\n\nРезультат покажет приблизительное количество уникальных посетителей за всю неделю, учитывая, что один и тот же пользователь мог заходить в разные дни.\n\n## Практические сценарии\n\n**Подсчёт уникальных посетителей.** Каждый визит добавляется в структуру, **PFCOUNT** показывает оценку уникальных пользователей за день, неделю, месяц.\n\n```\nPFADD visitors:2025-11-21 \"192.168.1.1\"\nPFADD visitors:2025-11-21 \"192.168.1.2\"\nPFCOUNT visitors:2025-11-21\n```\n\n**Аналитика поисковых запросов.** Сколько уникальных поисковых запросов было за период.\n\n```\nPFADD searches:2025-11-21 \"redis tutorial\"\nPFADD searches:2025-11-21 \"redis caching\"\nPFCOUNT searches:2025-11-21\n```\n\n**Отслеживание уникальных событий.** Сколько уникальных пользователей выполнили действие (кликнули, подписались, купили).\n\n```\nPFADD clicks:button:buy:2025-11-21 user_42\nPFADD clicks:button:buy:2025-11-21 user_100\nPFCOUNT clicks:button:buy:2025-11-21\n```\n\n**Агрегация по регионам или категориям.** Уникальные посетители по странам, уникальные товары по категориям.\n\n```\nPFADD visitors:country:US:2025-11-21 user_1\nPFADD visitors:country:US:2025-11-21 user_2\nPFADD visitors:country:RU:2025-11-21 user_3\nPFCOUNT visitors:country:US:2025-11-21\n```\n\n## Сравнение с обычными множествами\n\nДля точного подсчёта уникальных элементов можно использовать обычные множества:\n\n```\nSADD visitors:exact:2025-11-21 user_42\nSADD visitors:exact:2025-11-21 user_100\nSCARD visitors:exact:2025-11-21\n```\n\nНо есть важные различия:\n\n- **Память:** множество хранит все элементы и занимает память пропорционально количеству элементов. **HyperLogLog** всегда занимает около 12 КБ.\n- **Точность:** множество даёт точный результат, **HyperLogLog** — приблизительный (ошибка около 0.81%).\n- **Скорость:** оба варианта быстрые, но **HyperLogLog** обычно быстрее при больших объёмах данных.\n\nВыбор зависит от задачи: если нужна точность и элементов немного (тысячи, десятки тысяч), лучше множества. Если элементов миллионы или миллиарды, а небольшая погрешность допустима, **HyperLogLog** сэкономит много памяти.\n\n## Ограничения и особенности\n\n**HyperLogLog** не позволяет:\n\n- получить список элементов (структура их не хранит);\n- проверить, был ли конкретный элемент добавлен;\n- удалить отдельный элемент.\n\nЕсли нужны такие операции, лучше использовать обычные множества или другие структуры.\n\nВажно помнить:\n\n- оценка может отличаться от реального значения на 0.81% в среднем;\n- структура занимает фиксированный объём памяти (около 12 КБ), независимо от количества элементов;\n- при объединении нескольких структур точность сохраняется.\n\n## Итого\n\n**HyperLogLog в Redis** даёт компактный способ приблизительно подсчитывать уникальные элементы в огромных потоках данных, занимая при этом минимум памяти.\n\nДля аналитических задач, где важна оценка количества уникальных значений (посетители, события, запросы), а не точный список элементов, **PFADD** и **PFCOUNT** предоставляют эффективное решение с минимальным расходом ресурсов.\n\n"
    },
    {
      "title": "Redis Sentinel",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "ha-cluster",
      "sectionTitle": "Высокая доступность и кластеризация",
      "sectionOrder": 8,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "ha-cluster",
        "slug": "01-redis-sentinel",
        "lang": "ru"
      },
      "path": "/content/materials/redis/ha-cluster/01-redis-sentinel.ru.md",
      "content": "\n**Redis Sentinel** — это отдельный компонент, который следит за master и репликами, замечает сбои и при необходимости сам переключает роль на одну из реплик. Можно считать его «наблюдателем» и «аварийным переключателем» для Redis.\n\nГлавная цель Sentinel — убрать ручной failover и сделать так, чтобы приложение всегда знало, куда писать, даже если один из узлов упал.\n\n## Что делает Sentinel\n\nSentinel выполняет сразу несколько задач:\n\n- мониторит состояние master и replica;\n- решает, когда master считается недоступным;\n- выбирает подходящую реплику и продвигает её в новый master;\n- сообщает клиентам, где сейчас активный master.\n\nСписок наблюдаемых узлов и параметры порогов задаются в конфиге Sentinel.\n\n## Минимальная конфигурация Sentinel\n\nSentinel — это отдельный процесс Redis, запущенный в специальном режиме.\n\nПример простого конфига для одного мастера:\n\n```\nport 26379\n\nsentinel monitor mymaster 10.0.0.1 6379 2\nsentinel down-after-milliseconds mymaster 5000\nsentinel parallel-syncs mymaster 1\nsentinel failover-timeout mymaster 60000\n```\n\nЗдесь:\n\n- **mymaster** — имя наблюдаемого кластера Redis;\n- **10.0.0.1 6379** — адрес master;\n- **2** — сколько Sentinel должно согласиться, чтобы признать master мёртвым;\n- **down-after-milliseconds** — через сколько миллисекунд без ответа считать master недоступным;\n- **parallel-syncs** — сколько реплик можно одновременно пересинхронизировать после failover;\n- **failover-timeout** — окно времени, в котором должен уложиться процесс переключения.\n\nОбычно запускают минимум три экземпляра Sentinel, чтобы решения принимались большинством.\n\n## Как клиенты узнают о новом master\n\nSentinel сам меняет роли узлов, но приложение должно знать, куда теперь отправлять записи.\n\nЕсть два основных подхода:\n\n- клиенты, умеющие работать с Sentinel (драйверы для Redis), сами запрашивают у него адрес актуального master;\n- дополнительный слой (прокси, сервис‑дискавери) использует информацию Sentinel, чтобы отдавать клиентам правильный адрес.\n\nПример запроса из клиента к Sentinel для получения адреса master:\n\n```\nSENTINEL get-master-addr-by-name mymaster\n```\n\nОтветом будет текущий host и port активного master.\n\n## Итог\n\n**Redis Sentinel** добавляет к репликации слой наблюдения и автоматического переключения: он следит за узлами, решает, что master недоступен, и продвигает реплику в новую роль.\n\nПри правильно настроенных порогах и нескольких экземплярах Sentinel можно избавиться от ручного failover и сделать Redis заметно более устойчивым к сбоям отдельных серверов.\n\n\n"
    },
    {
      "title": "Автоматическое переключение",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "ha-cluster",
      "sectionTitle": "Высокая доступность и кластеризация",
      "sectionOrder": 8,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "ha-cluster",
        "slug": "02-automatic-failover",
        "lang": "ru"
      },
      "path": "/content/materials/redis/ha-cluster/02-automatic-failover.ru.md",
      "content": "\nАвтоматическое переключение (failover) в связке Redis + Sentinel означает, что при падении master система сама выбирает новую реплику и делает её основным узлом. Задача приложения — уметь быстро узнать новый адрес и продолжить работу без ручного вмешательства.\n\nРазберём, как выглядит процесс failover шаг за шагом и какие настройки влияют на его поведение.\n\n## Как Sentinel принимает решение о failover\n\nSentinel периодически пингует master и реплики. Когда master не отвечает дольше заданного порога, начинается процедура выбора нового master.\n\nКлючевые параметры:\n\n```\nsentinel down-after-milliseconds mymaster 5000\nsentinel failover-timeout mymaster 60000\nsentinel parallel-syncs mymaster 1\n```\n\nСмысл:\n\n- **down-after-milliseconds** — сколько миллисекунд без ответа считать master недоступным;\n- **failover-timeout** — общее окно для проведения failover;\n- **parallel-syncs** — сколько реплик можно одновременно пересинхронизировать с новым master.\n\nРешение о том, что master действительно мёртв (not reachable), принимается большинством Sentinel. Поэтому обычно поднимают минимум три экземпляра на разных серверах.\n\n## Процесс автоматического переключения\n\nКогда quorum Sentinel согласился, что master недоступен, начинается failover:\n\n1. Из доступных реплик выбирается кандидат в новый master (учитываются задержка, отставание, приоритет).\n2. Кандидату посылается команда стать самостоятельным master:\n\n```\nREPLICAOF NO ONE\n```\n\n3. Остальным репликам указывают новый master:\n\n```\nREPLICAOF <ip-нового-master> 6379\n```\n\n4. Информация о новом master публикуется через Sentinel, и клиенты, которые умеют с ним общаться, получают обновлённый адрес.\n\nВесь этот процесс занимает от нескольких секунд до десятков секунд, в зависимости от настроек и качества сети.\n\n## Как клиенты находят новый master\n\nКлиенты, поддерживающие Sentinel, обычно:\n\n1. Подключаются к набору Sentinel (например, по трём адресам).\n2. Запрашивают у него координаты master по имени:\n\n```\nSENTINEL get-master-addr-by-name mymaster\n```\n\n3. Подключаются к полученному адресу и используют его для команд записи.\n4. При ошибках подключения к Redis снова идут к Sentinel за обновлённым адресом.\n\nЕсли драйвер Redis в вашем языке не умеет работать с Sentinel, это можно обернуть отдельным слоем (прокси, сервис‑дискавери), который сам следит за Sentinel и отдаёт клиентам актуальный endpoint.\n\n## Типичные грабли при автоматическом переключении\n\nНа практике проблемы чаще всего связаны не с самим Sentinel, а с окружением:\n\n- слишком маленький **down-after-milliseconds** — частые ложные срабатывания при временных задержках сети;\n- клиенты закэшировали старый адрес master и не ходят к Sentinel за новым;\n- DNS или балансировщик не обновляют конфигурацию после failover;\n- реплики отстают слишком сильно, и новый master поднимается с устаревшими данными.\n\nПоэтому важно:\n\n- тестировать сценарии failover на тестовой среде;\n- проверять, как реальные клиенты узнают о новом master;\n- мониторить отставание реплик и время проведения failover.\n\n## Итог\n\nАвтоматическое переключение с помощью **Redis Sentinel** позволяет переживать падение master без ручного вмешательства: система сама выбирает реплику, продвигает её в master и перенастраивает остальные узлы.\n\nЕсли клиенты правильно интегрированы с Sentinel и настройки порогов подобраны под реальную сеть, Redis становится заметно устойчивее к сбоям отдельных серверов и кратковременным проблемам с инфраструктурой.\n\n\n"
    },
    {
      "title": "Redis Cluster",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "ha-cluster",
      "sectionTitle": "Высокая доступность и кластеризация",
      "sectionOrder": 8,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "ha-cluster",
        "slug": "03-redis-cluster",
        "lang": "ru"
      },
      "path": "/content/materials/redis/ha-cluster/03-redis-cluster.ru.md",
      "content": "\n**Redis Cluster** — это режим работы, в котором данные автоматически распределяются по нескольким узлам (шартам), а внутри каждого шарда всё ещё может быть master и реплики. Задача кластера — одновременно дать масштабирование по объёму данных и по нагрузке, сохраняя при этом отказоустойчивость.\n\nВ отличие от схемы «один master + несколько реплик», Redis Cluster умеет сам решать, на какой узел положить ключ, и как перенаправить клиента, если он обратился не туда.\n\n## Базовая идея кластера\n\nВ кластере Redis есть:\n\n- несколько master‑узлов, каждый хранит свою часть ключей;\n- опционально — реплики у каждого master для высокой доступности;\n- специальный механизм распределения ключей по **16384 слотам**.\n\nКаждый ключ попадает в один из 16384 хэш‑слотов по хешу:\n\n```\nhash_slot = CRC16(key) mod 16384\n```\n\nКаждый слот закреплён за конкретным master. Если мастер уходит из строя, и у него есть реплика, кластер может автоматически переключить слот на реплику.\n\n## Минимальная конфигурация кластера\n\nДля запуска кластера нужно несколько инстансов Redis с включённым режимом cluster.\n\nЧасть настроек в redis.conf:\n\n```\nport 6379\ncluster-enabled yes\ncluster-config-file nodes.conf\ncluster-node-timeout 5000\n```\n\nПосле запуска нескольких таких инстансов их объединяют в кластер с помощью утилиты:\n\n```\nredis-cli --cluster create \\\n  10.0.0.1:6379 10.0.0.2:6379 10.0.0.3:6379 \\\n  --cluster-replicas 1\n```\n\nФлаг **--cluster-replicas 1** говорит, что для каждого master будет создана одна реплика. В итоге получится набор мастер‑реплика пар, между которыми распределены все 16384 слота.\n\n## Маршрутизация запросов и редиректы\n\nКлиент кластера может попасть не на тот мастер, который хранит нужный ключ. В этом случае Redis отвечает редиректом:\n\n- **MOVED** — ключ живёт на другом узле, и этот слот уже закреплён за ним;\n- **ASK** — временный редирект во время переноса слотов между узлами.\n\nПример:\n\n```\nSET user:42 \"Alice\"\n```\n\nЕсли запрос пришёл не на тот узел, клиент получит ответ вида:\n\n```\nMOVED 12539 10.0.0.2:6379\n```\n\nДальше драйвер Redis, умеющий работать с кластером, сам перенаправит запрос на правильный узел и обновит у себя карту слотов.\n\n## Когда Redis Cluster уместен\n\nКластер имеет смысл, когда:\n\n- данных становится слишком много для одного сервера (по памяти или по диску);\n- нагрузка на один инстанс Redis превышает комфортный предел;\n- нужно горизонтально масштабировать чтение и запись по нескольким узлам.\n\nВажно помнить:\n\n- в режиме кластера не все команды доступны в прежнем виде (особенно мульти‑ключевые);\n- транзакции и Lua‑скрипты должны работать с ключами из одного слота;\n- есть свои особенности при миграции данных и смене топологии.\n\nДля сценариев, где достаточно одного узла с репликами, кластер может быть излишне сложным. Но для крупных систем с ростом данных это стандартный путь масштабирования Redis.\n\n## Итог\n\n**Redis Cluster** распределяет ключи по нескольким master‑узлам, добавляя к репликации автоматический шардинг и встроенный механизм отказоустойчивости.\n\nЕсли драйверы клиентов умеют работать с кластером, а ограничения по командам приняты в расчёт, кластер позволяет плавно наращивать объём данных и обрабатывать всё более высокую нагрузку без единой точки отказа.\n\n\n"
    },
    {
      "title": "Шардинг",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "ha-cluster",
      "sectionTitle": "Высокая доступность и кластеризация",
      "sectionOrder": 8,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "ha-cluster",
        "slug": "04-sharding",
        "lang": "ru"
      },
      "path": "/content/materials/redis/ha-cluster/04-sharding.ru.md",
      "content": "\n**Шардинг** в Redis — это разбиение ключей по нескольким узлам так, чтобы каждый узел хранил только часть данных. В режиме Redis Cluster шардинг встроен: кластер сам решает, на каком узле должен жить каждый ключ.\n\nЗадача разработчика — понимать, как работает распределение по слотам, и при необходимости управлять тем, какие ключи должны храниться вместе.\n\n## Хэш‑слоты и распределение ключей\n\nВ Redis Cluster пространство ключей разбито на **16384 хэш‑слота**. Каждый ключ попадает в один слот по формуле:\n\n```\nhash_slot = CRC16(key) mod 16384\n```\n\nКаждый мастер в кластере отвечает за подмножество этих слотов. При изменении топологии (добавление/удаление узлов) слоты могут мигрировать между мастерами.\n\nПосмотреть распределение слотов можно через:\n\n```\nCLUSTER SLOTS\n```\n\nОтвет покажет диапазоны слотов и узлы, за которые они отвечают.\n\n## Управление группами ключей через hash tags\n\nИногда нужно, чтобы несколько ключей гарантированно оказались на одном и том же узле — например, для транзакций, Lua‑скриптов или операций с несколькими ключами. Для этого используют **hash tags**.\n\nИдея простая: если в имени ключа есть фигурные скобки, для расчёта слота берётся только содержимое внутри скобок.\n\nПример:\n\n```\nSET user:{42}:profile \"{...}\"\nSET user:{42}:settings \"{...}\"\n```\n\nОба ключа попадут в один и тот же слот, потому что для хеша используется только подстрока **42**. Это позволяет безопасно использовать операции, которые требуют, чтобы все задействованные ключи были на одном мастере.\n\n## Добавление и удаление шардов\n\nКогда нагрузка растёт, в кластер можно добавить новые узлы и распределить слоты заново.\n\nПример добавления нового мастера:\n\n```\nredis-cli --cluster add-node 10.0.0.4:6379 10.0.0.1:6379\n```\n\nПосле этого слоты нужно перенести на новый узел:\n\n```\nredis-cli --cluster reshard 10.0.0.1:6379\n```\n\nИнтерактивно выбирается, сколько слотов и откуда переносить. Кластер во время миграции использует редиректы **ASK**, но для клиентов, поддерживающих Redis Cluster, этот процесс прозрачен.\n\nУдаление шардов работает похоже, только слоты сначала переносятся на другие мастера, а потом узел выбывает из кластера.\n\n## Классический client-side шардинг\n\nПомимо встроенного шардинга кластера, есть старый подход — **client-side шардинг**, когда приложение само решает, на какой Redis отправить ключ.\n\nПример идеи:\n\n- есть три инстанса Redis;\n- приложение считает хеш от ключа и по модулю количества инстансов выбирает нужный.\n\nТакой подход проще на старте, но:\n\n- не умеет автоматически перераспределять данные при изменении числа узлов;\n- не даёт встроенного failover;\n- требует много ручной работы при миграции.\n\nПоэтому для новых проектов чаще выбирают Redis Cluster, а client-side шардинг оставляют для специфических случаев.\n\n## Итог\n\nШардинг в **Redis Cluster** основан на 16384 хэш‑слотах, которые автоматически распределяются между мастер‑узлами и могут мигрировать при изменении топологии.\n\nИспользуя hash tags и штатные команды кластера для добавления и удаления узлов, можно контролировать, какие ключи лежат вместе, и плавно масштабировать систему, не переписывая логику приложения.\n\n\n"
    },
    {
      "title": "Масштабирование по нагрузке",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "ha-cluster",
      "sectionTitle": "Высокая доступность и кластеризация",
      "sectionOrder": 8,
      "order": 5,
      "id": {
        "category": "redis",
        "section": "ha-cluster",
        "slug": "05-scaling-and-load",
        "lang": "ru"
      },
      "path": "/content/materials/redis/ha-cluster/05-scaling-and-load.ru.md",
      "content": "\nRedis хорошо масштабируется вертикально (больше памяти и CPU на одном сервере), но в какой‑то момент этого становится мало. Тогда в игру вступают репликация, Sentinel и Redis Cluster — вместе они позволяют распределять нагрузку по нескольким узлам и переживать рост трафика.\n\nВажно понимать, какие рычаги масштабирования есть и как выбрать подходящий набор под конкретную систему.\n\n## Масштабирование чтения: реплики\n\nСамый простой шаг — разгрузить master, отправив часть чтений на реплики.\n\nПример идеи:\n\n- все записи идут на master;\n- часть чтений (например, отчёты, фоновые выборки) перенаправляется на replica.\n\nВыбор узла на стороне приложения:\n\n- для критичных к консистентности операций (балансы, заказы) читать только с master;\n- для менее критичных (отчёты, статистика, ленты новостей) — использовать реплики.\n\nРепликация настраивается так же, как в разделе про master–replica:\n\n```\nREPLICAOF 10.0.0.1 6379\n```\n\nТак можно постепенно добавлять новые реплики и горизонтально масштабировать чтение.\n\n## Масштабирование записи: кластер и шардинг\n\nЕсли упираемся уже не только в чтение, но и в запись, одного master становится мало. Здесь помогает Redis Cluster:\n\n- данные распределяются по нескольким master‑узлам;\n- каждый мастер обслуживает только свою часть ключей и нагрузку;\n- при необходимости каждому мастер‑узлу добавляются свои реплики.\n\nСоздание кластера:\n\n```\nredis-cli --cluster create \\\n  10.0.0.1:6379 10.0.0.2:6379 10.0.0.3:6379 \\\n  --cluster-replicas 1\n```\n\nДальше масштабирование сводится к добавлению новых шардов и перераспределению слотов. Клиенты, которые понимают Redis Cluster, автоматически разруливают маршрутизацию запросов.\n\n## Горизонтальное масштабирование с Sentinel\n\nSentinel сам по себе не масштабирует Redis по данным, но помогает масштабировать по доступности:\n\n- добавляем несколько master–replica пар для разных подсистем (кэш, сессии, очереди);\n- над каждой парой работает свой набор Sentinel;\n- клиенты знают только имена логических master и не привязаны к конкретным адресам.\n\nТак можно:\n\n- разделить нагрузку по функциям (один Redis под кэш, другой под сессии);\n- независимо масштабировать каждую часть;\n- при сбоях на уровне узла получать автоматический failover без даунтайма.\n\n## Выбор стратегии под задачу\n\nУсловно можно выделить несколько стадий развития:\n\n- один Redis‑узел с репликами для чтения — достаточно для большинства средних проектов;\n- несколько master–replica пар под разные задачи — когда важно изоляция и предсказуемость;\n- Redis Cluster — когда общий объём данных и нагрузка выходят за рамки одного сервера.\n\nПри этом Sentinel обычно присутствует на всех стадиях, где важна высокая доступность: он не масштабирует, но держит систему живой при отказах.\n\n## Итог\n\nМасштабирование по нагрузке в **Redis** строится слоями: сначала реплики для чтения, затем несколько master–replica пар под разные подсистемы и, при необходимости, Redis Cluster для горизонтального шардинга.\n\nЕсли заранее продумать, какие данные где хранятся и как клиенты находят актуальный master, можно плавно наращивать инфраструктуру Redis без резких архитектурных переделок.\n\n\n"
    },
    {
      "title": "Что такое Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "intro",
      "sectionTitle": "Что такое Redis",
      "sectionOrder": 1,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "intro",
        "slug": "01-what-is-redis",
        "lang": "ru"
      },
      "path": "/content/materials/redis/intro/01-what-is-redis.ru.md",
      "content": "\nRedis — это быстрый инструмент для хранения данных в формате «ключ–значение», который работает в оперативной памяти. Благодаря этому он отвечает практически мгновенно. Если сравнивать образно, то обычная база данных — это шкаф с полками, где каждая книга стоит на своём месте, а Redis — это стол, на котором лежат самые нужные вещи. До шкафа нужно идти, а со стола — взял и работаешь.\n\nЭта скорость делает Redis особенно полезным там, где данные нужно получать или обновлять очень часто: корзины интернет-магазинов, пользовательские сессии, системные счётчики, краткоживущие данные, проверки лимитов и многое другое. Redis не заменяет обычную базу данных, а выступает быстрым слоем между приложением и основным хранилищем.\n\n## Чем Redis отличается от обычной СУБД\n\nТрадиционные базы данных хранят информацию на диске. Это надёжно, но медленнее: данные нужно найти, считать, обработать. Redis сохраняет данные в оперативной памяти, поэтому доступ к ним происходит почти так же быстро, как доступ к переменной программы.\n\nSQL-базы предназначены для сложных запросов и больших наборов данных.  \nRedis — для ситуаций, где важны скорость и мгновенная реакция.\n\nПри необходимости Redis может сохранять данные на диск, но это дополнительная возможность, а не основная. Поэтому его чаще используют для временных или часто меняющихся данных.\n\n## Насколько Redis быстрее\n\nРазница в скорости заметна даже без глубоких измерений. Вставка и обновление значений в Redis занимает доли миллисекунды. В MySQL или Postgres аналогичная операция может занимать миллисекунды и больше, особенно под нагрузкой.\n\nВ реальных задачах это означает, что Redis выдерживает десятки или сотни тысяч операций в секунду без существенной потери производительности.\n\n### Сравнение вставки (INSERT)\n\n![Insert comparison](images/insert.png)\n\n### Сравнение обновления (UPDATE)\n\n![Update comparison](images/update.png)\n\nПо графикам видно, что Redis стабильно остаётся самым быстрым среди популярных СУБД.  \nЕго производительность почти не падает при росте количества операций — ключевое преимущество для высоконагруженных систем.\n\n## Когда Redis действительно удобен\n\nRedis используют там, где важно, чтобы данные появлялись быстро и не задерживали работу приложения:\n\n- кратковременные данные — сессии, корзины, черновики;\n- счётчики кликов, лайков, просмотров;\n- быстрый кэш, уменьшающий нагрузку на основную базу;\n- обмен сообщениями и событиями между частями системы;\n- временные блокировки, лимиты запросов, токены.\n\n## Итог\n\nRedis — это инструмент, который помогает приложениям работать быстрее и устойчивее под нагрузкой. Он прост, реактивен и значительно ускоряет операции, которые в обычной базе данных выполнялись бы заметно дольше. Именно поэтому Redis стал стандартом для тех случаев, где скорость играет ключевую роль."
    },
    {
      "title": "Архитектура и основные принципы работы",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "intro",
      "sectionTitle": "Архитектура и принципы работы",
      "sectionOrder": 1,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "intro",
        "slug": "02-architecture-and-principles",
        "lang": "ru"
      },
      "path": "/content/materials/redis/intro/02-architecture-and-principles.ru.md",
      "content": "\nАрхитектура Redis устроена достаточно просто, и именно в этой простоте скрывается его скорость. В отличие от традиционных баз данных, где много слоёв, модулей и механизмов синхронизации, Redis работает как компактный и быстрый сервер, который держит все данные в оперативной памяти и отвечает на команды последовательно, одну за другой.\n\nРабота в памяти — ключевой элемент. Когда данные лежат в RAM, нет необходимости читать их с диска, ждать позиционирования, проверки индексов и других операций. Сервер получает команду и сразу же выполняет её над объектом, который уже находится в памяти. Поэтому многие действия занимают не миллисекунды, а доли миллисекунды.\n\nRedis работает в одном потоке. Это может звучать неожиданно, ведь большинство систем стремится использовать как можно больше процессорных ядер. Но однопоточность позволяет избежать конфликтов при одновременном доступе, сложных блокировок и задержек. Сервер просто идёт по очереди команд, одна за другой, и обрабатывает их так быстро, что этот подход отлично справляется даже с большими нагрузками. Клиенты подключаются по сети и отправляют простые текстовые инструкции — получить значение, изменить его, добавить элемент в коллекцию. Сервер отвечает сразу после выполнения.\n\nИнтересной особенностью Redis является то, что он работает не только со строками. В основе лежит набор встроенных структур данных — от списков и хешей до упорядоченных множеств и потоков. Каждая структура спроектирована так, чтобы операции над ней выполнялись за минимальное время и не приводили к неожиданным задержкам.\n\nХотя Redis ориентирован на память, он умеет сохранять данные на диск. Это два разных режима: периодические снимки состояния и журнал команд, который фиксирует каждое изменение. При желании можно включить один из способов или оба сразу, в зависимости от того, насколько важна скорость и насколько критична надёжность.\n\nМеханизмы репликации и масштабирования тоже встроены в архитектуру. Основной сервер может передавать данные копии, на которую переносятся операции чтения. При необходимости к системе добавляют Sentinel для автоматического переключения в случае сбоя или запускают кластер, где данные распределяются по нескольким узлам. Но все эти возможности существуют не как тяжёлые и сложные модули, а как расширение базового принципа простоты и предсказуемости.\n\nВ итоге архитектура Redis строится вокруг идеи: чем меньше лишних слоёв и чем ближе данные к процессору, тем быстрее реагирует система. Эта прямолинейность делает Redis не только быстрым, но и понятным в использовании — даже человеку, который впервые с ним работает.\n\n"
    },
    {
      "title": "Установка и запуск Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "intro",
      "sectionTitle": "Установка и запуск Redis",
      "sectionOrder": 1,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "intro",
        "slug": "03-installation-and-setup",
        "lang": "ru"
      },
      "path": "/content/materials/redis/intro/03-installation-and-setup.ru.md",
      "content": "\nУстановка Redis на Linux выполняется через стандартные системные пакеты. Ниже приведён простой рабочий набор команд, который подходит для Ubuntu, Debian, Linux Mint и других систем на базе APT.\n\n## Установка\n\n```\nsudo apt update\nsudo apt install redis-server\n```\n\nПосле установки сервер запускается автоматически.\n\n## Проверка работы\n\nПроверяем статус службы:\n\n```\nsystemctl status redis-server\n```\n\nЕсли сервер работает, можно подключиться:\n\n```\nredis-cli\n```\n\nИ отправить тестовую команду:\n\n```\nPING\n```\n\nОжидаемый ответ:\n\n```\nPONG\n```\n\nЭто означает, что всё установлено корректно.\n\n## Управление сервером\n\n```\nsudo systemctl start redis-server\nsudo systemctl stop redis-server\nsudo systemctl restart redis-server\n```\n\n## Конфигурация\n\nОсновной конфигурационный файл расположен здесь:\n\n```\n/etc/redis/redis.conf\n```\n\nПосле изменений требуется перезапуск.\n\n## Минимальная проверка сохранения\n\n```\nredis-cli set test \"hello\"\nredis-cli get test\n```\n\nЕсли значение сохраняется после перезапуска, Redis корректно работает с диском.\n\n## Запуск через Docker\n\nЕсли не хочется устанавливать Redis в систему напрямую, его можно запустить в контейнере Docker. Это удобный способ получить изолированный экземпляр сервера.\n\n### Запуск контейнера\n\n```\ndocker run -d --name redis \\\n  -p 6379:6379 \\\n  redis:latest\n```\n\nПосле запуска Redis будет доступен на порту 6379, как и при обычной установке.\n\n### Проверка работы\n\n```\ndocker exec -it redis redis-cli ping\n```\n\nОжидаемый ответ:\n\n```\nPONG\n```\n\n### Остановка и удаление контейнера\n\n```\ndocker stop redis\ndocker rm redis\n```\n\nЭтот способ подходит, если нужно быстро развернуть сервер без изменения системы или когда проект полностью работает в контейнерах.\n"
    },
    {
      "title": "Когда НЕ использовать Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "intro",
      "sectionTitle": "Введение",
      "sectionOrder": 1,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "intro",
        "slug": "04-when-not-to-use-redis",
        "lang": "ru"
      },
      "path": "/content/materials/redis/intro/04-when-not-to-use-redis.ru.md",
      "content": "\nRedis — отличный инструмент для многих задач, но он не универсален. Есть ситуации, где его использование будет неэффективным, рискованным или просто неправильным выбором. Понимание ограничений помогает избежать проблем и выбрать подходящий инструмент с самого начала.\n\n## Когда данные должны быть строго персистентными\n\nRedis хранит данные в памяти. Хотя есть механизмы сохранения на диск (RDB и AOF), они не гарантируют нулевую потерю данных при сбое. Между снимками или записями в лог возможна потеря последних изменений.\n\n**Не используйте Redis, если:**\n\n- потеря даже нескольких секунд данных критична (финансовые транзакции, медицинские записи);\n- требуется строгая гарантия ACID с немедленной записью на диск;\n- данные должны быть надёжно сохранены даже при внезапном отключении питания.\n\n**Лучше выбрать:** PostgreSQL, MySQL, другие реляционные БД с гарантиями персистентности.\n\n## Когда нужны сложные запросы и связи\n\nRedis — это хранилище «ключ–значение» с простыми структурами данных. Здесь нет JOIN, сложных фильтров, агрегаций, полнотекстового поиска по содержимому.\n\n**Не используйте Redis, если:**\n\n- нужно делать запросы вроде «найти всех пользователей из города X, которые купили товар Y за последний месяц»;\n- важны связи между сущностями (один ко многим, многие ко многим);\n- требуется сложная аналитика с группировками и вычислениями.\n\n**Лучше выбрать:** PostgreSQL для реляционных данных, MongoDB для документной модели, Elasticsearch для поиска и аналитики.\n\n## Когда данных больше, чем доступной памяти\n\nRedis держит все данные в оперативной памяти. Если объём данных превышает доступную RAM, Redis либо начнёт вытеснять ключи (если настроена политика eviction), либо перестанет принимать записи.\n\n**Не используйте Redis, если:**\n\n- нужно хранить терабайты данных, а доступной памяти недостаточно;\n- данные редко используются, но должны быть доступны (архивы, старые логи);\n- стоимость RAM становится неподъёмной для объёма данных.\n\n**Лучше выбрать:** PostgreSQL, MongoDB, Cassandra — системы, которые умеют работать с диском и эффективно использовать память как кэш.\n\n## Когда нужны транзакции с изоляцией\n\nВ Redis есть команды MULTI/EXEC, но они не дают полной изоляции транзакций, как в реляционных БД. Нет блокировок на уровне строк, нет уровней изоляции, нет автоматического отката при конфликтах.\n\n**Не используйте Redis, если:**\n\n- критичны транзакции с гарантией изоляции (например, перевод денег между счетами);\n- нужно предотвратить чтение «грязных» данных во время транзакции;\n- важна консистентность при одновременных изменениях нескольких связанных сущностей.\n\n**Лучше выбрать:** PostgreSQL, MySQL с поддержкой транзакций и уровнями изоляции.\n\n## Когда нужна репликация с записью на несколько узлов\n\nRedis поддерживает репликацию, но запись идёт только на master. Реплики работают в режиме только чтения. Нет встроенной поддержки multi-master репликации, где можно писать на любой узел.\n\n**Не используйте Redis, если:**\n\n- нужна запись на несколько узлов одновременно с автоматической синхронизацией;\n- важна географическая распределённость с записью в разных регионах;\n- требуется сложная схема репликации с конфликт-резолюцией.\n\n**Лучше выбрать:** Cassandra, MongoDB с multi-master, распределённые системы с поддержкой записи на несколько узлов.\n\n## Когда нужны большие значения или сложные структуры\n\nХотя Redis поддерживает разные структуры данных, работа с очень большими значениями (мегабайты и больше) может быть неэффективной. Большие операции блокируют сервер и замедляют работу других клиентов.\n\n**Не используйте Redis, если:**\n\n- нужно хранить большие файлы, изображения, видео;\n- значения регулярно превышают несколько мегабайт;\n- важна эффективная работа с большими бинарными данными.\n\n**Лучше выбрать:** объектные хранилища (S3, MinIO), файловые системы, специализированные хранилища для больших данных.\n\n## Когда нужна строгая безопасность и аудит\n\nRedis изначально создавался для доверенных сред. Хотя есть механизмы безопасности (ACL, TLS), они не так развиты, как в специализированных БД.\n\n**Не используйте Redis, если:**\n\n- требуется детальный аудит всех операций с данными;\n- нужны строгие политики доступа на уровне строк или полей;\n- важна соответствие строгим стандартам безопасности (HIPAA, PCI-DSS) без дополнительных слоёв.\n\n**Лучше выбрать:** PostgreSQL с расширениями для аудита, специализированные БД с встроенными механизмами безопасности.\n\n## Когда нагрузка в основном на запись\n\nRedis оптимизирован для быстрого чтения. При очень высокой нагрузке на запись (десятки тысяч записей в секунду с большими значениями) может возникнуть узкое место, особенно если включена персистентность.\n\n**Не используйте Redis, если:**\n\n- основная нагрузка — запись больших объёмов данных (логирование, метрики);\n- нужна эффективная запись на диск без влияния на производительность;\n- важнее пропускная способность записи, чем скорость чтения.\n\n**Лучше выбрать:** специализированные системы для логов (Kafka, ClickHouse), временные ряды БД (InfluxDB, TimescaleDB).\n\n## Итого\n\n**Redis — отличный выбор для кэширования, сессий, счётчиков, очередей и быстрого доступа к данным в памяти.** Но он не заменяет реляционные БД для сложных запросов, не подходит для строгих транзакций и не справляется с данными, которые не помещаются в память.\n\nГлавное правило: **используйте Redis там, где важна скорость доступа к данным в памяти, а не там, где нужны сложные запросы, строгая персистентность или огромные объёмы данных.** Правильный выбор инструмента зависит от конкретных требований задачи, а не от популярности технологии.\n\n"
    },
    {
      "title": "Политики вытеснения",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "memory",
      "sectionTitle": "Управление памятью",
      "sectionOrder": 5,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "memory",
        "slug": "01-eviction-policies",
        "lang": "ru"
      },
      "path": "/content/materials/redis/memory/01-eviction-policies.ru.md",
      "content": "\n**Redis** обычно держит все данные в памяти. Если её не хватает, поведение сервера зависит от настроек: он либо начнёт вытеснять старые ключи, либо просто перестанет принимать записи с ошибкой. За это отвечает связка **maxmemory** и **maxmemory-policy**.\n\nЧтобы не получить неожиданный отказ от записи в продакшене, важно понимать, какие есть политики и в каких сценариях какую выбирать.\n\n## Лимит памяти maxmemory\n\nСначала задаётся общий лимит, сколько памяти **Redis** может использовать под данные.\n\nПосмотреть текущий лимит:\n\n```\nCONFIG GET maxmemory\n```\n\nУстановить, например, 1 гигабайт:\n\n```\nCONFIG SET maxmemory 1gb\n```\n\nПосле достижения лимита начинает работать политика вытеснения. Если лимит не задан (0), Redis будет пытаться использовать всю доступную память процесса и операционной системы — в продакшене это почти всегда плохая идея.\n\nОбычно лимит фиксируют на уровне, который удобно мониторить и под который рассчитан сервер.\n\n## Основные политики вытеснения\n\nПолитику можно узнать так:\n\n```\nCONFIG GET maxmemory-policy\n```\n\nИ поменять:\n\n```\nCONFIG SET maxmemory-policy allkeys-lru\n```\n\nРаспространённые варианты:\n\n- **noeviction** — новая запись при нехватке памяти завершится ошибкой. Подходит для сценариев, где нельзя терять данные и есть внешний контроль за объёмом.\n- **volatile-lru** — выталкивать по принципу LRU только те ключи, у которых есть **TTL**.\n- **allkeys-lru** — выталкивать по LRU любые ключи. Часто используется для кэша.\n- **volatile-ttl** — удалять в первую очередь ключи с минимальным оставшимся **TTL**.\n- **allkeys-random** и **volatile-random** — выбирать ключи для удаления случайно.\n\nВ новых версиях есть также варианты на основе **LFU** (частоты использования): **allkeys-lfu** и **volatile-lfu**.\n\n## Практические сценарии выбора политики\n\nДля чистого кэша, где данные всегда можно восстановить из основной базы, чаще всего выбирают:\n\n```\nCONFIG SET maxmemory-policy allkeys-lru\n```\n\nСценарий: хранение ключей вида **cache:article:42**, **cache:profile:10** без строгих гарантий сохранности. Redis сам будет удалять давно неиспользуемые записи, чтобы укладываться в заданный лимит.\n\nЕсли в Redis лежит не только кэш, но и важные данные, и при этом у временных ключей всегда есть **TTL**, уместен вариант:\n\n```\nCONFIG SET maxmemory-policy volatile-lru\n```\n\nТогда при нехватке памяти будут удаляться только ключи с временем жизни, а постоянные данные останутся нетронутыми. Важно следить, чтобы все «одноразовые» и кэширующие ключи действительно имели TTL.\n\n## Типичные ошибки при настройке\n\nЧастые проблемы:\n\n- лимит **maxmemory** не задан, Redis занимает всю память сервера;\n- выбрана политика **noeviction**, а приложение не умеет обрабатывать ошибку записи;\n- политика требует **TTL**, но ключи кэша и сессий создаются без явного времени жизни;\n- разные типы данных смешаны в одном инстансе Redis: и кэш, и критичные данные, и очереди.\n\nПрактичный подход — разделять назначения по разным инстансам: один Redis только под кэш с политикой **allkeys-lru**, другой — под сессии и очереди с аккуратной работой с TTL и без агрессивного вытеснения.\n\n## Итог\n\nПолитики вытеснения в **Redis** определяют, что произойдёт, когда сервер упрётся в лимит памяти: какие ключи будут удаляться и будут ли операции записи вообще успешны.\n\nГрамотный выбор **maxmemory** и **maxmemory-policy** под конкретный сценарий (кэш, сессии, очереди, критичные данные) помогает избежать неожиданного падения сервиса и контролировать поведение Redis под нагрузкой.\n\n\n"
    },
    {
      "title": "Оценка размера ключей",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "memory",
      "sectionTitle": "Управление памятью",
      "sectionOrder": 5,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "memory",
        "slug": "02-key-size-estimation",
        "lang": "ru"
      },
      "path": "/content/materials/redis/memory/02-key-size-estimation.ru.md",
      "content": "\nКогда данных становится много, важно понимать, сколько памяти реально занимает каждый ключ и какие структуры «съедают» больше всего. В **Redis** для этого есть отдельные инструменты: команды **MEMORY USAGE**, **MEMORY STATS** и **MEMORY DOCTOR**.\n\nС их помощью можно найти самые тяжёлые ключи, сравнить разные варианты хранения и принять осознанное решение по оптимизации.\n\n## MEMORY USAGE — размер одного ключа\n\nПроще всего начать с оценки конкретного ключа. Команда **MEMORY USAGE** показывает примерный объём памяти в байтах, который занимает значение.\n\nПример с простым кэшем статьи:\n\n```\nSET cache:article:42 \"{...json статьи...}\"\nMEMORY USAGE cache:article:42\n```\n\nВ ответ Redis вернёт число, например:\n\n```\n(integer) 2048\n```\n\nЭто не точный, но достаточно близкий к реальности размер. Полезно запускать **MEMORY USAGE** на разных типах ключей:\n\n- строки с JSON;\n- хеши с теми же данными;\n- списки, множества, упорядоченные множества.\n\nТак можно быстро увидеть, какой формат для вашей задачи дешевле по памяти.\n\n## Поиск «тяжёлых» ключей через SCAN\n\nЧтобы понять, какие ключи в инстансе самые крупные, можно пройтись по ним через **SCAN** и для каждого посмотреть **MEMORY USAGE**.\n\nНапример, ищем тяжёлые ключи кэша:\n\n```\nSCAN 0 MATCH cache:* COUNT 100\nMEMORY USAGE cache:article:1\nMEMORY USAGE cache:article:2\nMEMORY USAGE cache:profile:42\n```\n\nСкрипт на стороне приложения:\n\n- вызывает **SCAN** в цикле;\n- для каждого найденного ключа делает **MEMORY USAGE**;\n- сортирует по размеру и показывает топ-10–20 самых больших.\n\nТакой подход помогает быстро найти неожиданные «пожиратели» памяти: огромные списки логов, ключи без **TTL**, слишком крупные JSON-объекты.\n\n## MEMORY STATS и MEMORY DOCTOR\n\nДля общей картины по памяти можно использовать:\n\n```\nMEMORY STATS\n```\n\nКоманда возвращает большой набор метрик: общую использованную память, накладные расходы на структуры, настройки аллокатора, фрагментацию. Полезно сохранить этот вывод и сравнивать его до и после изменений в схеме хранения.\n\nЕсли хочется быстрой подсказки от самого Redis:\n\n```\nMEMORY DOCTOR\n```\n\nОтвет будет в текстовом виде и может содержать советы уровня:\n\n- уменьшить количество маленьких ключей;\n- обратить внимание на фрагментацию;\n- посмотреть на конфигурацию аллокатора.\n\nЭти рекомендации не всегда точечные, но часто помогают заметить общие проблемы.\n\n## Сравнение вариантов хранения на примере\n\nДопустим, у нас есть 1000 настроек пользователей. Можно хранить их как 1000 отдельных ключей:\n\n```\nSET user:1:settings \"{...}\"\nSET user:2:settings \"{...}\"\n...\nSET user:1000:settings \"{...}\"\n```\n\nА можно как один хеш:\n\n```\nHSET user:settings 1 \"{...}\"\nHSET user:settings 2 \"{...}\"\n...\nHSET user:settings 1000 \"{...}\"\n```\n\nЧтобы сравнить, достаточно измерить:\n\n```\nMEMORY USAGE user:1:settings\nMEMORY USAGE user:settings\n```\n\nВо многих случаях один хеш будет экономичнее, чем множество мелких ключей, за счёт меньших накладных расходов. Но лучше всегда проверять на своих данных.\n\n## Итог\n\nИнструменты **MEMORY USAGE**, **MEMORY STATS** и **MEMORY DOCTOR** помогают превратить оптимизацию памяти в измеряемый процесс, а не в угадывание.\n\nРегулярная оценка размеров ключей и поиск самых тяжёлых записей позволяет вовремя заметить неэффективные структуры и переработать схему хранения до того, как Redis начнёт упираться в лимит.\n\n\n"
    },
    {
      "title": "Оптимизация потребления памяти",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "memory",
      "sectionTitle": "Управление памятью",
      "sectionOrder": 5,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "memory",
        "slug": "03-memory-optimization",
        "lang": "ru"
      },
      "path": "/content/materials/redis/memory/03-memory-optimization.ru.md",
      "content": "\nДаже при правильно настроенных лимитах и политиках вытеснения важно, как именно данные лежат в **Redis**. Те же самые объёмы информации можно хранить по-разному: где‑то тратится в разы больше памяти, где‑то — значительно меньше.\n\nОптимизация обычно сводится к трём вещам: выбор структуры данных, аккуратные ключи и разумное время жизни.\n\n## Выбор подходящей структуры\n\nРазные структуры в **Redis** по‑разному расходуют память. Часто можно заметно выиграть, если заменить россыпь мелких ключей на один хеш или использовать упорядоченное множество вместо списка.\n\nПример с профилями пользователей.\n\nВариант 1 — много отдельных строк:\n\n```\nSET user:42:name \"Alice\"\nSET user:42:email \"alice@example.com\"\nSET user:42:city \"Berlin\"\n```\n\nВариант 2 — один хеш:\n\n```\nHSET user:42 name \"Alice\" email \"alice@example.com\" city \"Berlin\"\n```\n\nВо втором случае меньше накладных расходов на ключи, а отдельные поля по‑прежнему можно читать и обновлять независимо. На практике хеши хорошо подходят для компактного хранения небольших сущностей.\n\n## Экономные названия ключей\n\nКаждый ключ сам по себе занимает память. Если в проекте миллионы ключей, лишние символы в имени начинают стоить дорого.\n\nПример:\n\n```\nSET very-long-namespace:users:profiles:42 \"{...}\"\n```\n\nМожно упростить схему, не теряя смысла:\n\n```\nSET user:profile:42 \"{...}\"\n```\n\nГлавные идеи:\n\n- избегать излишне длинных префиксов;\n- не дублировать одну и ту же часть названия несколько раз;\n- держать схему ключей понятной, но без лишних слов.\n\nПеред массовым вводом новой схемы ключей полезно оценить реальный выигрыш через **MEMORY USAGE** на тестовом наборе данных.\n\n## TTL и очистка ненужных данных\n\nЧасть данных в **Redis** по своей природе временная: кэш, одноразовые токены, черновики, сессии. Если не задавать им **TTL**, они будут накапливаться и занимать память даже после того, как перестанут быть нужны.\n\nПримеры с разумным временем жизни:\n\n```\nSETEX cache:article:42 300 \"{...json статьи...}\"\nSETEX session:token:abc123 1800 \"user:42\"\n```\n\nПара практических правил:\n\n- у любых кэширующих ключей должен быть **TTL**;\n- у сессий — срок жизни, соответствующий бизнес‑логике;\n- временные флаги и коды подтверждения всегда создаются с ограничением по времени.\n\nДля удаления крупных ключей лучше использовать **UNLINK**, чтобы не блокировать сервер:\n\n```\nUNLINK big:list\nUNLINK cache:heavy:result\n```\n\n## Разделение данных по инстансам\n\nИногда оптимизация — это не только про байты, но и про поведение под нагрузкой. Стоит разделять:\n\n- чистый кэш;\n- сессии и авторизацию;\n- очереди задач и события.\n\nНапример:\n\n- один инстанс **Redis** работает как кэш с агрессивной политикой **allkeys-lru** и короткими **TTL**;\n- другой инстанс хранит сессии и очереди, где память используется более предсказуемо, а вытеснение либо отключено, либо настроено мягко.\n\nТак проще контролировать потребление памяти и поведение каждой части системы, не пытаясь впихнуть все сценарии в один набор настроек.\n\n## Итог\n\nОптимизация памяти в **Redis** — это в первую очередь про правильный выбор структур данных, аккуратную схему ключей и осознанное использование **TTL**.\n\nЕсли регулярно измерять размер ключей, пересматривать схему хранения и разделять разные типы нагрузки по инстансам, Redis остаётся компактным и предсказуемым даже при росте объёмов данных.\n\n\n"
    },
    {
      "title": "Основные метрики и команда INFO",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "monitoring",
      "sectionTitle": "Мониторинг и отладка",
      "sectionOrder": 10,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "monitoring",
        "slug": "01-info-and-metrics",
        "lang": "ru"
      },
      "path": "/content/materials/redis/monitoring/01-info-and-metrics.ru.md",
      "content": "\nДля нормальной эксплуатации **Redis** важно не только писать и читать данные, но и понимать, как чувствует себя сервер: хватает ли памяти, не зашкаливает ли число подключений, нет ли проблем с репликацией. Базовый инструмент для этого — команда **INFO**.\n\nЧерез INFO можно быстро посмотреть ключевые метрики и на их основе настроить мониторинг в Prometheus, Grafana и других системах.\n\n## Команда INFO по разделам\n\nВ самом простом виде:\n\n```\nINFO\n```\n\nRedis вернёт большой блок текста, разбитый на разделы: Server, Clients, Memory, Persistence, Stats, Replication и так далее.\n\nМожно запрашивать конкретный раздел:\n\n```\nINFO memory\nINFO stats\nINFO replication\n```\n\nЭто удобнее для автоматического сбора метрик и для быстрой диагностики проблем в конкретной области.\n\n## Важные метрики памяти\n\nРаздел **memory** помогает оценить, сколько ресурсов реально съедает Redis.\n\nПример:\n\n```\nINFO memory\n```\n\nКлючевые поля:\n\n- used_memory — сколько памяти реально занято под данные и структуры Redis;\n- used_memory_rss — сколько памяти занят процесс в системе (с учётом фрагментации);\n- maxmemory — лимит памяти, если он настроен;\n- mem_fragmentation_ratio — отношение RSS к used_memory, показывает уровень фрагментации.\n\nНа практике:\n\n- если used_memory близко к maxmemory, скоро начнут работать политики вытеснения;\n- если mem_fragmentation_ratio сильно больше 1, есть смысл расследовать фрагментацию и настройки аллокатора.\n\n## Общие статистики и нагрузка\n\nРаздел **stats** даёт представление о том, насколько активно используется Redis.\n\nПример:\n\n```\nINFO stats\n```\n\nПолезные поля:\n\n- total_commands_processed — сколько команд всего обработано;\n- instantaneous_ops_per_sec — текущий QPS (команды в секунду);\n- keyspace_hits и keyspace_misses — попадания и промахи по ключам;\n- expired_keys — сколько ключей было удалено по TTL.\n\nЭти метрики хорошо подходят:\n\n- для графиков нагрузки во времени;\n- для понимания эффективности кэша (по hit/miss);\n- для оценки того, сколько ключей реально живёт за счёт TTL.\n\n## Клиенты и соединения\n\nРаздел **clients** помогает увидеть, сколько подключений открыто и нет ли «утечек» клиентов.\n\nПример:\n\n```\nINFO clients\n```\n\nСмотрим:\n\n- connected_clients — число активных соединений;\n- blocked_clients — сколько клиентов сейчас заблокировано (например, на BLPOP или командах, ожидающих данных).\n\nЕсли connected_clients растёт без остановки или часто достигает лимитов, стоит:\n\n- проверить, правильно ли приложения закрывают подключения;\n- настроить пулы соединений;\n- при необходимости увеличить лимиты и ресурсы.\n\n## Итог\n\nКоманда **INFO** — центральный инструмент быстрой диагностики и базового мониторинга Redis: через неё можно увидеть память, нагрузку, клиентов и состояние репликации.\n\nЕсли регулярно смотреть на ключевые поля и вытащить их в систему мониторинга, многие проблемы с Redis становятся заметны задолго до того, как превратятся в реальные аварии.\n\n\n"
    },
    {
      "title": "MONITOR, SLOWLOG и медленные команды",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "monitoring",
      "sectionTitle": "Мониторинг и отладка",
      "sectionOrder": 10,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "monitoring",
        "slug": "02-monitor-and-slowlog",
        "lang": "ru"
      },
      "path": "/content/materials/redis/monitoring/02-monitor-and-slowlog.ru.md",
      "content": "\nКогда Redis начинает «тормозить», важно понять, какие именно команды его грузят: кто шлёт слишком тяжёлые запросы, какие операции работают медленно и почему. Для этого в Redis есть две мощные вещи: **MONITOR** для живого просмотра команд и **SLOWLOG** для истории медленных операций.\n\nЭти инструменты удобно использовать в паре: MONITOR — для оперативной отладки, SLOWLOG — для системного анализа.\n\n## MONITOR — живой поток команд\n\nКоманда **MONITOR** показывает все команды, которые выполняются на сервере, в режиме реального времени.\n\nПример:\n\n```\nMONITOR\n```\n\nПосле этого клиент начнёт получать строки вида:\n\n```\n1669212345.123456 [0 10.0.0.5:53421] \"SET\" \"user:42\" \"Alice\"\n1669212345.234567 [0 10.0.0.6:53422] \"GET\" \"cache:article:42\"\n```\n\nЧто это даёт:\n\n- видно, какие ключи активно используются;\n- можно отследить, какие сервисы шлют неожиданные команды;\n- удобно в отладке на тестовой среде.\n\nВажно:\n\n- MONITOR сильно нагружает сервер и сеть, особенно под высокой нагрузкой;\n- его не стоит использовать постоянно в продакшене;\n- лучше подключаться к MONITOR с отдельного, временного клиента и на ограниченное время.\n\n## SLOWLOG — журнал медленных команд\n\n**SLOWLOG** хранит записи о командах, которые выполнялись дольше заданного порога.\n\nПосмотреть текущие настройки:\n\n```\nCONFIG GET slowlog-log-slower-than\nCONFIG GET slowlog-max-len\n```\n\nТипичные значения:\n\n- slowlog-log-slower-than — порог в микросекундах (например, 10000 = 10 мс);\n- slowlog-max-len — сколько записей хранить в журнале.\n\nПример настройки:\n\n```\nCONFIG SET slowlog-log-slower-than 10000\nCONFIG SET slowlog-max-len 128\n```\n\nПросмотр журнала:\n\n```\nSLOWLOG GET 10\n```\n\nОтвет содержит:\n\n- идентификатор записи;\n- время выполнения;\n- саму команду и её аргументы.\n\nТак можно увидеть, какие конкретные запросы стабильно занимают десятки или сотни миллисекунд.\n\n## Как использовать эти инструменты на практике\n\nТиповой сценарий:\n\n1. В продакшене всегда включён разумный SLOWLOG (порог в районе 5–10 мс).\n2. При первых жалобах на тормоза смотрим SLOWLOG и ищем паттерны:\n\n```\nSLOWLOG GET 20\n```\n\n3. Если нужно понять, откуда точно приходят проблемные команды, временно включаем MONITOR на тесте или на отдельной реплике.\n4. По результатам:\n\n- оптимизируем ключи и команды;\n- пересматриваем использование тяжёлых операций (например, KEYS, большие LRANGE, массовые скрипты).\n\n## Итог\n\n**MONITOR** даёт живую картинку всех команд, а **SLOWLOG** — аккуратный список самых медленных операций за последнее время.\n\nЕсли держать SLOWLOG настроенным постоянно и подключать MONITOR точечно для сложных случаев, отладка производительности Redis превращается из угадывания в понятный и воспроизводимый процесс.\n\n\n"
    },
    {
      "title": "Логи Redis и настройки логирования",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "monitoring",
      "sectionTitle": "Мониторинг и отладка",
      "sectionOrder": 10,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "monitoring",
        "slug": "03-logging",
        "lang": "ru"
      },
      "path": "/content/materials/redis/monitoring/03-logging.ru.md",
      "content": "\nПомимо команд INFO и SLOWLOG, много ценной информации о работе **Redis** можно получить из обычных логов сервера. Они помогают понять, когда сервер перезапускался, были ли ошибки при сохранении snapshot, как ведёт себя репликация и что происходило перед аварией.\n\nВажно правильно настроить, куда пишет Redis, какой уровень логирования использовать и как забирать эти данные в централизованную систему.\n\n## Куда пишет Redis: logfile и syslog\n\nОсновные параметры логирования:\n\n```\nlogfile \"\"\nsyslog-enabled no\nsyslog-ident redis\nsyslog-facility local0\n```\n\nЕсли **logfile** пустой, Redis пишет логи в stdout/stderr — это удобно для контейнеров и систем, где логи собирает оркестратор.\n\nЕсли нужно писать в файл:\n\n```\nlogfile \"/var/log/redis/redis-server.log\"\n```\n\nВ продакшене чаще всего:\n\n- или оставляют вывод в stdout и забирают его средствами платформы;\n- или пишут в файл и ротируют через logrotate.\n\n## Уровень логирования\n\nЗа уровень отвечает параметр **loglevel**.\n\nВарианты:\n\n```\nloglevel notice\n```\n\nДоступные уровни:\n\n- debug — максимально подробные логи (только для отладки на dev);\n- verbose — расширенная информация;\n- notice — разумный уровень по умолчанию;\n- warning — только предупреждения и ошибки.\n\nДля продакшена обычно достаточно **notice** или, при очень чувствительном диске, **warning**. Для отладки сложных проблем можно временно включить **verbose** или **debug**, но не оставлять так надолго.\n\n## Что искать в логах\n\nТипичные вещи, которым стоит уделять внимание:\n\n- сообщения о запуске и остановке сервера;\n- ошибки сохранения RDB или записи AOF;\n- предупреждения о блокирующих операциях;\n- события, связанные с репликацией и Sentinel;\n- сообщения о переполнении памяти и срабатывании политик вытеснения.\n\nПримеры:\n\n- ошибки BGSAVE;\n- предупреждения о частых полных синхронизациях реплик;\n- записи о failover при использовании Sentinel.\n\nИмея централизованный сбор логов, легко построить алерты на появление критичных сообщений.\n\n## Интеграция с внешним мониторингом\n\nЧасто логи Redis отправляют в:\n\n- системные журналы (journald, syslog);\n- централизованные стеки (ELK, Loki, Cloud Logging);\n- системы алертинга (через парсинг логов).\n\nОбщий подход:\n\n- настроить единый формат логов;\n- добавить метки окружения и инстанса;\n- фильтровать только важные сообщения для алертов.\n\nНа практике это позволяет быстро ответить на вопросы вида «что случилось с Redis в момент X» без подключения к серверу по SSH.\n\n## Итог\n\nЛоги **Redis** дополняют INFO и SLOWLOG: они показывают историю событий сервера — от перезапусков и ошибок snapshot до проблем с репликацией и памятью.\n\nЕсли настроить удобный вывод логов, выбрать адекватный loglevel и собрать их в централизованную систему, поиск причин сбоев и странного поведения Redis становится гораздо проще и быстрее.\n\n\n"
    },
    {
      "title": "Диагностика памяти и горячих ключей",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "monitoring",
      "sectionTitle": "Мониторинг и отладка",
      "sectionOrder": 10,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "monitoring",
        "slug": "04-memory-hotkeys-diagnostics",
        "lang": "ru"
      },
      "path": "/content/materials/redis/monitoring/04-memory-hotkeys-diagnostics.ru.md",
      "content": "\nКогда Redis начинает упираться в лимит памяти или отдельные ключи вызывают всплески нагрузки, важно уметь быстро понять, кто именно виноват. Для этого пригодятся команды **MEMORY** и инструменты вроде **LATENCY DOCTOR**, а также аккуратный обход ключей.\n\nЧасть этих приёмов уже встречалась в разделе про управление памятью, здесь посмотрим на них с точки зрения мониторинга и быстрой диагностики.\n\n## Быстрая оценка памяти через INFO и MEMORY STATS\n\nПервый шаг — посмотреть общую картину:\n\n```\nINFO memory\n```\n\nЕсли used_memory близок к maxmemory или mem_fragmentation_ratio заметно больше 1, стоит копнуть глубже.\n\nБолее детальный снимок:\n\n```\nMEMORY STATS\n```\n\nКоманда возвращает массив статистик: сколько памяти уходит на данные, на служебные структуры, на аллокатор. Эти данные удобно загонять в мониторинг, чтобы отслеживать тренды роста и понимать, где именно «толстеет» Redis.\n\n## Поиск тяжёлых ключей через MEMORY USAGE\n\nЧтобы найти, какие ключи занимают больше всего памяти, можно пройтись по ним через SCAN и для каждого замерить размер.\n\nПример ручного подхода:\n\n```\nSCAN 0 MATCH cache:* COUNT 100\nMEMORY USAGE cache:article:1\nMEMORY USAGE cache:article:2\n```\n\nНа практике:\n\n- скрипт на стороне приложения обходит ключи по SCAN;\n- вызывает **MEMORY USAGE** для каждого;\n- строит топ‑N самых тяжёлых ключей.\n\nТак легко обнаружить:\n\n- слишком крупные JSON‑значения;\n- ключи без TTL, которые накопили огромные структуры;\n- неожиданные коллекции логов и очередей.\n\n## Поиск горячих ключей через мониторинг\n\nГорячие ключи — это те, к которым идёт непропорционально много обращений. Они могут становиться узким местом: один ключ с тяжёлым значением, который читают тысячи раз в секунду.\n\nПростейший приём:\n\n- временно включить **MONITOR** на тестовой реплике или в ограниченное время;\n- отфильтровать поток команд по ключам и посчитать частоту обращений.\n\nПример:\n\n```\nMONITOR\n```\n\nДальше парсер или отдельный инструмент считает, какие ключи встречаются чаще всего. Такие ключи:\n\n- кандидаты на оптимизацию структуры данных;\n- могут требовать кэширования на стороне приложения;\n- иногда подсказка, что данные стоит разнести по нескольким ключам.\n\n## LATENCY DOCTOR и неожиданные задержки\n\nRedis имеет встроенный инструмент для анализа задержек:\n\n```\nLATENCY DOCTOR\n```\n\nОн пытается автоматически найти и описать проблемы:\n\n- длительные блокирующие операции;\n- резкие скачки в работе диска;\n- аномалии в репликации.\n\nВывод команды даёт текстовые рекомендации и может указать, где искать корень проблемы — в памяти, диске, сети или конкретных командах.\n\n## Итог\n\nДиагностика памяти и горячих ключей в **Redis** опирается на INFO и MEMORY STATS для общей картины, MEMORY USAGE и SCAN для поиска тяжёлых ключей, а также MONITOR и LATENCY DOCTOR для анализа частоты обращений и задержек.\n\nЕсли держать под рукой эти инструменты и периодически смотреть на них не только во время аварий, многие проблемы с памятью и узкими местами можно поймать и исправить заранее.\n\n\n"
    },
    {
      "title": "Типичные проблемы производительности и диагностика",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "monitoring",
      "sectionTitle": "Мониторинг и отладка",
      "sectionOrder": 10,
      "order": 5,
      "id": {
        "category": "redis",
        "section": "monitoring",
        "slug": "05-common-performance-issues",
        "lang": "ru"
      },
      "path": "/content/materials/redis/monitoring/05-common-performance-issues.ru.md",
      "content": "\nКогда Redis «медленный», реальная причина почти всегда одна из нескольких: крупные блокирующие команды, неподходящие структуры данных, проблемы с диском (snapshot, AOF), перегруженный сетью или CPU сервер. Хорошая новость — эти ситуации повторяются из проекта в проект, и для них есть устойчивые приёмы диагностики.\n\nРазберём несколько типичных симптомов и шаги, которые помогают быстро сузить поиск.\n\n## Высокая задержка ответов\n\nСимптом: время ответа Redis скачет, иногда подскакивает до десятков и сотен миллисекунд.\n\nЧто проверить:\n\n1. Общую картину:\n\n```\nINFO stats\nINFO clients\nLATENCY DOCTOR\n```\n\n2. SLOWLOG:\n\n```\nSLOWLOG GET 20\n```\n\nЕсли в SLOWLOG видно команды вроде:\n\n- большие LRANGE на сотни тысяч элементов;\n- KEYS с широкими шаблонами;\n- тяжёлые Lua‑скрипты;\n\nто это первые кандидаты на оптимизацию.\n\n## Просадки из‑за snapshot и AOF\n\nСимптом: периодические пики задержек и нагрузки на диск, совпадающие с BGSAVE или BGREWRITEAOF.\n\nЧто смотреть:\n\n```\nINFO persistence\n```\n\nПолезные поля:\n\n- rdb_last_bgsave_status и rdb_last_bgsave_time_sec;\n- aof_last_bgrewrite_status и aof_last_bgrewrite_time_sec.\n\nЕсли длительность фоновых операций велика, а в логах часто видны запуск BGSAVE/BGREWRITEAOF, стоит:\n\n- уменьшить частоту snapshot;\n- убедиться, что диск достаточно быстрый;\n- по возможности выносить Redis и тяжёлые дисковые операции на разные устройства.\n\n## Перегруженный одним узлом кластер\n\nВ кластере возможна ситуация, когда одна нода обрабатывает непропорционально много запросов.\n\nПроверить:\n\n```\nCLUSTER NODES\nINFO stats\n```\n\nЕсли один мастер показывает значительно больший instantaneous_ops_per_sec и used_memory, чем остальные, возможно:\n\n- распределение слотов неравномерно;\n- hash tags ведут слишком много ключей на одну ноду.\n\nРешения:\n\n- перераспределить слоты через redis-cli --cluster reshard;\n- пересмотреть схему ключей и использование hash tags.\n\n## Застрявшие или блокирующие клиенты\n\nСимптом: растёт число blocked_clients, часть команд «висят».\n\nПроверить:\n\n```\nINFO clients\nCLIENT LIST\n```\n\nblocked_clients > 0 говорит, что есть операции, ожидающие данных (BLPOP, BRPOP, XREAD с BLOCK), или другие блокировки.\n\nНужно:\n\n- убедиться, что продюсеры действительно пишут в очереди;\n- проверить, нет ли ситуаций, когда потребители забывают подтверждать сообщения в Streams и переполняют PEL;\n- при необходимости ограничить время блокировки и предусмотреть таймауты на стороне приложения.\n\n## Итог\n\nТипичные проблемы производительности в **Redis** почти всегда сводятся к тяжёлым командам, неудачной конфигурации персистентности или неравномерному распределению нагрузки.\n\nЕсли использовать INFO, SLOWLOG, LATENCY DOCTOR, CLIENT LIST и, при необходимости, команды кластера, диагностика превращается в понятный набор шагов, а не в хаотичный поиск вслепую.\n\n\n"
    },
    {
      "title": "Кэширование",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "01-caching",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/01-caching.ru.md",
      "content": "\nКэширование — одна из самых частых причин использовать Redis. Идея простая: дорогой по времени или ресурсоёмкий результат один раз считается, сохраняется в Redis и потом быстро читается оттуда.\n\n## Простой кэш для тяжёлого запроса\n\nПредставим, что есть запрос к базе данных, который занимает сотни миллисекунд. Вместо того чтобы каждый раз ходить в БД, приложение сначала проверяет Redis.\n\nЛогика на уровне приложения выглядит так:\n\n1. Посмотреть значение в Redis по заранее известному ключу.\n2. Если значение есть — вернуть его.\n3. Если значения нет — взять данные из БД, положить в Redis и вернуть пользователю.\n\nПример работы с ключом cache:article:42:\n\n```\nGET cache:article:42\n```\n\nЕсли ответ пустой, приложение читает статью из базы и записывает результат с временем жизни:\n\n```\nSETEX cache:article:42 60 \"{...json статьи...}\"\n```\n\nКлюч живёт 60 секунд, после чего удаляется. Следующий запрос снова обратится к БД, обновит кэш и цикл продолжится.\n\n**Плюс такого подхода:** кэш не переполнен старыми данными, потому что они автоматически истекают.\n\n## Кэширование страниц и HTTP-ответов\n\nRedis удобно использовать как кэш для целых страниц или фрагментов HTML.\n\nНапример, есть страница товара `/products/10`. Приложение может сформировать HTML один раз и сохранить его в Redis:\n\n```\nSETEX cache:page:/products/10 30 \"<html>...\" \n```\n\nПри следующем запросе к странице сначала проверяется Redis:\n\n```\nGET cache:page:/products/10\n```\n\nЕсли HTML найден, сервер сразу отдаёт его пользователю, не тратя время на повторную сборку страницы.\n\n## Обновление и сброс кэша\n\nКэш всегда связан с исходными данными. Если данные поменялись, старый кэш становится бесполезным.\n\n**Простой подход:** после изменения данных удалить связанный ключ.\n\n```\nDEL cache:article:42\n```\n\nСледующий запрос создаст свежий кэш через SETEX.\n\nИногда кэш обновляют не только при чтении, но и сразу после записи в основное хранилище: как только данные изменились, новое значение кладут в Redis, чтобы не ждать первого запроса.\n\n## Что кэшировать имеет смысл\n\n**Тяжёлые запросы.** То, что долго считается или часто запрашивается.\n\n**Редко меняющиеся данные.** Справочники, популярные статьи, публичные профили.\n\n**Результаты сложных агрегатов.** Статистика, подготовленные выборки.\n\nЧем дороже получение данных без Redis, тем больше выигрывает кэш.\n\n## Чего кэшировать не стоит\n\nДанные, которые меняются каждую секунду и при этом всегда должны быть строго актуальными (например, баланс счёта в банковской системе), плохо подходят для простого кэширования. В таких случаях используют другие механизмы согласованности.\n\nКэширование в Redis не требует сложных схем: достаточно выбрать понятные ключи, задать разумный TTL и обновлять кэш при изменении исходных данных.\n"
    },
    {
      "title": "Rate Limiting",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "02-rate-limiting",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/02-rate-limiting.ru.md",
      "content": "\nRate limiting — это ограничение числа операций за промежуток времени. Чаще всего его используют, чтобы защитить API, формы логина и другие чувствительные точки от злоупотреблений.\n\nИдея простая: считать события (запросы, попытки входа) и не давать делать их слишком часто.\n\n## Простой лимит: не больше N запросов за окно\n\nКлассический пример: не больше 10 запросов в минуту с одного пользователя или IP.\n\nВ качестве ключа можно взять что‑то вроде:\n\n```\nrate:login:ip:127.0.0.1\n```\n\nКаждый запрос увеличивает счётчик и задаёт срок жизни ключа:\n\n```\nINCR rate:login:ip:127.0.0.1\nEXPIRE rate:login:ip:127.0.0.1 60\n```\n\nЛогика в приложении:\n\n1. Увеличить счётчик через INCR.\n2. Если это первый запрос (ответ 1) — задать время жизни через EXPIRE.\n3. Если значение счётчика больше порога (например, 10) — вернуть ошибку «слишком много запросов».\n\nТак получается простое «окно» на 60 секунд: после паузы счётчик сам обнуляется.\n\n## Болеe ровный лимит: скользящее окно на ZSET\n\nФиксированное окно иногда даёт «скачки»: пользователь может сделать почти 2× лимита на границе минут. Чтобы сгладить это, используют скользящее окно на упорядоченном множестве.\n\nКлюч для пользователя:\n\n```\nrate:api:user:42\n```\n\nПри каждом запросе берём текущий timestamp (например, в миллисекундах) и выполняем последовательность команд:\n\n1. Добавить метку времени в ZSET.\n2. Удалить из ZSET все записи старше окна (например, старше 60 секунд).\n3. Посчитать, сколько записей осталось.\n\nПример команд:\n\n```\nZADD rate:api:user:42 1710000000000 \"req1\"\nZREMRANGEBYSCORE rate:api:user:42 -inf 1709999940000\nZCARD rate:api:user:42\n```\n\nЕсли ZCARD показывает, что запросов больше лимита, новый запрос отклоняется.\n\n**Плюсы такого подхода:** более честное ограничение «N запросов за последние X секунд», а не за календарную минуту.\n\n## Что именно ограничивать\n\nВ качестве части ключа для лимита можно использовать:\n\n- идентификатор пользователя;\n- IP‑адрес;\n- комбинацию метода и пути API;\n- любое другое значение, которое нужно защитить.\n\nПримеры ключей:\n\n```\nrate:api:user:42\nrate:api:ip:10.0.0.1\nrate:login:user:42\n```\n\nГлавное — чтобы по ключу было понятно, что именно вы ограничиваете.\n\n## Итого\n\n**Rate limiting на Redis** сводится к двум идеям:\n\n- простой счётчик с TTL для грубого лимита «N запросов за окно»;\n- упорядоченное множество с метками времени для более ровного скользящего окна.\n\nДальше всё зависит от логики приложения: где именно вы добавляете запрос в счётчик и как обрабатываете ситуацию, когда лимит превышен.\n"
    },
    {
      "title": "Очереди задач",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "03-task-queues",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/03-task-queues.ru.md",
      "content": "\n\nОчереди задач помогают вынести тяжёлую или долгую работу из основного потока приложения. Вместо того чтобы делать всё сразу во время HTTP-запроса, задача кладётся в очередь, а отдельный рабочий процесс (worker) забирает её и выполняет в фоне.\n\n## Простой вариант на списках\n\nСамый доступный вариант очереди в Redis — обычный список. Один или несколько производителей кладут задачи в список, а воркеры их забирают.\n\nПример: очередь писем.\n\nПроизводитель кладёт задачу:\n\n```\nLPUSH queue:email \"{\\\"to\\\":\\\"user@example.com\\\",\\\"subject\\\":\\\"Hello\\\"}\"\n```\n\nВоркер забирает задачи с конца списка:\n\n```\nRPOP queue:email\n```\n\nЕсли очередь пустая, RPOP вернёт пустой результат, и воркер может подождать перед следующей попыткой.\n\nЧтобы не опрашивать Redis в цикле, используют блокирующую команду:\n\n```\nBRPOP queue:email 5\n```\n\nКоманда ждёт до 5 секунд, пока не появится новый элемент. Если за это время ничего не пришло, возвращается пустой результат, и можно повторить попытку.\n\n**Плюсы списков:** простая модель, минимум команд, легко начать.\n\n## Несколько очередей и приоритеты\n\nЧасто задач несколько типов: срочные и обычные. Для этого удобно завести несколько списков.\n\nНапример:\n\n```\nLPUSH queue:email:high \"{...}\"\nLPUSH queue:email:default \"{...}\"\n```\n\nВоркер сначала пытается забрать задачу из приоритетной очереди, потом из обычной:\n\n```\nBRPOP queue:email:high queue:email:default 5\n```\n\nRedis сам вернёт задачу из первой непустой очереди.\n\n## Очередь на Streams\n\nСписки просты, но у них есть минус: если воркер забрал задачу и упал до обработки, задача потеряется. Потоки (Streams) дают более надёжную схему.\n\nПример очереди на Streams:\n\nДобавление задачи:\n\n```\nXADD queue:email * to \"user@example.com\" subject \"Hello\"\n```\n\nСоздание группы потребителей (делается один раз):\n\n```\nXGROUP CREATE queue:email workers $ MKSTREAM\n```\n\nЧтение задач воркером из группы:\n\n```\nXREADGROUP GROUP workers worker-1 COUNT 1 STREAMS queue:email >\n```\n\nПосле успешной обработки воркер подтверждает задачу:\n\n```\nXACK queue:email workers <id-записи>\n```\n\nЕсли воркер упал и не успел отправить XACK, запись можно забрать другим воркером из «подвисших» задач через XCLAIM или XPENDING. Так задачи не теряются.\n\n## Что класть в задачу\n\nОбычно в очередь кладут не весь объём данных, а только то, что нужно для повторного поиска:\n\n**Идентификатор.** Например, **user_id**, **order_id**, **notification_id**.\n\n**Тип действия.** Что именно нужно сделать: **send_email**, **rebuild_cache**, **generate_report**.\n\n**Минимальные параметры.** Всё, что нельзя потом достать из основной базы.\n\nПример полезной структуры для задачи:\n\n```\n{\n  \"type\": \"send_email\",\n  \"user_id\": 42,\n  \"template\": \"welcome\"\n}\n```\n\nВоркер по этим данным берёт остальное из основной базы и выполняет нужную операцию.\n\n## Итого\n\n**Очереди задач на Redis** позволяют разгружать основной поток приложения и выполнять тяжёлые операции в фоне. Для простых случаев достаточно списков и команд LPUSH/BRPOP. Когда важно не терять задачи и распределять их между несколькими воркерами, удобнее использовать Streams с группами потребителей."
    },
    {
      "title": "Pub/Sub",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "04-pubsub",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/04-pubsub.ru.md",
      "content": "\nPub/Sub в Redis — это способ отправлять сообщения сразу многим получателям. Один отправитель публикует событие в канал, а все подписчики этого канала получают его почти мгновенно.\n\nЭтот механизм удобен для чатов, уведомлений, сигналов между сервисами и любых ситуаций, где важно «рассказать всем, кто слушает, что что‑то произошло».\n\n## Основная идея\n\nЕсть три участника:\n\n**Канал.** Имя, по которому объединяются отправители и получатели. Например, news:sport.\n\n**Подписчик.** Клиент, который говорит Redis: «хочу получать всё из этого канала».\n\n**Публикатор.** Клиент или сервис, который отправляет сообщения в каналы.\n\nВажно: Pub/Sub не хранит историю. Сообщение видят только те, кто был подписан в момент отправки.\n\n## Простой пример\n\nОдин клиент подписывается на канал:\n\n```\nSUBSCRIBE news:sport\n```\n\nТеперь всё, что придёт в канал news:sport, сразу попадёт этому клиенту.\n\nДругой клиент публикует сообщение:\n\n```\nPUBLISH news:sport \"Гол на 90-й минуте\"\n```\n\nПодписчик увидит это сообщение мгновенно. Если в этот канал подписано несколько клиентов, все они получат один и тот же текст.\n\nЧтобы перестать слушать канал, можно отписаться:\n\n```\nUNSUBSCRIBE news:sport\n```\n\n## Шаблоны каналов\n\nЕсли нужно слушать сразу много каналов, удобно использовать шаблоны.\n\nПодписка по шаблону:\n\n```\nPSUBSCRIBE news:*\n```\n\nТак клиент получит сообщения из всех каналов, которые начинаются с news:. Например, news:sport, news:it, news:world.\n\nОтписка от шаблонов:\n\n```\nPUNSUBSCRIBE news:*\n```\n\n## Пример: уведомления для пользователей\n\nПусть у каждого пользователя есть свой канал уведомлений.\n\nСхема ключей для каналов:\n\n```\nnotifications:user:42\nnotifications:user:100\n```\n\nКлиент пользователя 42 подписывается на свой канал:\n\n```\nSUBSCRIBE notifications:user:42\n```\n\nКогда в системе что‑то происходит (новое сообщение, лайк, комментарий), сервер отправляет событие в нужный канал:\n\n```\nPUBLISH notifications:user:42 \"Новое сообщение в чате\"\n```\n\nКлиент сразу получает уведомление и может показать его в интерфейсе.\n\n## Когда Pub/Sub подходит, а когда нет\n\nPub/Sub хорошо работает, когда:\n\n**Нужна онлайн‑доставка.** Важны только те, кто сейчас подключён.\n\n**Сообщения одноразовые.** Не нужно хранить историю.\n\n**Много слушателей.** Одно сообщение сразу получает несколько клиентов.\n\nPub/Sub плохо подходит, когда:\n\n**Сообщения нельзя терять.** Если получатель отключился, событие ему не придёт.\n\n**Нужна история событий.** Нельзя «догнать» старые сообщения после переподключения.\n\nВ таких случаях лучше смотреть в сторону Streams или очередей задач.\n\n## Итого\n\nPub/Sub в Redis — простой способ делать вещание событий: отправитель публикует сообщение в канал, все подписчики получают его сразу. Никакой истории, только живой поток. Для чатов, сигналов между сервисами и онлайн‑уведомлений этого часто достаточно, особенно на ранних этапах проекта.\n"
    },
    {
      "title": "Хранение сессий",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 5,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "05-session-storage",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/05-session-storage.ru.md",
      "content": "\nХранение сессий в Redis позволяет быстро проверять, авторизован ли пользователь, и не нагружать основную базу лишними запросами. Сессия связывает случайный токен с информацией о пользователе и временем жизни.\n\n## Зачем хранить сессии в Redis\n\n**Redis** хорошо подходит для сессий, потому что:\n\n**Быстро.** Проверка токена — это один запрос к памяти.\n\n**Есть TTL.** Срок действия сессии задаётся автоматически и не требует ручной очистки.\n\n**Удобно масштабировать.** Несколько экземпляров приложения могут работать с одним Redis и видеть одни и те же сессии.\n\n## Простая схема сессии\n\nОбычно сессия выглядит так:\n\n- у пользователя есть случайный токен, который хранится в cookie или заголовке;\n- по этому токену в Redis лежит информация о пользователе.\n\nПример ключа для сессии:\n\n```\nsession:token:abc123\n```\n\nВнутри можно хранить:\n\n- идентификатор пользователя (**user_id**);\n- нужные флаги (например, **is_admin**);\n- время создания, если требуется.\n\nВ Redis это можно записать строкой (JSON) или хешем. Простейший вариант со строкой и временем жизни 30 минут:\n\n```\nSETEX session:token:abc123 1800 \"{\\\"user_id\\\":42}\"\n```\n\n## Создание сессии при логине\n\nПоследовательность шагов при успешном входе:\n\n1. Проверить логин и пароль в основной базе.\n2. Сгенерировать случайный токен.\n3. Сохранить сессию в Redis с TTL.\n4. Отдать токен клиенту.\n\nПример записи сессии в виде хеша:\n\n```\nHSET session:token:abc123 user_id 42\nEXPIRE session:token:abc123 1800\n```\n\nКлиент получает токен **abc123** и отправляет его с каждым запросом (через cookie или заголовок).\n\n## Проверка сессии при запросе\n\nНа каждом запросе сервер:\n\n1. Достаёт токен из cookie или заголовка.\n2. Проверяет, есть ли такая сессия в Redis.\n3. Если сессия найдена — считает пользователя авторизованным.\n\nПример проверки:\n\n```\nHGET session:token:abc123 user_id\n```\n\nЕсли Redis вернул значение, можно считать, что пользователь вошёл. Если пусто — сессия истекла или никогда не существовала.\n\nИногда при каждом запросе с TTL делают «продление» сессии:\n\n```\nEXPIRE session:token:abc123 1800\n```\n\nТак время жизни сдвигается вперёд, пока пользователь активен.\n\n## Выход из аккаунта\n\nПри выходе из аккаунта достаточно удалить запись о сессии:\n\n```\nDEL session:token:abc123\n```\n\nПосле этого токен больше не будет найден, и следующий запрос с этим токеном будет считаться неавторизованным.\n\nЕсли у пользователя много одновременных сессий (несколько устройств), можно делать ключи вида:\n\n```\nsession:user:42:device:phone\nsession:user:42:device:laptop\n```\n\nИ удалять только нужную сессию или сразу все, если требуется принудительный выход везде.\n\n## Итого\n\n**Сессии в Redis** — это связка «токен → данные пользователя с TTL». Приложение быстро проверяет токен, не ходит лишний раз в основную базу и может гибко управлять сроком жизни авторизации.\n\n"
    },
    {
      "title": "Реализация счетчиков и метрик",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 6,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "06-counters-and-metrics",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/06-counters-and-metrics.ru.md",
      "content": "\n\nСчётчики и метрики в Redis используют, чтобы быстро понимать, что происходит в системе: сколько раз нажали кнопку, сколько было логинов, просмотров страниц, ошибок и так далее. Всё держится на простых операциях инкремента.\n\n## Простые счётчики\n\nБазовый вариант — общий счётчик события. Например, сколько всего раз пользователи вошли в систему.\n\nУвеличить счётчик:\n\n```\nINCR metrics:logins\n```\n\nПрочитать текущее значение:\n\n```\nGET metrics:logins\n```\n\nКоманда **INCR** создаст ключ, если его ещё нет, и начнёт отсчёт с 1.\n\nАналогично можно считать клики по кнопке или отправки формы:\n\n```\nINCR metrics:click:buy\nINCR metrics:form:feedback:submit\n```\n\n## Счётчики по дням\n\nЧтобы не просто знать общий итог, а видеть статистику по времени, в ключ добавляют дату.\n\nНапример, логины по дням:\n\n```\nINCR metrics:logins:2025-11-21\n```\n\nПросмотры страницы:\n\n```\nINCR metrics:views:article:42:2025-11-21\n```\n\nТак легко построить график: приложение или аналитика просто считывают значения по датам.\n\nИногда у таких ключей задают время жизни, чтобы старая статистика не висела вечно:\n\n```\nEXPIRE metrics:views:article:42:2025-11-21 2592000\n```\n\nЗдесь данные удалятся через 30 дней.\n\n## Несколько метрик в одном ключе\n\nЕсли метрик много, удобно собирать их в один хеш.\n\nПример общего хеша по системе:\n\n```\nHINCRBY metrics:global logins 1\nHINCRBY metrics:global registrations 1\nHINCRBY metrics:global errors 1\n```\n\nПрочитать все значения сразу:\n\n```\nHGETALL metrics:global\n```\n\nТак можно быстро получить набор ключевых показателей без обхода десятков отдельных ключей.\n\n## Уникальные значения и HyperLogLog\n\nОбычный счётчик показывает количество событий, но не количество уникальных пользователей. Для приблизительного подсчёта уникальных значений в Redis есть **HyperLogLog**.\n\nДобавить пользователя в структуру:\n\n```\nPFADD metrics:uv:2025-11-21 user_42\n```\n\nПолучить оценку числа уникальных пользователей за день:\n\n```\nPFCOUNT metrics:uv:2025-11-21\n```\n\nЭто даёт быстрый и компактный способ считать уникальных посетителей, клиенты, сессии и другие объекты, которых может быть очень много.\n\n## Сброс и чтение показателей\n\nЕсли нужно обнулить счётчик, его просто удаляют:\n\n```\nDEL metrics:logins\n```\n\nИли сбрасывают только отдельное поле в хеше, записав нужное значение через **HSET**.\n\nДля сбора метрик приложение обычно:\n\n- увеличивает счётчики там, где происходят события;\n- периодически читает значения и отправляет их в систему мониторинга или отчётов.\n\n## Итого\n\nСчётчики и метрики в Redis строятся вокруг нескольких команд: **INCR**, **HINCRBY**, **PFADD**, **PFCOUNT**. С их помощью можно считать события, разрезать статистику по дням, хранить несколько показателей в одном ключе и оценивать количество уникальных пользователей без тяжёлых запросов к основной базе."
    },
    {
      "title": "Распределенные блокировки",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "patterns",
      "sectionTitle": "Паттерны и практические кейсы",
      "sectionOrder": 3,
      "order": 7,
      "id": {
        "category": "redis",
        "section": "patterns",
        "slug": "07-distributed-locks",
        "lang": "ru"
      },
      "path": "/content/materials/redis/patterns/07-distributed-locks.ru.md",
      "content": "\nРаспределённые блокировки нужны, когда несколько процессов или серверов должны координировать доступ к общему ресурсу. Например, только один воркер должен обрабатывать задачу, только один процесс может обновлять критичные данные, или нужно предотвратить одновременное выполнение дорогой операции.\n\n**Redis** хорошо подходит для таких блокировок, потому что операции атомарны и выполняются быстро.\n\n## Простая блокировка через SET NX\n\nБазовый способ получить блокировку — использовать команду **SET** с опцией **NX** (только если ключ не существует) и временем жизни.\n\nПример получения блокировки:\n\n```\nSET lock:task:42 \"worker-1\" NX EX 30\n```\n\nЧто происходит:\n\n- **lock:task:42** — имя ключа блокировки;\n- **worker-1** — идентификатор того, кто получил блокировку (полезно для отладки);\n- **NX** — создать ключ только если его ещё нет;\n- **EX 30** — ключ автоматически удалится через 30 секунд.\n\nЕсли команда вернула **OK**, блокировка получена. Если вернула пустой ответ, ключ уже существует — кто‑то другой держит блокировку.\n\n## Освобождение блокировки\n\nКогда работа завершена, блокировку нужно освободить. Важно удалять только свою блокировку, чтобы не снять чужую.\n\nПроверка и удаление:\n\n```\nGET lock:task:42\n```\n\nЕсли значение совпадает с идентификатором текущего процесса, можно удалить:\n\n```\nDEL lock:task:42\n```\n\nНо эта схема не атомарна: между GET и DEL другой процесс может успеть взять блокировку. Безопаснее использовать Lua‑скрипт, который проверяет и удаляет за один шаг.\n\n## Атомарное освобождение через Lua\n\nСкрипт проверяет, что значение ключа совпадает с идентификатором, и только тогда удаляет:\n\n```\nEVAL \"\n  if redis.call('GET', KEYS[1]) == ARGV[1] then\n    return redis.call('DEL', KEYS[1])\n  else\n    return 0\n  end\n\" 1 lock:task:42 worker-1\n```\n\nЗдесь:\n\n- **KEYS[1]** — имя ключа блокировки;\n- **ARGV[1]** — идентификатор процесса, который пытается освободить блокировку.\n\nЕсли идентификатор совпал, ключ удаляется и возвращается 1. Если нет — возвращается 0, блокировка не снимается.\n\n## Продление времени жизни блокировки\n\nИногда работа занимает больше времени, чем изначально заданный TTL. В таких случаях блокировку нужно продлить.\n\nПродление тоже лучше делать атомарно через Lua:\n\n```\nEVAL \"\n  if redis.call('GET', KEYS[1]) == ARGV[1] then\n    return redis.call('EXPIRE', KEYS[1], ARGV[2])\n  else\n    return 0\n  end\n\" 1 lock:task:42 worker-1 60\n```\n\nСкрипт проверяет владельца и продлевает TTL только если идентификатор совпадает.\n\n## Типичные сценарии использования\n\n**Обработка задач воркерами.** Только один воркер должен взять задачу из очереди. Блокировка гарантирует, что задача не будет обработана дважды.\n\n```\nSET lock:process:queue:email \"worker-123\" NX EX 300\n```\n\n**Обновление критичных данных.** При изменении баланса или статуса заказа важно, чтобы два процесса не делали это одновременно.\n\n```\nSET lock:order:42:update \"api-server-1\" NX EX 10\n```\n\n**Предотвращение дублирования операций.** Дорогая операция (генерация отчёта, отправка массовой рассылки) должна выполняться только один раз.\n\n```\nSET lock:report:daily \"scheduler\" NX EX 3600\n```\n\n## Выбор времени жизни блокировки\n\nTTL блокировки должен быть достаточно большим, чтобы покрыть время выполнения операции, но не слишком большим, чтобы при сбое процесса блокировка не висела часами.\n\nТипичные значения:\n\n- для быстрых операций — 5–30 секунд;\n- для обработки задач — 1–5 минут;\n- для долгих операций — 10–30 минут с возможностью продления.\n\nЕсли процесс упал и не освободил блокировку, TTL автоматически удалит ключ, и другой процесс сможет взять блокировку.\n\n## Проблемы и ограничения простой блокировки\n\nПростая блокировка на одном Redis работает хорошо, но есть нюансы:\n\n- если Redis упадёт, все блокировки потеряются;\n- при использовании репликации возможны рассинхронизации;\n- в кластере Redis нужно учитывать особенности шардирования.\n\nДля критичных систем, где важна максимальная надёжность, используют алгоритм **Redlock**, который работает с несколькими независимыми инстансами Redis. Но для большинства практических задач простая блокировка через **SET NX EX** вполне достаточна.\n\n## Итого\n\n**Распределённые блокировки в Redis** строятся вокруг команды **SET NX EX**: атомарное создание ключа с временем жизни гарантирует, что только один процесс получит блокировку.\n\nВажно правильно освобождать блокировку (лучше через Lua‑скрипт) и выбирать разумное время жизни, чтобы балансировать между защитой от зависших процессов и риском преждевременного освобождения блокировки.\n\n"
    },
    {
      "title": "RDB: снимки данных на диск",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "persistence",
      "sectionTitle": "Персистентность данных",
      "sectionOrder": 6,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "persistence",
        "slug": "01-rdb",
        "lang": "ru"
      },
      "path": "/content/materials/redis/persistence/01-rdb.ru.md",
      "content": "\nРежим **RDB** — это периодические снимки состояния Redis на диск. Сервер в какой‑то момент «замораживает» данные и записывает их в бинарный файл **RDB**, чтобы при перезапуске быстро восстановиться до этого состояния.\n\nТакой подход минимально влияет на производительность в обычное время и хорошо подходит для резервного копирования, но при аварии между снимками часть последних изменений может потеряться.\n\n## Как работает RDB на практике\n\nRedis сохраняет снимок либо по расписанию, либо по явной команде. Внутри используется механизм **BGSAVE**: сервер делает fork процесса, и дочерний процесс пишет данные в RDB‑файл, пока основной продолжает принимать команды.\n\nПосмотреть текущие настройки сохранения:\n\n```\nCONFIG GET save\nCONFIG GET dbfilename\nCONFIG GET dir\n```\n\nПример типичной конфигурации:\n\n```\nsave 900 1\nsave 300 10\nsave 60 10000\ndbfilename dump.rdb\ndir /var/lib/redis\n```\n\nЭто значит, что Redis создаст snapshot, если за 900 секунд произошёл хотя бы 1 апдейт, или за 300 секунд — 10 апдейтов, или за 60 секунд — 10000 апдейтов.\n\n## Ручное создание snapshot\n\nИногда нужно сделать снимок «по требованию», например перед обновлением приложения.\n\nСинхронное сохранение (блокирует сервер):\n\n```\nSAVE\n```\n\nАсинхронное сохранение (рекомендуется для продакшена):\n\n```\nBGSAVE\n```\n\nПосле **BGSAVE** в каталоге **dir** появится обновлённый **dump.rdb**. Этот файл можно:\n\n- скопировать на удалённый сервер как резервную копию;\n- использовать для поднятия тестового окружения;\n- хранить в бэкап‑хранилище вместе с другими бэкапами.\n\n## Что происходит при перезапуске\n\nКогда Redis стартует и находит в каталоге **dump.rdb**, он:\n\n1. Загружает данные из RDB в память.\n2. Начинает принимать команды, как обычно.\n\nВсе изменения, сделанные после последнего snapshot, будут потеряны. Если, например, RDB создавался раз в 5 минут, а сервер упал через 4 минуты после сохранения, эти 4 минуты операций не восстановятся.\n\nПоэтому RDB воспринимают как вариант «периодической» персистентности, где допускается небольшой временной лаг в данных.\n\n## Когда RDB уместен, а когда нет\n\nRDB хорошо подходит для:\n\n- резервного копирования состояния Redis;\n- сценариев, где допустима потеря части последних данных;\n- относительно спокойных по записи систем, где snapshot не слишком нагружает диск и память.\n\nRDB хуже подходит, когда:\n\n- важна почти нулевая потеря данных при сбое;\n- нагрузка на запись высокая, и частые snapshot создают заметную нагрузку;\n- Redis используется как основной источник финансовых или других критичных данных.\n\nВ таких случаях RDB часто комбинируют с **AOF** или включают отдельные механизмы репликации и бэкапов.\n\n## Итог\n\nRDB — это простой и быстрый способ периодически сохранять состояние Redis на диск в одном бинарном файле.\n\nЭтот режим почти не мешает производительности в обычной работе и удобен для бэкапов, но всегда нужно помнить, что между снимками часть недавних операций может быть потеряна при аварийном перезапуске.\n\n\n"
    },
    {
      "title": "AOF: журнал команд",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "persistence",
      "sectionTitle": "Персистентность данных",
      "sectionOrder": 6,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "persistence",
        "slug": "02-aof",
        "lang": "ru"
      },
      "path": "/content/materials/redis/persistence/02-aof.ru.md",
      "content": "\nРежим **AOF** (Append Only File) записывает каждую команду изменения данных в журнал на диск. При перезапуске Redis читает этот журнал и «проигрывает» команды заново, восстанавливая состояние почти до момента сбоя.\n\nЗа счёт этого AOF даёт более надёжную персистентность, чем одни только RDB‑снимки, но требует аккуратных настроек и периодической перепаковки файла.\n\n## Как устроен AOF\n\nКогда AOF включён, Redis:\n\n1. При каждом изменении данных дописывает команду в AOF‑файл.\n2. Периодически «сбрасывает» буфер на диск в зависимости от настроек синхронизации.\n3. В фоне может переписывать файл, убирая из него лишние старые команды.\n\nОсновные настройки можно посмотреть так:\n\n```\nCONFIG GET appendonly\nCONFIG GET appendfilename\nCONFIG GET appendfsync\n```\n\nЕсли **appendonly** равен yes, то режим AOF включён. Имя файла по умолчанию — **appendonly.aof**.\n\n## Настройка частоты fsync\n\nКлючевой параметр, влияющий на надёжность и производительность, — **appendfsync**. Он определяет, как часто Redis будет вызывать fsync для записи данных на диск.\n\nВарианты:\n\n```\nCONFIG SET appendfsync always\nCONFIG SET appendfsync everysec\nCONFIG SET appendfsync no\n```\n\nСмысл:\n\n- **always** — fsync после каждой команды. Максимальная надёжность, но может сильно замедлить запись.\n- **everysec** — fsync раз в секунду. Компромисс: в худшем случае теряется около секунды данных.\n- **no** — Redis полагается на буферы ОС. Быстро, но потеря последних изменений при сбое может быть больше.\n\nНа практике чаще всего выбирают **everysec** как баланс между безопасностью и скоростью.\n\n## Включение AOF на живом инстансе\n\nЕсли AOF был выключен, его можно включить без остановки сервера:\n\n```\nCONFIG SET appendonly yes\n```\n\nRedis:\n\n1. Создаст начальный AOF‑файл на основе текущего состояния (под капотом использует RDB + преобразование в набор команд).\n2. Начнёт дописывать новые команды в файл.\n\nЭтот процесс может занять время и временно увеличить нагрузку на диск и память, поэтому включать AOF лучше в спокойный период.\n\n## Перепаковка AOF (AOF rewrite)\n\nСо временем AOF‑файл растёт, потому что в нём остаются старые команды, которые много раз перезаписывали одни и те же ключи. Чтобы файл не раздувался бесконечно, Redis умеет переписывать его в компактный вариант.\n\nЯвный запуск перепаковки:\n\n```\nBGREWRITEAOF\n```\n\nRedis:\n\n1. Создаёт новый временный AOF‑файл с «сжатым» набором команд.\n2. В момент переключения аккуратно заменяет старый файл новым.\n\nТипичный пример:\n\n- старый файл содержит множество SET одного и того же ключа;\n- новый файл будет содержать только один последний SET, который даёт то же итоговое состояние.\n\nПерепаковка может запускаться автоматически при росте файла, если настроены соответствующие параметры в конфиге.\n\n## Когда AOF уместен\n\nРежим AOF хорошо подходит, когда:\n\n- важна минимальная потеря данных при сбое;\n- Redis хранит критичную бизнес‑информацию, а не только кэш;\n- нужно иметь детальный журнал операций для отладки или анализа.\n\nНужно учитывать:\n\n- AOF создаёт дополнительную нагрузку на диск;\n- при некорректных настройках appendfsync запись может стать узким местом;\n- при очень высоких нагрузках на запись иногда используют отдельные инстансы под AOF и под кэш.\n\nЧасто AOF комбинируют с RDB, чтобы ускорить запуск и иметь два независимых источника восстановления.\n\n## Итог\n\n**AOF** превращает Redis в систему с почти непрерывной персистентностью: каждая команда записывается в журнал и может быть воспроизведена после перезапуска.\n\nГрамотный выбор режима **appendfsync**, регулярная перепаковка AOF‑файла и понимание нагрузок на диск позволяют использовать этот механизм без ощутимого удара по производительности.\n\n\n"
    },
    {
      "title": "Комбинированные режимы RDB + AOF",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "persistence",
      "sectionTitle": "Персистентность данных",
      "sectionOrder": 6,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "persistence",
        "slug": "03-combined-modes",
        "lang": "ru"
      },
      "path": "/content/materials/redis/persistence/03-combined-modes.ru.md",
      "content": "\nВ реальных системах редко ограничиваются только RDB или только AOF. Чаще всего их комбинируют: RDB даёт быстрый старт с готовым снимком, а AOF добавляет поверх почти непрерывный журнал изменений.\n\nТакой гибридный режим позволяет ускорить запуск, повысить надёжность и иметь два независимых источника восстановления.\n\n## Как Redis сочетает RDB и AOF\n\nКогда включены оба механизма:\n\n- Redis периодически делает RDB‑snapshot (по настройкам **save**);\n- параллельно каждое изменение записывается в **AOF**;\n- при запуске сервер по умолчанию сначала пытается загрузить AOF, а если его нет или он повреждён — использует RDB.\n\nПорядок загрузки можно проверить и настроить в конфиге, но общая идея проста: AOF считается более «свежим» источником, потому что хранит последние команды.\n\n## Типичная схема: RDB для бэкапов, AOF для минимума потерь\n\nОдин из рабочих вариантов:\n\n1. Оставить включённые snapshot через **save** для периодических RDB‑файлов.\n2. Включить AOF с режимом **appendfsync everysec**.\n3. Настроить автоматическую перепаковку AOF.\n\nКонфигурация будет выглядеть примерно так:\n\n```\nsave 900 1\nsave 300 10\nsave 60 10000\n\nappendonly yes\nappendfilename \"appendonly.aof\"\nappendfsync everysec\n```\n\nВ этом режиме:\n\n- RDB‑файлы удобно использовать для бэкапов и переноса данных;\n- AOF даёт возможность восстановиться почти до момента сбоя с потерей максимум одной секунды изменений.\n\n## Оптимизация запуска: AOF поверх RDB\n\nДля очень больших баз запуск только по AOF может быть медленным: Redis нужно прочитать и выполнить большой журнал команд. Чтобы ускорить старт, есть механизм создания «сложного» AOF на основе snapshot.\n\nСхема работы:\n\n1. Redis делает RDB‑snapshot.\n2. Этот snapshot конвертируется в AOF‑формат как набор начальных команд.\n3. Поверх него продолжается обычный лог AOF.\n\nКоманды управления зависят от конкретной версии Redis, но общая идея в том, чтобы:\n\n- хранить компактное начальное состояние (аналог RDB);\n- иметь короткий хвост AOF с последними изменениями.\n\nЭто уменьшает время запуска и размер файла, сохраняя при этом семантику журнала команд.\n\n## Когда комбинированный режим оправдан\n\nИмеет смысл включать оба механизма, когда:\n\n- Redis хранит данные, потеря которых нежелательна;\n- нужен удобный способ регулярно забирать снимки для бэкапов;\n- объём данных достаточно большой, чтобы волноваться о времени старта и размере AOF.\n\nВместе с этим:\n\n- растёт нагрузка на диск (snapshot + журнал);\n- нужно внимательно следить за настройками памяти и частотой BGSAVE и BGREWRITEAOF;\n- важно мониторить время выполнения фоновых операций, чтобы они не пересекались в самый неудачный момент.\n\nЕсли же Redis используется как чистый кэш, а потеря данных при перезапуске некритична, комбинированный режим чаще всего избыточен — достаточно настроить политику вытеснения и, при необходимости, отдельные RDB‑snapshot для диагностики.\n\n## Итог\n\nКомбинация **RDB + AOF** даёт более гибкий и надёжный вариант персистентности: быстрый старт с готовым снимком и минимальную потерю данных за счёт журнала команд.\n\nВажно подобрать частоту snapshot, режим **appendfsync** и стратегию перепаковки AOF так, чтобы баланс между надёжностью, скоростью и нагрузкой на диск соответствовал реальным требованиям проекта.\n\n\n"
    },
    {
      "title": "Настройки персистентности и бэкапы",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "persistence",
      "sectionTitle": "Персистентность данных",
      "sectionOrder": 6,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "persistence",
        "slug": "04-persistence-settings-and-backups",
        "lang": "ru"
      },
      "path": "/content/materials/redis/persistence/04-persistence-settings-and-backups.ru.md",
      "content": "\nДаже зная разницу между **RDB** и **AOF**, легко запутаться в реальных настройках: как часто делать snapshot, какой режим **appendfsync** выбрать, куда складывать файлы и как организовать бэкапы.\n\nЗадача этого раздела — дать практичные схемы настройки персистентности под разные сценарии и показать простые приёмы резервного копирования Redis.\n\n## Базовые настройки персистентности\n\nПроверить текущие параметры можно так:\n\n```\nCONFIG GET save\nCONFIG GET appendonly\nCONFIG GET appendfsync\nCONFIG GET dir\nCONFIG GET dbfilename\nCONFIG GET appendfilename\n```\n\nЭти команды показывают:\n\n- расписание snapshot (**save**);\n- включён ли AOF (**appendonly**);\n- частоту fsync для AOF (**appendfsync**);\n- каталог и имена файлов для RDB и AOF.\n\nМенять настройки на лету можно через **CONFIG SET**, но для долгосрочных конфигураций лучше фиксировать их в redis.conf и держать под контролем через систему управления конфигурациями.\n\n## Сценарий: Redis как кэш\n\nЕсли Redis используется только как кэш, основной источник данных находится в другой базе, а потеря содержимого Redis не критична.\n\nПрактичная схема:\n\n- отключить snapshot и AOF;\n- настроить лимит памяти и политику вытеснения.\n\nПример:\n\n```\nCONFIG SET save \"\"\nCONFIG SET appendonly no\n\nCONFIG SET maxmemory 2gb\nCONFIG SET maxmemory-policy allkeys-lru\n```\n\nВ этом режиме Redis не делает дисковые записи ради персистентности, работает максимально быстро, а восстановление после перезапуска сводится к прогреву кэша из основного хранилища.\n\n## Сценарий: Redis хранит важные данные\n\nЕсли Redis хранит сессии, очереди задач или бизнес‑данные, которые терять нельзя, имеет смысл включить и RDB, и AOF.\n\nПример настроек:\n\n```\nsave 900 1\nsave 300 10\nsave 60 10000\n\nappendonly yes\nappendfilename \"appendonly.aof\"\nappendfsync everysec\n```\n\nВажные моменты:\n\n- **appendfsync everysec** даёт баланс между скоростью и надёжностью;\n- snapshot по **save** создают регулярные RDB‑файлы, удобные для бэкапов;\n- лог AOF позволяет восстановиться почти до момента сбоя.\n\nДополнительно стоит включить репликацию на резервный инстанс и следить за временем выполнения BGSAVE и BGREWRITEAOF по метрикам.\n\n## Простые бэкапы RDB и AOF\n\nБэкап Redis сводится к копированию файлов RDB и, при необходимости, AOF.\n\nАлгоритм для RDB:\n\n1. Убедиться, что snapshot свежий (при необходимости вызвать **BGSAVE**).\n2. Подождать завершения сохранения (по логам или метрикам).\n3. Скопировать файл **dump.rdb** в безопасное хранилище.\n\nПример ручной последовательности:\n\n```\nBGSAVE\n```\n\nпосле завершения:\n\n```\ncp /var/lib/redis/dump.rdb /backups/redis/dump-2025-11-23.rdb\n```\n\nЕсли используется AOF:\n\n1. Убедиться, что нет активного BGREWRITEAOF.\n2. При желании запустить **BGREWRITEAOF**, чтобы получить компактный файл.\n3. Скопировать **appendonly.aof** в хранилище бэкапов.\n\nВ продакшене эти шаги обычно автоматизируют скриптами и кронами или средствами оркестрации.\n\n## Практические советы по персистентности\n\nНесколько правил, которые часто спасают от проблем:\n\n- выбирать режимы персистентности под конкретный сценарий, а не «на всякий случай всё включить»;\n- не запускать **SAVE** на больших базах, использовать только **BGSAVE**;\n- не забывать про влияние RDB и AOF на память и диск при настройке **maxmemory**;\n- регулярно проверять, что файлы RDB и AOF реально попадают в внешние бэкапы;\n- периодически тестировать восстановление на отдельном стенде, а не надеяться, что всё заработает само.\n\n## Итог\n\nНастройки персистентности в **Redis** — это компромисс между скоростью, надёжностью и простотой эксплуатации.\n\nЕсли осознанно выбирать между режимами «только кэш», «критичные данные» и гибридными схемами, а бэкапы делать и проверять регулярно, Redis остаётся предсказуемым и надёжным даже в сложных продакшен‑окружениях.\n\n\n"
    },
    {
      "title": "Принципы репликации",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "replication",
      "sectionTitle": "Репликация",
      "sectionOrder": 7,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "replication",
        "slug": "01-principles",
        "lang": "ru"
      },
      "path": "/content/materials/redis/replication/01-principles.ru.md",
      "content": "\n**Репликация** в Redis позволяет копировать данные с одного узла на один или несколько реплик. Основной узел принимает записи, а реплики получают поток изменений и поддерживают у себя почти такое же состояние. Это нужно для отказоустойчивости и разгрузки чтения.\n\nБазовая идея: есть один ведущий сервер, который принимает все изменения, и несколько ведомых, которые синхронно или с небольшой задержкой подтягивают данные.\n\n## Роль master и replica\n\nВ простейшем варианте конфигурации есть:\n\n- один основной узел, который принимает команды записи;\n- несколько реплик, которые получают данные только от master.\n\nПосмотреть роли можно через:\n\n```\nINFO replication\n```\n\nНа master вывод будет содержать примерно такое:\n\n```\nrole:master\nconnected_slaves:1\nslave0:ip=10.0.0.2,port=6379,state=online,offset=12345,lag=0\n```\n\nНа реплике:\n\n```\nrole:slave\nmaster_host:10.0.0.1\nmaster_port:6379\nmaster_link_status:up\n```\n\nПо умолчанию реплики работают только на чтение. Это защищает от случайных изменений данных на нескольких узлах и упрощает логику приложения: все записи идут в один master.\n\n## Односторонний поток данных\n\nРепликация в Redis всегда идёт в одну сторону: replica копирует состояние с master, но не наоборот.\n\nПри первом подключении реплика:\n\n1. Запрашивает полную синхронизацию.\n2. Получает snapshot данных от master.\n3. Применяет к себе этот snapshot.\n4. Дальше принимает поток новых команд и применяет их по мере прихода.\n\nЕсли соединение временно обрывается, Redis пытается сделать частичную синхронизацию, используя журнал смещений, чтобы не пересылать всю базу заново. Но в простом понимании важно помнить: master считается источником правды, а replica — копией.\n\n## Зачем нужна репликация\n\nРепликация решает сразу несколько задач:\n\n- распределение нагрузки по чтению — запросы могут идти на реплики;\n- резервная копия данных в реальном времени;\n- подготовка площадки для быстрого переключения в случае сбоя master.\n\nТипичные сценарии:\n\n- выделить master для записи, а отчётные запросы и тяжёлые чтения отправлять на реплики;\n- держать одну replica в другом датацентре для аварийного восстановления;\n- использовать набор master и нескольких replica как основу для автоматического failover через Sentinel или кластер.\n\n## Итог\n\nРепликация в **Redis** строится вокруг простой модели master–replica: один узел принимает изменения, остальные получают от него поток данных и поддерживают актуальное состояние.\n\nТакой подход помогает масштабировать чтение и повышать отказоустойчивость, не усложняя приложение сложной логикой записи на несколько узлов одновременно.\n\n\n"
    },
    {
      "title": "Настройка master–replica",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "replication",
      "sectionTitle": "Репликация",
      "sectionOrder": 7,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "replication",
        "slug": "02-master-replica",
        "lang": "ru"
      },
      "path": "/content/materials/redis/replication/02-master-replica.ru.md",
      "content": "\nНастроить схему master–replica в Redis можно двумя способами: через конфигурационные файлы при запуске или через команды во время работы сервера. В обоих случаях идея одна и та же — указать реплике, у какого master она должна забирать данные.\n\nРазберём минимальную конфигурацию и практические команды, которые пригодятся в разработке и продакшене.\n\n## Базовая конфигурация через redis.conf\n\nПредставим, что у нас два сервера:\n\n- основной: **10.0.0.1:6379**;\n- реплика: **10.0.0.2:6379**.\n\nНа master конфигурация может быть минимальной:\n\n```\nbind 0.0.0.0\nport 6379\n```\n\nНа реплике достаточно указать, откуда брать данные:\n\n```\nbind 0.0.0.0\nport 6379\n\nreplicaof 10.0.0.1 6379\n```\n\nПосле запуска:\n\n- master принимает все записи;\n- replica подключается к master, делает полную синхронизацию и дальше подтягивает изменения.\n\nПроверить роли можно командой:\n\n```\nINFO replication\n```\n\nНа реплике важно держать включённым режим только для чтения, чтобы случайно не писать в неё напрямую:\n\n```\nreplica-read-only yes\n```\n\n## Настройка через команды во время работы\n\nИногда удобнее настраивать репликацию «на лету» без перезапуска.\n\nПусть Redis уже запущен на обоих серверах. Тогда на реплике достаточно выполнить:\n\n```\nREPLICAOF 10.0.0.1 6379\n```\n\nС этого момента узел станет replica указанного master. Если позднее нужно вернуть его к одиночному режиму:\n\n```\nREPLICAOF NO ONE\n```\n\nЭта команда отключает репликацию, и узел снова становится самостоятельным master с теми данными, которые у него есть.\n\nПолезно проверять текущую роль:\n\n```\nROLE\n```\n\nОтвет покажет, является ли сервер master, replica и какие есть соединения.\n\n## Настройка доступа и безопасности\n\nЕсли на master включена авторизация, реплика должна знать пароль, чтобы подключиться.\n\nНа master:\n\n```\nrequirepass \"strong-master-password\"\n```\n\nНа реплике:\n\n```\nmasterauth \"strong-master-password\"\nreplicaof 10.0.0.1 6379\n```\n\nВ новых версиях можно использовать ACL и более гибкие правила, но базовая идея остаётся той же: реплика аутентифицируется к master и после этого начинает получать данные.\n\nВажно:\n\n- не использовать один и тот же Redis для разных окружений (dev, stage, prod);\n- ограничивать доступ по сети к портам Redis;\n- следить, чтобы реплика не «убежала» синхронизироваться с неправильным master.\n\n## Итог\n\nНастройка master–replica в **Redis** сводится к простым шагам: указать реплике адрес master, проверить роли и, при необходимости, настроить авторизацию.\n\nДальше Redis сам берёт на себя полную и частичную синхронизацию, а задача разработчика — правильно встроить эту схему в инфраструктуру и не писать напрямую в реплики.\n\n\n"
    },
    {
      "title": "Поведение при сбоях",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "replication",
      "sectionTitle": "Репликация",
      "sectionOrder": 7,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "replication",
        "slug": "03-failover-behavior",
        "lang": "ru"
      },
      "path": "/content/materials/redis/replication/03-failover-behavior.ru.md",
      "content": "\nРепликация в Redis сама по себе не даёт автоматического переключения при сбоях, но задаёт базовую модель, как система ведёт себя, когда падает master или отваливается сеть. Понимание этого поведения важно, чтобы не потерять данные и правильно строить сценарии аварийного восстановления.\n\nРазберём типичные ситуации: отказ master, потеря связи с replica и ручной перевод роли.\n\n## Если упал master\n\nКогда основной узел недоступен:\n\n- записи на него перестают работать — приложение получает ошибки подключения;\n- реплики продолжают обслуживать запросы на чтение с теми данными, которые у них уже есть;\n- репликация останавливается до восстановления связи.\n\nПриложение может временно переключить чтение на реплики, но записи всё равно придётся куда‑то направлять. Без Sentinel или кластера переключение ролей происходит вручную.\n\nПростой сценарий ручного failover:\n\n1. Убедиться, что master действительно недоступен и не вернётся.\n2. Выбрать одну из реплик как новую основную.\n3. На этой реплике выполнить:\n\n```\nREPLICAOF NO ONE\n```\n\nТеперь узел станет самостоятельным master. Приложение переводит записи на этот адрес.\n\n## Если потерялась связь с репликой\n\nКогда сеть между master и replica рвётся:\n\n- master продолжает работать как обычно;\n- replica перестаёт получать новые данные, но всё ещё обслуживает чтение на своём старом состоянии;\n- в **INFO replication** на master видно, что состояние реплики offline, а offset не растёт.\n\nЕсли реплика используется для чтения, важно понимать, что данные на ней могут отставать на минуту, час или дольше, в зависимости от того, сколько длится проблема с сетью.\n\nКогда связь восстанавливается, Redis пытается сделать частичную синхронизацию. Если это невозможно (слишком большое отставание, переполнен журнал), происходит полная ресинхронизация заново.\n\n## Риск потери данных при принудительном переключении\n\nВ ручном failover есть важная тонкость. Если:\n\n- master успел принять часть записей;\n- эти записи ещё не долетели до replica из‑за задержки или сети;\n- мы переводим replica в master;\n\nто эти «последние» записи на старом master будут потеряны.\n\nПоэтому:\n\n- при возможности стоит использовать Sentinel или кластер, которые учитывают задержки и согласованность;\n- в критичных системах полезно применять команду **WAIT**, чтобы убедиться, что запись дошла до нужного числа реплик:\n\n```\nSET user:42:name \"Alice\"\nWAIT 1 1000\n```\n\nЗдесь Redis вернёт, на сколько реплик запись точно дошла за 1000 миллисекунд. Это не полностью решает проблему, но даёт больше контроля.\n\n## Автоматический failover: куда смотреть дальше\n\nЧистая репликация решает задачу копирования данных, но не управляет ролями master и replica. Для автоматического переключения при сбоях используют:\n\n- **Redis Sentinel** — наблюдает за узлами, голосует о недоступности master и продвигает одну из реплик;\n- **Redis Cluster** — распределяет данные по шартам и имеет встроенный механизм failover.\n\nОсновные принципы остаются прежними, но логика выбора нового master и перенастройки клиентов перекладывается на инфраструктуру.\n\n## Итог\n\nПри сбоях в репликации **Redis** ведёт себя предсказуемо: master остаётся единственной точкой записи, реплики продолжают обслуживать чтение, а переключение ролей нужно делать вручную или через Sentinel и кластер.\n\nЕсли учитывать возможное отставание реплик и аккуратно подходить к ручному failover, можно избежать потери последних записей и построить надёжную схему аварийного восстановления.\n\n\n"
    },
    {
      "title": "Синхронизация и задержки",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "replication",
      "sectionTitle": "Репликация",
      "sectionOrder": 7,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "replication",
        "slug": "04-sync-and-lag",
        "lang": "ru"
      },
      "path": "/content/materials/redis/replication/04-sync-and-lag.ru.md",
      "content": "\nРепликация в Redis асинхронная: master не ждёт, пока все реплики применят изменения, прежде чем ответить клиенту. Это делает систему очень быстрой, но всегда оставляет небольшой риск отставания и потери части последних данных при сбое.\n\nЧтобы управлять этим риском, важно понимать, как работает синхронизация, как измерять задержки и в каких ситуациях имеет смысл ждать подтверждения от реплик.\n\n## Полная и частичная синхронизация\n\nПри первом подключении replica делает полную синхронизацию:\n\n1. master создаёт snapshot и отправляет его реплике;\n2. replica загружает snapshot и применяет его;\n3. после этого replica продолжает принимать поток новых команд.\n\nЕсли соединение временно обрывается, Redis пытается использовать частичную синхронизацию. Для этого он:\n\n- ведёт журнал смещений репликации (offset);\n- хранит недавние команды в буфере.\n\nЕсли отставание реплики укладывается в этот буфер, мастер досылает только недостающие команды. Если нет — запускается новая полная синхронизация.\n\nПонять, что происходит, можно через:\n\n```\nINFO replication\n```\n\nТам видно смещения, состояние связей и отставание по каждой реплике.\n\n## Измерение задержек между master и replica\n\nВ разделе репликации **INFO** показывает показатель **lag** для каждой реплики:\n\n```\nslave0:ip=10.0.0.2,port=6379,state=online,offset=12345,lag=1\n```\n\nПолезные значения:\n\n- **lag** — сколько секунд прошло с момента последнего подтверждения от replica;\n- **offset** — позиция в потоке репликации.\n\nЕсли **lag** растёт и долго держится на больших значениях, это сигнал, что:\n\n- сеть между master и replica нестабильна;\n- ресурсы на реплике не успевают переваривать поток команд;\n- или есть проблемы с диском, если включены тяжёлые режимы персистентности.\n\nТакие ситуации стоит мониторить и настраивать алерты.\n\n## Когда надо ждать подтверждения от реплик (WAIT)\n\nДля операций, которые нельзя потерять, Redis предлагает команду **WAIT**. Она позволяет дождаться, пока данные будут гарантированно записаны на заданное число реплик.\n\nПример:\n\n```\nSET order:501 \"...\"\nWAIT 1 1000\n```\n\nЗдесь:\n\n- первое число — сколько реплик нужно дождаться;\n- второе — таймаут в миллисекундах.\n\nRedis вернёт число реплик, которые подтвердили запись за отведённое время. Если это число меньше ожидаемого, приложение может принять решение:\n\n- повторить операцию позже;\n- зафиксировать факт частичной репликации;\n- временно остановить критичные операции.\n\nВажно помнить, что **WAIT** увеличивает задержку ответа для клиента и не превращает Redis в полностью синхронную систему, но даёт больше контроля для отдельных особо важных операций.\n\n## Практические рекомендации по работе с задержками\n\nНесколько рабочих правил:\n\n- не считать, что replica всегда идеально синхронизирована с master — небольшое отставание нормально;\n- мониторить **lag** и **offset** через **INFO replication**;\n- аккуратно относиться к чтению с реплик там, где нужны строго консистентные данные;\n- использовать **WAIT** только для критичных операций, где допустима дополнительная задержка;\n- следить, чтобы полная синхронизация не запускалась слишком часто — это признак проблем с сетью, памятью или конфигурацией.\n\n## Итог\n\nСинхронизация и задержки в репликации **Redis** — это баланс между скоростью и консистентностью: асинхронная модель делает систему очень быстрой, но требует осознанного отношения к отставанию реплик.\n\nЕсли регулярно смотреть на метрики репликации и точечно использовать инструменты вроде **WAIT**, можно контролировать риск потери данных и при этом не потерять главное преимущество Redis — высокую производительность.\n\n\n"
    },
    {
      "title": "Базовая защита Redis",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "security",
        "slug": "01-basic-security",
        "lang": "ru"
      },
      "path": "/content/materials/redis/security/01-basic-security.ru.md",
      "content": "\nПо умолчанию **Redis** настроен скорее для доверенной среды: локальная разработка, внутренняя сеть, отсутствие прямого доступа из интернета. В продакшене такой подход опасен — сервер может стать открытым для всех, кто видит его порт.\n\nНачинать защиту Redis стоит с трёх вещей: сетевые ограничения, базовая аутентификация и отключение лишних команд в уязвимой среде.\n\n## Сетевые ограничения: bind и protected-mode\n\nПервый слой — не давать лишнего сетевого доступа к Redis.\n\nТипичная безопасная настройка:\n\n```\nbind 127.0.0.1\nprotected-mode yes\nport 6379\n```\n\nСмысл:\n\n- bind 127.0.0.1 — принимать подключения только с локальной машины;\n- protected-mode yes — включён защищённый режим, который запрещает опасные операции при подозрительной конфигурации.\n\nЕсли нужно принимать подключения по сети, лучше явно указать адрес внутреннего интерфейса и защитить доступ firewall, VPN или отдельным уровнем прокси:\n\n```\nbind 10.0.0.10\nprotected-mode yes\n```\n\nОткрывать Redis напрямую в интернет почти никогда не нужно и очень рискованно.\n\n## Пароль и команда AUTH\n\nДаже во внутренней сети стоит включить аутентификацию.\n\nВ конфиге:\n\n```\nrequirepass \"strong-password\"\n```\n\nПосле этого любой клиент должен сначала аутентифицироваться:\n\n```\nAUTH strong-password\nSET cache:page:/ \"...\"\n```\n\nПростые правила:\n\n- использовать длинный случайный пароль;\n- не хранить пароль в открытом виде в репозиториях;\n- передавать пароль в переменных окружения или менеджере секретов.\n\nЕсли требуется несколько ролей с разными правами, лучше использовать ACL, о которых пойдёт речь отдельно.\n\n## Отключение опасных команд\n\nНа некоторых окружениях имеет смысл отключить команды, которые позволяют вызывать shell или управлять модулями.\n\nПримеры:\n\n```\nrename-command FLUSHALL \"\"\nrename-command FLUSHDB \"\"\nrename-command CONFIG \"\"\nrename-command SHUTDOWN \"\"\n```\n\nПустая строка в качестве нового имени фактически отключает команду. Это не защита от всего, но позволяет случайно не стереть данные через FLUSHALL или не дать внешнему пользователю крутить CONFIG.\n\nВажные моменты:\n\n- такие настройки нужно хорошо документировать для команды;\n- инструменты администрирования Redis должны учитывать, что некоторые команды переименованы или отключены.\n\n## Итог\n\nБазовая защита **Redis** — это в первую очередь про сетевую изоляцию, включённый protected-mode, адекватный bind и обязательную аутентификацию.\n\nЕсли с самого начала ограничить доступ к серверу и отключить самые опасные команды в продакшене, риск случайных и умышленных проблем с безопасностью резко снижается даже до внедрения более сложных механизмов.\n\n\n"
    },
    {
      "title": "ACL и разграничение прав",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "security",
        "slug": "02-acl",
        "lang": "ru"
      },
      "path": "/content/materials/redis/security/02-acl.ru.md",
      "content": "\nПароль на весь Redis — это минимум. В более сложных системах хочется давать разным сервисам разные права: одним только чтение, другим ограниченный набор команд, третьим полный доступ. Для этого в **Redis** есть **ACL** — списки контроля доступа.\n\nИдея проста: создаём пользователей с разными правами, выдаём каждому свои учётные данные и описываем, что им можно.\n\n## Просмотр и базовые команды ACL\n\nПосмотреть текущих пользователей:\n\n```\nACL LIST\n```\n\nПолучить информацию о конкретном пользователе:\n\n```\nACL GETUSER default\n```\n\nСоздать нового пользователя и выдать ему права:\n\n```\nACL SETUSER app-reader on >strong-pass ~* +GET +MGET +INFO\n```\n\nРазбор:\n\n- on — включить пользователя;\n- >strong-pass — задать пароль;\n- ~* — разрешить доступ ко всем ключам (ограничения по шаблонам разберём ниже);\n- +GET +MGET +INFO — список разрешённых команд.\n\nПосле этого клиент может аутентифицироваться как app-reader:\n\n```\nAUTH app-reader strong-pass\nGET cache:article:42\n```\n\n## Ограничения по ключам\n\nКроме команд, можно ограничивать доступ по шаблонам ключей.\n\nПример: сервис, который должен видеть только свои ключи сессий.\n\nСоздадим пользователя:\n\n```\nACL SETUSER session-service on >session-pass ~session:* +GET +SET +DEL\n```\n\nЗдесь:\n\n- ~session:* — разрешён доступ только к ключам, начинающимся с session:;\n- +GET +SET +DEL — можно читать, записывать и удалять свои сессии.\n\nЕсли такой пользователь попробует обратиться к cache:article:42, Redis вернёт ошибку доступа.\n\n## Разделение ролей по сервисам\n\nПрактичный подход — завести отдельных пользователей под разные типы сервисов:\n\n- для фоновых задач — право на чтение и запись очередей и кэша;\n- для публичного API — ограниченный набор чтений и безопасных записей;\n- для административных инструментов — расширенный набор команд.\n\nПримеры:\n\nСервис кэша:\n\n```\nACL SETUSER cache-service on >cache-pass ~cache:* +GET +SET +DEL +EXPIRE\n```\n\nСервис метрик:\n\n```\nACL SETUSER metrics-service on >metrics-pass ~metrics:* +INCR +GET +MGET\n```\n\nАдмин:\n\n```\nACL SETUSER admin on >admin-pass allcommands allkeys\n```\n\nТакой расклад позволяет, даже при утечке одного пароля, сильно ограничить ущерб.\n\n## Итог\n\nACL в **Redis** позволяют задать тонкую модель доступа: какие команды доступны, к каким ключам можно обращаться и под какими учётными данными работает каждый сервис.\n\nЕсли для разных частей системы завести отдельных пользователей с минимально необходимыми правами, даже компрометация одной учётной записи не даст злоумышленнику полный контроль над всей базой.\n\n\n"
    },
    {
      "title": "Сетевая безопасность и TLS",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "security",
        "slug": "03-network-and-tls",
        "lang": "ru"
      },
      "path": "/content/materials/redis/security/03-network-and-tls.ru.md",
      "content": "\nДаже при правильных паролях и ACL Redis остаётся уязвимым, если его можно перехватить по сети: трафик без шифрования легко читать и подменять. Поэтому в продакшене важно одновременно ограничить сеть и, при необходимости, включить **TLS**.\n\nПрактически это сводится к трём шагам: изоляция по сети, защита порта Redis и настройка шифрования.\n\n## Изоляция по сети\n\nПервая линия защиты — не выпускать Redis в открытый мир.\n\nТипичные приёмы:\n\n- помещать Redis в приватную подсеть;\n- разрешать к нему доступ только с адресов приложений;\n- закрывать внешний порт на уровне firewall.\n\nПример грубой, но показательной настройки firewall на сервере:\n\n```\niptables -A INPUT -p tcp --dport 6379 -s 10.0.0.0/24 -j ACCEPT\niptables -A INPUT -p tcp --dport 6379 -j DROP\n```\n\nЗдесь 6379 открыт только для подсети 10.0.0.0/24. Остальные подключения режутся ещё до попадания в Redis.\n\nВ оркестраторах вроде Kubernetes те же правила реализуются через NetworkPolicy и настройки сервисов.\n\n## Включение TLS на стороне Redis\n\nНачиная с современных версий, Redis умеет принимать TLS‑подключения напрямую.\n\nВ конфиге:\n\n```\nport 0\ntls-port 6379\n\ntls-cert-file /etc/redis/tls/redis.crt\ntls-key-file /etc/redis/tls/redis.key\ntls-ca-cert-file /etc/redis/tls/ca.crt\n```\n\nЗдесь:\n\n- port 0 — отключаем нешифрованный порт;\n- tls-port 6379 — включаем порт только под TLS;\n- tls-cert-file, tls-key-file, tls-ca-cert-file — путь к сертификату, ключу и корневому сертификату.\n\nПосле этого клиенты должны подключаться с поддержкой TLS:\n\n```\nredis-cli -h my-redis-host -p 6379 --tls \\\n  --cert /etc/redis/tls/client.crt \\\n  --key /etc/redis/tls/client.key \\\n  --cacert /etc/redis/tls/ca.crt\n```\n\nВ бою сертификаты обычно выдаются через корпоративный PKI или автоматизированные системы вроде cert-manager.\n\n## TLS через прокси\n\nЕсли по каким‑то причинам нет возможности собрать Redis с поддержкой TLS, можно использовать внешний прокси.\n\nИдея:\n\n- Redis слушает только на локальном адресе без TLS;\n- снаружи доступен только прокси (например, stunnel, Envoy, Nginx‑стрим), который принимает TLS и прокидывает трафик внутрь.\n\nСхема:\n\n- приложение → TLS → прокси → plain‑TCP → Redis.\n\nПлюсы:\n\n- не нужно трогать конфиг Redis;\n- проще унифицировать шифрование для нескольких сервисов;\n- сертификатами управляет один слой.\n\nМинусы:\n\n- дополнительный компонент в инфраструктуре;\n- важно следить за его отказоустойчивостью и масштабированием.\n\n## Итог\n\nСетевая безопасность в **Redis** начинается с изоляции по сети и правильного bind, а завершается шифрованием трафика через TLS либо на самом Redis, либо через внешний прокси.\n\nЕсли не выпускать порт Redis в интернет, ограничивать список клиентов и шифровать соединения между датацентрами и внешними сервисами, риск перехвата и подмены данных заметно снижается.\n\n\n"
    },
    {
      "title": "Безопасность данных и бэкапы",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "security",
        "slug": "04-data-security-and-backups",
        "lang": "ru"
      },
      "path": "/content/materials/redis/security/04-data-security-and-backups.ru.md",
      "content": "\nПомимо защиты доступа к самому Redis, важно подумать о том, что происходит с данными на диске и в бэкапах. Если RDB‑ и AOF‑файлы лежат в открытом виде, их кража может быть не менее опасна, чем прямой доступ к серверу.\n\nЗадача — сделать так, чтобы потеря диска или бэкапного хранилища не означала автоматическую утечку всех пользовательских данных.\n\n## Где лежат файлы Redis\n\nСначала нужно чётко понимать, где именно находятся данные Redis.\n\nПосмотреть настройки:\n\n```\nCONFIG GET dir\nCONFIG GET dbfilename\nCONFIG GET appendfilename\n```\n\nТипичный ответ:\n\n```\ndir /var/lib/redis\ndbfilename dump.rdb\nappendfilename appendonly.aof\n```\n\nЭто означает, что:\n\n- snapshot RDB лежит в /var/lib/redis/dump.rdb;\n- журнал AOF — в /var/lib/redis/appendonly.aof.\n\nИменно эти файлы нужно включать в зону повышенной защиты: права доступа, мониторинг, шифрование диска.\n\n## Права доступа и изоляция на сервере\n\nМинимальные меры:\n\n- запускать Redis под отдельным пользователем (например, redis);\n- ограничить доступ к каталогу данных:\n\n```\nchown -R redis:redis /var/lib/redis\nchmod 700 /var/lib/redis\n```\n\nТак только пользователь redis будет иметь прямой доступ к файлам RDB и AOF. Остальные пользователи системы не смогут просто так их прочитать.\n\nВ контейнерных и облачных окружениях аналогичные ограничения задаются через политики безопасности и права на volume.\n\n## Шифрование диска и бэкапов\n\nЧтобы кража диска или snapshot в облаке не привела к мгновенной утечке, стоит использовать шифрование:\n\n- на уровне файловой системы (LUKS, BitLocker, eCryptfs и аналоги);\n- на уровне облачного диска (встроенное шифрование в облаке);\n- на уровне бэкапного хранилища (S3‑совместимые хранилища с включённым encryption at rest).\n\nАлгоритм простой:\n\n1. Включить шифрование для дисков, где лежит каталог Redis.\n2. Включить шифрование для хранилища бэкапов.\n3. Следить, чтобы ключи шифрования хранились отдельно от данных и были защищены.\n\nТак даже физическая кража диска не позволит прочитать содержимое без доступа к ключам.\n\n## Чувствительные данные в Redis\n\nОтдельный вопрос — какие именно данные вы кладёте в Redis.\n\nПрактика:\n\n- по возможности избегать хранения «голых» персональных данных (ФИО, адреса, документы);\n- для особо чувствительных полей использовать шифрование на уровне приложения и хранить в Redis уже зашифрованные значения;\n- не кэшировать в Redis то, что нельзя безопасно восстановить или аннулировать.\n\nПример:\n\nвместо хранения телефона как есть:\n\n```\nSET user:42:phone \"+123456789\"\n```\n\nприложение может хранить зашифрованную строку, а ключи шифрования держать отдельно, например в KMS:\n\n```\nSET user:42:phone \"ENC:.....\"\n```\n\nДаже если кто‑то прочитает dump.rdb, расшифровать содержимое без доступа к KMS будет значительно сложнее.\n\n## Итог\n\nБезопасность данных в **Redis** — это не только пароли и ACL, но и защита RDB/AOF‑файлов, дисков и бэкапов, а также осознанный подход к тому, какие данные и в каком виде мы туда кладём.\n\nЕсли ограничить права доступа к файлам, шифровать хранилища и не хранить в Redis лишнюю чувствительную информацию в открытом виде, последствия утечки или кражи инфраструктуры будут гораздо менее критичными.\n\n\n"
    },
    {
      "title": "Типичные ошибки безопасности",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "security",
      "sectionTitle": "Безопасность",
      "sectionOrder": 9,
      "order": 5,
      "id": {
        "category": "redis",
        "section": "security",
        "slug": "05-common-mistakes",
        "lang": "ru"
      },
      "path": "/content/materials/redis/security/05-common-mistakes.ru.md",
      "content": "\nБольшинство проблем безопасности с **Redis** возникают не из‑за сложных уязвимостей, а из‑за простых ошибок в конфигурации. Сервер оказывается доступен из интернета, пароли лежат в репозитории, а дампы данных никто не защищает.\n\nНиже — короткий список типичных промахов и способов их избежать.\n\n## Открытый Redis в интернет\n\nКлассическая ошибка — поднять Redis с bind 0.0.0.0 и без firewall.\n\nПример опасной конфигурации:\n\n```\nbind 0.0.0.0\nprotected-mode no\nrequirepass \"\"\n```\n\nТакой сервер становится добычей для автоматических сканеров: любой, кто найдёт порт 6379, может выполнять команды, читать и стирать данные.\n\nКак правильно:\n\n- не публиковать Redis напрямую в интернет;\n- использовать приватные сети, VPN и firewall;\n- включать protected-mode и аккуратно настраивать bind.\n\n## Отсутствие аутентификации и ACL\n\nЕщё одна частая проблема — отсутствие пароля и единый доступ ко всему Redis.\n\nОшибочный подход:\n\n- rely только на «внутреннюю сеть»;\n- использовать один пароль для всего и всех сервисов.\n\nЛучше:\n\n- всегда задавать requirepass или ACL;\n- создавать отдельных пользователей для разных сервисов;\n- выдавать каждому минимально необходимый набор команд и ключей.\n\n## Пароли и конфиги в репозитории\n\nДаже при хорошей настройке Redis можно всё испортить, если положить пароли и ключи в git.\n\nТипичный антипример:\n\n- redis.conf с реальными паролями в репозитории;\n- docker-compose.yml с открытыми секретами;\n- README с реальными командами AUTH.\n\nЛучше:\n\n- хранить секреты в менеджерах вроде Vault или встроенных секрета‑хранилищах облака;\n- передавать пароли через переменные окружения или отдельные файлы, не попадающие в git;\n- использовать шаблоны конфигураций с подстановкой секретов на этапе деплоя.\n\n## Незащещённые дампы и бэкапы\n\nДаже если сам Redis хорошо спрятан, RDB/AOF‑файлы и бэкапы часто лежат без шифрования и с широкими правами доступа.\n\nОшибки:\n\n- каталоги с dump.rdb и appendonly.aof доступны всем пользователям на сервере;\n- бэкапы в облаке не шифруются;\n- доступ к бэкапному хранилищу не ограничен.\n\nЧто делать:\n\n- ограничить права на каталог данных Redis;\n- включить шифрование дисков и хранилищ бэкапов;\n- регулярно проверять, кто имеет доступ к этим данным.\n\n## Игнорирование обновлений\n\nRedis активно развивается, и вместе с новыми фичами выходят исправления безопасности. Оставлять продакшен на старой версии на годы вперёд — рискованно.\n\nПрактичные шаги:\n\n- следить за релизами Redis и changelog;\n- периодически обновлять версию на стендах и в продакшене;\n- иметь простой процесс отката на прошлую версию в случае проблем.\n\n## Итог\n\nТипичные ошибки безопасности в **Redis** почти всегда связаны с простыми вещами: неправильный bind, отсутствие аутентификации, открытые в репозитории пароли и незащищённые бэкапы.\n\nЕсли осознанно пройтись по этим пунктам и привести конфигурацию в порядок, уровень защиты Redis заметно вырастет, не усложняя архитектуру и не требуя экзотических решений.\n\n\n"
    },
    {
      "title": "Принципы работы",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "streams",
      "sectionTitle": "Redis Streams",
      "sectionOrder": 4,
      "order": 1,
      "id": {
        "category": "redis",
        "section": "streams",
        "slug": "01-principles",
        "lang": "ru"
      },
      "path": "/content/materials/redis/streams/01-principles.ru.md",
      "content": "\n**Redis Streams** — это способ работать с событиями как с непрерывной лентой записей. Вместо того чтобы просто хранить значение по ключу, мы получаем упорядоченный поток сообщений, к которому можно подключаться, читать новые элементы и обрабатывать их как очередь задач или лог событий.\n\nГлавная идея проста: в поток постоянно добавляются новые события, каждое получает уникальный идентификатор и набор полей. Клиенты могут читать эти события с нужного места, не теряя порядок, и строить вокруг этого надёжную обработку.\n\n## Поток как лог событий\n\nУ обычных структур данных в Redis мы работаем с текущим состоянием: значение ключа, содержимое списка, хеша или множества. В **Streams** мы работаем с историей изменений — каждое событие добавляется в конец потока и остаётся там, пока мы его явно не удалим или не обрежем.\n\nПредставим поток событий заказов:\n\n```\nXADD orders:stream * user_id 123 status \"created\" amount 1000\nXADD orders:stream * user_id 456 status \"paid\" amount 500\nXADD orders:stream * user_id 123 status \"shipped\" amount 1000\n```\n\nКаждый вызов **XADD** добавляет запись в конец **orders:stream** и возвращает её идентификатор вида время-последовательность, например:\n\n```\n1698249572-0\n1698249573-0\n1698249574-0\n```\n\nБазовая модель простая:\n\n- поток — это упорядоченная лента событий;\n- каждое событие имеет уникальный идентификатор;\n- данные события — это набор полей и значений.\n\nТакой подход удобно использовать для логов, журналов действий пользователей, бизнес-событий между сервисами.\n\n## Структура записи в потоке\n\nКаждое сообщение в **Streams** — это пара: идентификатор и набор полей. Полей может быть сколько угодно, главное — соблюдать разумную схему.\n\nТипичная запись для логирования действий пользователя:\n\n```\nXADD user:activity:stream * user_id 123 action \"login\" ip \"10.0.0.5\"\nXADD user:activity:stream * user_id 123 action \"view_page\" page \"/products/42\"\nXADD user:activity:stream * user_id 789 action \"logout\" reason \"timeout\"\n```\n\nЗдесь есть несколько важных моментов:\n\n- ключ потока **user:activity:stream** явно говорит о назначении;\n- поле **user_id** позволяет связать события с конкретным пользователем;\n- поля **action**, **page**, **ip**, **reason** дают контекст для аналитики и отладки.\n\nКогда позже мы будем читать поток, эти же поля используются для разбора сообщения и принятия решения, что с ним делать.\n\n## Идентификаторы сообщений и порядок\n\nИдентификатор в **Streams** обычно генерируется автоматически с помощью звёздочки:\n\n```\nXADD metrics:payments:stream * status \"ok\" amount 150\n```\n\nRedis подставляет текущее время и счётчик, формируя значение вида время-последовательность. Это обеспечивает строгий порядок: новые сообщения всегда идут после старых.\n\nИдентификаторы используются:\n\n- чтобы читать поток начиная с нужного места;\n- чтобы не пропускать сообщения при повторных чтениях;\n- чтобы понимать, какие события уже были обработаны.\n\nБазовое чтение потока выглядит так:\n\n```\nXREAD COUNT 2 STREAMS orders:stream 0-0\n```\n\nКоманда вернёт первые две записи из **orders:stream**, начиная с самого начала. Специальный идентификатор 0-0 означает «читать с начала потока». Если вместо него подставить последний прочитанный идентификатор, можно продолжить чтение с нужного места.\n\n## Когда Streams подходят, а когда нет\n\n**Streams** логичнее всего использовать там, где есть последовательность событий, которые нужно обрабатывать по порядку или раздавать нескольким потребителям:\n\n- логирование действий пользователей;\n- события от микросервисов;\n- очереди задач с подтверждением обработки;\n- аналитические события для последующей агрегации.\n\nЕсли задача — просто хранить последнее состояние объекта, например текущий баланс или актуальный профиль пользователя, **Streams** будут излишни. В таких случаях проще и дешевле по памяти использовать строки или хеши.\n\nВажно понимать, что поток сам по себе не очищается. Если не использовать обрезку, он будет расти бесконечно. В разделах про команды и очереди сообщений мы разберём, как управлять размером потока и не давать ему разрастаться.\n\n## Итог\n\n**Redis Streams** дают удобную модель лога событий: каждая запись добавляется в конец потока, получает уникальный идентификатор и остаётся доступной для чтения и повторной обработки.\n\nЭта структура идеально подходит для задач, где важна история и порядок событий, а не только текущее состояние. Главное — сразу продумать схему ключей, поля сообщений и политику очистки, чтобы поток оставался управляемым и полезным."
    },
    {
      "title": "XADD, XREAD, XGROUP",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "streams",
      "sectionTitle": "Redis Streams",
      "sectionOrder": 4,
      "order": 2,
      "id": {
        "category": "redis",
        "section": "streams",
        "slug": "02-xadd-xread-xgroup",
        "lang": "ru"
      },
      "path": "/content/materials/redis/streams/02-xadd-xread-xgroup.ru.md",
      "content": "\nВ основе работы с **Redis Streams** лежат три команды: **XADD** для записи сообщений, **XREAD** для чтения и **XGROUP** для создания и управления группами потребителей. На практике этого уже достаточно, чтобы построить простую очередь задач или обработку событий между сервисами.\n\nРазберём, как они работают на реальных примерах: от простого «написать и прочитать» до подготовки потока к использованию с группами.\n\n## XADD — добавление сообщений в поток\n\nКоманда **XADD** добавляет новое сообщение в конец потока. Минимальный вариант:\n\n```\nXADD orders:stream * user_id 123 status \"created\" amount 1000\n```\n\nЧто здесь происходит:\n\n- создаётся поток **orders:stream**, если его ещё нет;\n- символ звёздочки говорит Redis сгенерировать идентификатор автоматически;\n- дальше идут пары поле–значение: **user_id 123**, **status \"created\"**, **amount 1000**.\n\nВ ответ Redis вернёт идентификатор сообщения, например:\n\n```\n\"1698249601-0\"\n```\n\nЕсли нужно ограничивать размер потока, можно сразу включить обрезку:\n\n```\nXADD orders:stream MAXLEN 1000 * user_id 123 status \"created\" amount 1000\n```\n\nВ этом случае в потоке будет храниться примерно 1000 последних записей, более старые Redis будет удалять по мере добавления новых. Это удобно для логов и аналитики, где не нужна бесконечная история.\n\n## XREAD — чтение сообщений из потока\n\nКоманда **XREAD** читает сообщения из одного или нескольких потоков. Простейший пример — прочитать всё с начала:\n\n```\nXREAD COUNT 3 STREAMS orders:stream 0-0\n```\n\nЗдесь:\n\n- **COUNT 3** ограничивает количество возвращаемых сообщений;\n- **STREAMS orders:stream** указывает, из какого потока читать;\n- **0-0** означает «начать с самого начала потока».\n\nОбычно **XREAD** используют для чтения только новых сообщений. Для этого вместо конкретного идентификатора передают доллар:\n\n```\nXREAD BLOCK 5000 STREAMS orders:stream $\n```\n\nВажные детали:\n\n- **$** означает «ждать только новые сообщения, которых ещё нет у клиента»;\n- **BLOCK 5000** говорит: подождать до 5 секунд появления новых данных, затем вернуть управление даже если сообщений нет.\n\nТак клиент может держать соединение с Redis и получать события почти в реальном времени, не опрашивая сервер в цикле.\n\nЕсли поток не существует, **XREAD** просто вернёт пустой результат. Ошибки не будет — это нужно учитывать в приложении и, при необходимости, создавать поток через **XADD** заранее.\n\n## XGROUP — подготовка потока для групп потребителей\n\nГруппы потребителей — это ключевая возможность **Streams**, которая позволяет нескольким воркерам обрабатывать поток, не дублируя работу. Чтобы использовать группы, поток сначала нужно подготовить командой **XGROUP CREATE**.\n\nСоздадим поток задач на отправку писем и группу обработчиков:\n\n```\nXGROUP CREATE email:tasks:stream email-workers 0-0 MKSTREAM\n```\n\nЗдесь:\n\n- **email:tasks:stream** — ключ потока;\n- **email-workers** — имя группы;\n- **0-0** — с какого идентификатора считать сообщения доступными группе;\n- **MKSTREAM** говорит Redis создать поток, если его ещё нет.\n\nЧаще на практике используют специальное значение доллара:\n\n```\nXGROUP CREATE email:tasks:stream email-workers $ MKSTREAM\n```\n\nТак группа начнёт работу только с новыми сообщениями, которые появятся после создания, не затрагивая старую историю.\n\nЕсли попытаться создать группу повторно с теми же именами потока и группы, Redis вернёт ошибку. Поэтому в автоматических скриптах часто используют вариант с игнорированием ошибки на создание или проверяют наличие группы заранее.\n\n## Связка XADD, XREAD и XGROUP в живой системе\n\nРеальная схема обычно выглядит так:\n\n1. Один или несколько сервисов добавляют задачи в поток с помощью **XADD**.\n2. Поток один раз подготавливается под группы с помощью **XGROUP CREATE**.\n3. Воркеры читают сообщения уже не через **XREAD**, а через **XREADGROUP** (об этом подробно в следующем разделе).\n\nПример — постановка задач на отправку писем:\n\nСоздание группы:\n\n```\nXGROUP CREATE email:tasks:stream email-workers $ MKSTREAM\n```\n\nДобавление задач:\n\n```\nXADD email:tasks:stream * user_id 123 template \"welcome\"\nXADD email:tasks:stream * user_id 456 template \"reset_password\"\n```\n\nЧтение новых задач без групп (для простого потребителя или отладки):\n\n```\nXREAD COUNT 10 STREAMS email:tasks:stream 0-0\n```\n\nВ боевом варианте вместо этого используют чтение через **XREADGROUP**, чтобы распределять задачи между несколькими воркерами и подтверждать успешную обработку.\n\n## Итог\n\nКоманды **XADD**, **XREAD** и **XGROUP** формируют базовый набор для работы с **Redis Streams**: первая пишет события, вторая читает их, третья готовит поток к распределённой обработке через группы потребителей.\n\nПонимание этих команд позволяет уже на этом уровне построить простую, но рабочую систему очередей и логов. В следующем разделе мы углубимся в **Consumer Groups** и посмотрим, как организовать надёжную обработку сообщений несколькими воркерами с подтверждением и повторными попытками."
    },
    {
      "title": "Consumer Groups",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "streams",
      "sectionTitle": "Redis Streams",
      "sectionOrder": 4,
      "order": 3,
      "id": {
        "category": "redis",
        "section": "streams",
        "slug": "03-consumer-groups",
        "lang": "ru"
      },
      "path": "/content/materials/redis/streams/03-consumer-groups.ru.md",
      "content": "\n**Consumer Groups** в **Redis Streams** позволяют нескольким воркерам безопасно обрабатывать один и тот же поток сообщений, не дублируя работу и не теряя события. Каждый воркер входит в группу, получает свою порцию задач и подтверждает обработку, чтобы Redis мог переотдать незавершённые сообщения при сбоях.\n\nЕсли смотреть на это практическими глазами, Consumer Groups — это способ построить пул воркеров поверх одного потока: сколько бы экземпляров сервиса ни работало, каждое сообщение будет обработано ровно одним из них.\n\n## Базовая схема работы группы\n\nПредставим поток задач на обработку заказов:\n\n```\nXGROUP CREATE orders:stream orders-workers $ MKSTREAM\n```\n\nДальше в приложении поднимаются несколько воркеров, каждый со своим именем потребителя внутри группы:\n\n```\nXREADGROUP GROUP orders-workers worker-1 COUNT 10 STREAMS orders:stream >\nXREADGROUP GROUP orders-workers worker-2 COUNT 10 STREAMS orders:stream >\n```\n\nВажные детали:\n\n- **orders-workers** — имя группы потребителей;\n- **worker-1** и **worker-2** — имена конкретных потребителей (экземпляров сервиса);\n- символ **>** говорит «дай мне только новые сообщения, которые ещё никому не назначены».\n\nRedis раздаёт новые сообщения между потребителями внутри группы. Если воркеров несколько, задачи распределяются по ним, как в очереди.\n\n## Подтверждение обработки: XACK и PEL\n\nКогда воркер прочитал сообщение через **XREADGROUP** и успешно его обработал, он обязан подтвердить это командой **XACK**:\n\n```\nXACK orders:stream orders-workers 1698249601-0\n```\n\nЗдесь:\n\n- **orders:stream** — поток;\n- **orders-workers** — группа;\n- **1698249601-0** — идентификатор обработанного сообщения.\n\nПока подтверждения нет, сообщение считается «висящим» в специальном списке PEL (Pending Entries List). Посмотреть такие сообщения можно через **XPENDING**:\n\n```\nXPENDING orders:stream orders-workers\n```\n\nВ ответ Redis покажет:\n\n- сколько сообщений «в работе»;\n- минимальный и максимальный идентификаторы;\n- примеры по потребителям.\n\nЭто особенно полезно, когда один из воркеров упал и не успел подтвердить обработку. Сообщения не пропадают, их можно перераспределить.\n\n## Повторная выдача сообщений другим воркерам\n\nЕсли потребитель перестал отвечать, сообщения, которые числятся за ним в PEL, можно вручную или программно передать другому воркеру. Для этого используется команда **XCLAIM**.\n\nПример: за **worker-1** «зависли» сообщения, которые висят дольше 60 секунд. Мы хотим передать их **worker-2**:\n\nСначала смотрим, какие сообщения зависли у **worker-1**:\n\n```\nXPENDING orders:stream orders-workers - + 10 worker-1\n```\n\nДопустим, среди них есть **1698249601-0**. Тогда:\n\n```\nXCLAIM orders:stream orders-workers worker-2 60000 1698249601-0\n```\n\nЗдесь:\n\n- **worker-2** забирает себе сообщение;\n- **60000** — минимальное время в миллисекундах, которое сообщение должно провести в PEL, прежде чем его можно будет «забрать».\n\nПосле успешной обработки новый воркер так же делает **XACK**, и сообщение окончательно считается завершённым.\n\n## Типичный цикл жизни сообщения в группе\n\nЕсли собрать всё вместе, жизнь одной записи в **Streams** с Consumer Groups выглядит так:\n\n1. Продюсер добавляет запись в поток через **XADD**.\n2. Группа уже создана командой **XGROUP CREATE**.\n3. Один из воркеров читает запись через **XREADGROUP** с маркером **>**.\n4. Redis назначает сообщение этому потребителю и помещает его в PEL.\n5. Воркер обрабатывает задачу и вызывает **XACK**.\n6. Сообщение остаётся в потоке как часть истории, но больше не считается «висящим» в группе.\n\nЕсли воркер падает между шагами 3 и 5, сообщение остаётся в PEL и может быть перераспределено через **XPENDING** и **XCLAIM**.\n\n## Когда стоит использовать Consumer Groups\n\nConsumer Groups особенно полезны в сценариях:\n\n- есть поток задач, которые должны быть выполнены ровно один раз;\n- нагрузка плавает, и нужно просто добавлять или убирать воркеры;\n- важно не терять сообщения при падении отдельных экземпляров сервиса;\n- несколько сервисов читают один и тот же поток по-разному — для этого можно создать несколько независимых групп на одном потоке.\n\nЕсли же есть всего один потребитель, который читает поток линейно, можно обойтись обычным **XREAD** и собственным хранением последнего прочитанного идентификатора. Consumer Groups здесь дадут больше сложности, чем пользы.\n\n## Итог\n\n**Consumer Groups** превращают Redis Streams в полноценную основу для распределённых очередей: сообщения раздаются между воркерами, отслеживаются в PEL, подтверждаются и при необходимости перераспределяются.\n\nТакой подход позволяет строить надёжные системы обработки задач без потерь и дублирования, сохраняя при этом всю историю событий в самом потоке."
    },
    {
      "title": "Построение очередей сообщений",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "streams",
      "sectionTitle": "Redis Streams",
      "sectionOrder": 4,
      "order": 4,
      "id": {
        "category": "redis",
        "section": "streams",
        "slug": "04-message-queues",
        "lang": "ru"
      },
      "path": "/content/materials/redis/streams/04-message-queues.ru.md",
      "content": "\nС помощью **Redis Streams** можно строить надёжные очереди сообщений: один или несколько сервисов кладут задачи в поток, а группа воркеров забирает их, обрабатывает и подтверждает выполнение. В отличие от простых списков, здесь есть подтверждение обработки, повторная выдача задач при сбоях и возможность масштабировать потребителей.\n\nРазберём, как собрать рабочую очередь пошагово: от постановки задач до обработки и очистки.\n\n## Очередь задач на одном потоке\n\nБазовая модель очереди — один поток для задач и одна группа потребителей.\n\nСоздадим поток и группу для воркеров, которые рассылают письма:\n\n```\nXGROUP CREATE email:tasks:stream email-workers $ MKSTREAM\n```\n\nТеперь любой сервис может положить задачу в очередь:\n\n```\nXADD email:tasks:stream * user_id 123 template \"welcome\"\nXADD email:tasks:stream * user_id 456 template \"reset_password\"\n```\n\nВоркеры читают задачи из группы:\n\n```\nXREADGROUP GROUP email-workers worker-1 COUNT 5 STREAMS email:tasks:stream >\n```\n\nКаждый воркер:\n\n- получает набор задач;\n- обрабатывает каждую (например, отправляет письмо);\n- подтверждает обработку через **XACK**:\n\n```\nXACK email:tasks:stream email-workers 1698249601-0 1698249602-0\n```\n\nТак формируется классическая очередь: задачи приходят в поток, распределяются по воркерам и отмечаются как выполненные.\n\n## Масштабирование: несколько воркеров и балансировка\n\nЧтобы увеличить пропускную способность, достаточно добавить ещё воркеры с разными именами потребителей в той же группе:\n\n```\nXREADGROUP GROUP email-workers worker-2 COUNT 5 STREAMS email:tasks:stream >\nXREADGROUP GROUP email-workers worker-3 COUNT 5 STREAMS email:tasks:stream >\n```\n\nRedis сам будет раздавать новые сообщения между **worker-1**, **worker-2**, **worker-3**. Сообщение попадает только одному потребителю, поэтому работа не дублируется.\n\nЕсли один из воркеров падает, его незавершённые сообщения остаются в PEL. Их можно:\n\n- либо автоматически переобрабатывать тем же воркером после перезапуска;\n- либо вручную перераспределить через **XPENDING** и **XCLAIM**, как описано в разделе про Consumer Groups.\n\nТаким образом, очередь остаётся живой даже при частичных сбоях.\n\n## Ограничение размера очереди и очистка\n\nЕсли в очередь постоянно добавляются новые задачи, важно не дать потоку вырасти бесконечно. Для этого используют обрезку через **MAXLEN** в **XADD**:\n\n```\nXADD email:tasks:stream MAXLEN 10000 * user_id 123 template \"welcome\"\n```\n\nЗдесь в потоке в среднем будет примерно 10000 последних задач. Старые записи удаляются. Для обычных рабочих очередей этого достаточно: нас интересуют только актуальные задачи.\n\nИногда нужно жёстко ограничить размер, чтобы контролировать память. Тогда используют опцию **MAXLEN ~** или без тильды — чем строже ограничение, тем чаще Redis будет тратить ресурсы на поддержание длины.\n\nЕсли требуется полностью очистить очередь, можно удалить поток:\n\n```\nDEL email:tasks:stream\n```\n\nПосле этого при первом **XADD** поток создастся заново, но группы потребителей тоже исчезнут. В боевых системах чаще регулируют длину и периодически чистят старые данные, не удаляя поток полностью.\n\n## Разделение очередей по типам задач\n\nВ реальных системах удобно делить очереди по типам работ:\n\n- **email:tasks:stream** — отправка писем;\n- **billing:tasks:stream** — операции с оплатами;\n- **reports:tasks:stream** — генерация отчётов.\n\nКаждая очередь получает свою группу потребителей и набор воркеров. Например, для биллинга создадим отдельную группу:\n\n```\nXGROUP CREATE billing:tasks:stream billing-workers $ MKSTREAM\n```\n\nПостановка задачи:\n\n```\nXADD billing:tasks:stream * user_id 999 type \"invoice\" amount 2500\n```\n\nОбработка:\n\n```\nXREADGROUP GROUP billing-workers billing-1 COUNT 5 STREAMS billing:tasks:stream >\n```\n\nТак можно независимо масштабировать только те очереди, которые действительно нагружены, не трогая остальные.\n\n## Итог\n\n**Redis Streams** позволяют строить очереди сообщений с подтверждением обработки, перераспределением «зависших» задач и масштабированием воркеров через Consumer Groups.\n\nПри грамотной схеме ключей, ограничении длины потока и аккуратной работе с подтверждениями получается гибкий и надёжный механизм фоновой обработки задач, который легко вписывается в микросервисную архитектуру."
    },
    {
      "title": "Практические сценарии",
      "category": "redis",
      "categoryTitle": "Redis",
      "section": "streams",
      "sectionTitle": "Redis Streams",
      "sectionOrder": 4,
      "order": 5,
      "id": {
        "category": "redis",
        "section": "streams",
        "slug": "05-practical-scenarios",
        "lang": "ru"
      },
      "path": "/content/materials/redis/streams/05-practical-scenarios.ru.md",
      "content": "\n**Redis Streams** хорошо раскрываются на живых задачах: когда нужно передать событие между сервисами, организовать фоновые работы или собрать последовательный лог действий пользователей. Ниже — несколько типичных сценариев, которые легко повторить и адаптировать под свои проекты.\n\nКаждый пример опирается на уже знакомые команды **XADD**, **XREAD**, **XGROUP** и **XREADGROUP**.\n\n## Фоновые задачи: отправка писем и уведомлений\n\nКлассика для Streams — вынести отправку писем, пушей и других уведомлений в отдельную очередь, чтобы не блокировать основной HTTP-запрос.\n\nПостановка задач в очередь:\n\n```\nXGROUP CREATE notify:tasks:stream notify-workers $ MKSTREAM\n\nXADD notify:tasks:stream * user_id 123 type \"email\" template \"welcome\"\nXADD notify:tasks:stream * user_id 456 type \"push\" template \"promo\" channel \"mobile\"\n```\n\nВоркеры читают задачи и обрабатывают их:\n\n```\nXREADGROUP GROUP notify-workers worker-1 COUNT 10 STREAMS notify:tasks:stream >\n```\n\nПосле успешной отправки:\n\n```\nXACK notify:tasks:stream notify-workers 1698249601-0 1698249602-0\n```\n\nТакое разделение позволяет:\n\n- не держать пользователя в ожидании долгой отправки;\n- масштабировать только воркеры уведомлений при росте нагрузки;\n- гибко управлять повторами при временных ошибках внешних сервисов.\n\n## Лог действий пользователей для аналитики\n\nВместо того чтобы сразу писать каждое действие в тяжёлую базу, можно сначала собрать события в поток, а затем асинхронно выгружать их в хранилище аналитики.\n\nЗапись событий:\n\n```\nXADD analytics:user:activity:stream * user_id 123 action \"view_page\" page \"/products/42\"\nXADD analytics:user:activity:stream * user_id 123 action \"add_to_cart\" product_id 42\nXADD analytics:user:activity:stream * user_id 789 action \"search\" query \"laptop\"\n```\n\nСервис аналитики периодически читает новые записи:\n\n```\nXREAD COUNT 100 STREAMS analytics:user:activity:stream $\n```\n\nЛибо работает через свою группу:\n\n```\nXGROUP CREATE analytics:user:activity:stream analytics-workers $ MKSTREAM\nXREADGROUP GROUP analytics-workers etl-1 COUNT 100 STREAMS analytics:user:activity:stream >\n```\n\nПреимущества:\n\n- события не теряются, даже если аналитическое хранилище временно недоступно;\n- можно повторно прогнать историю для отладки или перерасчёта метрик;\n- нагрузка на основную базу снижается, так как запись идёт батчами.\n\n## Шина событий между микросервисами\n\nStreams удобно использовать как простую шину событий: один сервис публикует бизнес-события, остальные подписываются на них через свои группы.\n\nПродюсер заказов пишет в поток:\n\n```\nXADD events:orders:stream * event \"order_created\" order_id 501 user_id 123 amount 1500\nXADD events:orders:stream * event \"order_cancelled\" order_id 502 user_id 456 reason \"payment_failed\"\n```\n\nСервис биллинга создаёт свою группу и реагирует только на нужные события:\n\n```\nXGROUP CREATE events:orders:stream billing-subscribers $ MKSTREAM\nXREADGROUP GROUP billing-subscribers billing-1 COUNT 10 STREAMS events:orders:stream >\n```\n\nСервис уведомлений делает то же самое, но обрабатывает события по-своему:\n\n```\nXGROUP CREATE events:orders:stream notify-subscribers $ MKSTREAM\nXREADGROUP GROUP notify-subscribers notify-1 COUNT 10 STREAMS events:orders:stream >\n```\n\nКаждая группа видит все события независимо от других и ведёт свой прогресс чтения. Это позволяет легко добавлять новые потребители, не меняя продюсера.\n\n## Ограничение скоростей и «умные» очереди\n\nStreams можно использовать как основу для rate limiting и более сложных схем обработки, когда важно не только выполнить задачи, но и соблюдать ограничения по скорости.\n\nНапример, у нас есть поток задач на внешнее API, где нельзя делать больше 100 запросов в минуту:\n\n```\nXGROUP CREATE external:api:tasks:stream api-workers $ MKSTREAM\n\nXADD external:api:tasks:stream * user_id 123 endpoint \"/profile\" priority \"normal\"\nXADD external:api:tasks:stream * user_id 456 endpoint \"/balance\" priority \"high\"\n```\n\nВоркеры:\n\n- читают задачи через **XREADGROUP**;\n- перед выполнением смотрят счётчик запросов в **rate:external:api**;\n- либо сразу выполняют и инкрементят счётчик, либо откладывают задачу на потом.\n\nКомбинация **Streams** и счётчиков в Redis позволяет строить гибкие схемы ограничения скорости без сложной инфраструктуры.\n\n## Итог\n\n**Redis Streams** хорошо подходят для задач, где есть последовательность событий или задач, которые нужно безопасно передавать между частями системы и обрабатывать асинхронно.\n\nНа их основе можно строить очереди фоновых работ, логи и шины событий для микросервисов, при этом оставаясь в рамках знакомого Redis и не вводя отдельную систему для каждого сценария."
    }
  ]
}