---
title: "Построение очередей сообщений"
category: "redis"
categoryTitle: "Redis"
section: "streams"
sectionTitle: "Redis Streams"
sectionOrder: 4
order: 4
---

С помощью **Redis Streams** можно строить надёжные очереди сообщений: один или несколько сервисов кладут задачи в поток, а группа воркеров забирает их, обрабатывает и подтверждает выполнение. В отличие от простых списков, здесь есть подтверждение обработки, повторная выдача задач при сбоях и возможность масштабировать потребителей.

Разберём, как собрать рабочую очередь пошагово: от постановки задач до обработки и очистки.

## Очередь задач на одном потоке

Базовая модель очереди — один поток для задач и одна группа потребителей.

Создадим поток и группу для воркеров, которые рассылают письма:

```
XGROUP CREATE email:tasks:stream email-workers $ MKSTREAM
```

Теперь любой сервис может положить задачу в очередь:

```
XADD email:tasks:stream * user_id 123 template "welcome"
XADD email:tasks:stream * user_id 456 template "reset_password"
```

Воркеры читают задачи из группы:

```
XREADGROUP GROUP email-workers worker-1 COUNT 5 STREAMS email:tasks:stream >
```

Каждый воркер:

- получает набор задач;
- обрабатывает каждую (например, отправляет письмо);
- подтверждает обработку через **XACK**:

```
XACK email:tasks:stream email-workers 1698249601-0 1698249602-0
```

Так формируется классическая очередь: задачи приходят в поток, распределяются по воркерам и отмечаются как выполненные.

## Масштабирование: несколько воркеров и балансировка

Чтобы увеличить пропускную способность, достаточно добавить ещё воркеры с разными именами потребителей в той же группе:

```
XREADGROUP GROUP email-workers worker-2 COUNT 5 STREAMS email:tasks:stream >
XREADGROUP GROUP email-workers worker-3 COUNT 5 STREAMS email:tasks:stream >
```

Redis сам будет раздавать новые сообщения между **worker-1**, **worker-2**, **worker-3**. Сообщение попадает только одному потребителю, поэтому работа не дублируется.

Если один из воркеров падает, его незавершённые сообщения остаются в PEL. Их можно:

- либо автоматически переобрабатывать тем же воркером после перезапуска;
- либо вручную перераспределить через **XPENDING** и **XCLAIM**, как описано в разделе про Consumer Groups.

Таким образом, очередь остаётся живой даже при частичных сбоях.

## Ограничение размера очереди и очистка

Если в очередь постоянно добавляются новые задачи, важно не дать потоку вырасти бесконечно. Для этого используют обрезку через **MAXLEN** в **XADD**:

```
XADD email:tasks:stream MAXLEN 10000 * user_id 123 template "welcome"
```

Здесь в потоке в среднем будет примерно 10000 последних задач. Старые записи удаляются. Для обычных рабочих очередей этого достаточно: нас интересуют только актуальные задачи.

Иногда нужно жёстко ограничить размер, чтобы контролировать память. Тогда используют опцию **MAXLEN ~** или без тильды — чем строже ограничение, тем чаще Redis будет тратить ресурсы на поддержание длины.

Если требуется полностью очистить очередь, можно удалить поток:

```
DEL email:tasks:stream
```

После этого при первом **XADD** поток создастся заново, но группы потребителей тоже исчезнут. В боевых системах чаще регулируют длину и периодически чистят старые данные, не удаляя поток полностью.

## Разделение очередей по типам задач

В реальных системах удобно делить очереди по типам работ:

- **email:tasks:stream** — отправка писем;
- **billing:tasks:stream** — операции с оплатами;
- **reports:tasks:stream** — генерация отчётов.

Каждая очередь получает свою группу потребителей и набор воркеров. Например, для биллинга создадим отдельную группу:

```
XGROUP CREATE billing:tasks:stream billing-workers $ MKSTREAM
```

Постановка задачи:

```
XADD billing:tasks:stream * user_id 999 type "invoice" amount 2500
```

Обработка:

```
XREADGROUP GROUP billing-workers billing-1 COUNT 5 STREAMS billing:tasks:stream >
```

Так можно независимо масштабировать только те очереди, которые действительно нагружены, не трогая остальные.

## Итог

**Redis Streams** позволяют строить очереди сообщений с подтверждением обработки, перераспределением «зависших» задач и масштабированием воркеров через Consumer Groups.

При грамотной схеме ключей, ограничении длины потока и аккуратной работе с подтверждениями получается гибкий и надёжный механизм фоновой обработки задач, который легко вписывается в микросервисную архитектуру.