---
title: "Профилирование и pprof"
category: "golang"
categoryTitle: "Go"
section: "best-practices"
sectionTitle: "Практики и качество"
sectionOrder: 11
order: 4
---

Код работает, тесты зелёные, но сервис тормозит или ест слишком много памяти. Угадывать, где проблема — плохая стратегия. Go предоставляет встроенный профайлер **pprof**, который точно показывает, на что тратится CPU и куда уходит память.

## Подключение pprof к серверу

Самый простой способ — импортировать пакет **net/http/pprof**. Он автоматически регистрирует HTTP-эндпоинты для профилирования.

```
import (
    "net/http"
    _ "net/http/pprof"
)

func main() {
    go func() {
        http.ListenAndServe("localhost:6060", nil)
    }()

    runApp()
}
```

Подчёркивание перед импортом (**_ "net/http/pprof"**) означает: "нам не нужны функции из этого пакета, но его init() должен выполниться". Именно init() регистрирует обработчики.

Эндпоинт слушает на **localhost:6060** — доступен только локально. Не выставляйте pprof наружу в продакшене без аутентификации.

## CPU-профиль

CPU-профиль показывает, какие функции потребляют больше всего процессорного времени.

### Сбор профиля

```
go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30
```

Во время сбора отправляйте нагрузку на сервер (реальные запросы или через утилиту вроде **wrk** / **hey**), чтобы профиль отразил типичную работу.

### Анализ в интерактивном режиме

После сбора откроется интерактивная консоль.

```
(pprof) top 10
```

Команда **top** показывает функции, которые потребляют больше всего CPU:

```
Showing top 10 nodes out of 85
      flat  flat%   sum%        cum   cum%
     2.10s 28.38% 28.38%      2.10s 28.38%  runtime.memmove
     1.20s 16.22% 44.59%      1.20s 16.22%  encoding/json.(*decodeState).scanWhile
     0.80s 10.81% 55.41%      3.40s 45.95%  myapp/handler.ProcessRequest
```

- **flat** — время, проведённое непосредственно в этой функции.
- **cum** (cumulative) — время в этой функции плюс во всех функциях, которые она вызвала.

```
(pprof) list ProcessRequest
```

Команда **list** показывает исходный код с аннотациями — сколько времени потратила каждая строка.

### Визуализация

```
go tool pprof -http=:8080 http://localhost:6060/debug/pprof/profile?seconds=30
```

Флаг **-http** запускает веб-интерфейс с интерактивным графом вызовов, flame graph и другими визуализациями. Это самый удобный способ анализа.

## Профиль памяти (heap)

Показывает, какие функции выделяют больше всего памяти.

```
go tool pprof http://localhost:6060/debug/pprof/heap
```

```
(pprof) top
      flat  flat%   sum%        cum   cum%
    512MB 45.00% 45.00%    512MB 45.00%  myapp/cache.LoadAll
    128MB 11.25% 56.25%    128MB 11.25%  encoding/json.(*Decoder).Decode
```

Два режима просмотра:

- **inuse_space** (по умолчанию) — сколько памяти занято прямо сейчас.
- **alloc_space** — сколько памяти было выделено за всё время (включая уже освобождённую).

```
(pprof) sample_index = alloc_space
(pprof) top
```

Режим **alloc_space** полезен для поиска мест, где создаётся много короткоживущих объектов — это нагружает сборщик мусора.

## Профилирование горутин

Если сервис зависает или горутины утекают (goroutine leak), посмотрите профиль горутин.

```
go tool pprof http://localhost:6060/debug/pprof/goroutine
```

```
(pprof) top
    5000  goroutines in total
    4990  myapp/worker.processJob (blocked on channel receive)
```

Если видите тысячи горутин, застрявших в одном месте — это утечка. Горутина создаётся, но никогда не завершается (например, читает из канала, в который никто не пишет).

## Профилирование в тестах

Для профилирования без запуска сервера используйте флаги **go test**. Для CPU — **-cpuprofile**, для памяти — **-memprofile**:

```
go test -cpuprofile=cpu.out -bench=. ./...
go tool pprof cpu.out

go test -memprofile=mem.out -bench=. ./...
go tool pprof mem.out
```

Это удобно для оптимизации конкретных функций: написали бенчмарк, сняли профиль, нашли узкое место, оптимизировали, сняли профиль снова.

## Профилирование в коде

Иногда нужно профилировать не сервер, а утилиту командной строки.

```
import "runtime/pprof"

func main() {
    f, _ := os.Create("cpu.out")
    pprof.StartCPUProfile(f)
    defer pprof.StopCPUProfile()

    doHeavyWork()
}
```

```
go tool pprof cpu.out
```

## Практический пример: поиск утечки памяти

Сервис постепенно ест всё больше памяти. Алгоритм поиска:

1. Снимите heap-профиль: **go tool pprof -http=:8080 http://localhost:6060/debug/pprof/heap**.
2. Откройте flame graph в веб-интерфейсе.
3. Найдите самую широкую полоску — это функция, выделяющая больше всего памяти.
4. Посмотрите исходный код через **list**.
5. Типичные причины: растущий кэш без TTL, срезы, которые только растут, горутины, которые не завершаются.

## Итог

**pprof** — встроенный профайлер Go для CPU, памяти и горутин. Подключается одной строкой импорта. Используйте **go tool pprof -http** для визуального анализа. **Никогда не оптимизируйте по ощущениям — снимите профиль и оптимизируйте то, что действительно тормозит.**
